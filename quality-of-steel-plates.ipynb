{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 68699,
     "databundleVersionId": 7659021,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30674,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.kernel_approximation import AdditiveChi2Sampler\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.feature_selection import RFECV, SelectKBest\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.cluster import KMeans, FeatureAgglomeration\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-28T13:29:19.576961Z",
     "iopub.execute_input": "2024-03-28T13:29:19.577336Z",
     "iopub.status.idle": "2024-03-28T13:29:19.588419Z",
     "shell.execute_reply.started": "2024-03-28T13:29:19.577308Z",
     "shell.execute_reply": "2024-03-28T13:29:19.587385Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T16:44:54.419977900Z",
     "start_time": "2024-03-31T16:44:52.386920500Z"
    }
   },
   "execution_count": 1,
   "outputs": [],
   "id": "818c9dca0d55fb94"
  },
  {
   "cell_type": "code",
   "source": [
    "train = pd.read_csv('./data/train.csv').drop('id', axis=1)\n",
    "test = pd.read_csv('./data/test.csv').drop('id', axis=1)\n",
    "sub = pd.read_csv('./data/sample_submission.csv', index_col='id')"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:14:38.256617Z",
     "iopub.execute_input": "2024-03-28T12:14:38.257027Z",
     "iopub.status.idle": "2024-03-28T12:14:38.536993Z",
     "shell.execute_reply.started": "2024-03-28T12:14:38.256987Z",
     "shell.execute_reply": "2024-03-28T12:14:38.536055Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:18:17.663767300Z",
     "start_time": "2024-03-31T20:18:17.215986Z"
    }
   },
   "execution_count": 102,
   "outputs": [],
   "id": "1c4f2114c7f14632"
  },
  {
   "cell_type": "code",
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:14:42.059628Z",
     "iopub.execute_input": "2024-03-28T12:14:42.060531Z",
     "iopub.status.idle": "2024-03-28T12:14:42.097942Z",
     "shell.execute_reply.started": "2024-03-28T12:14:42.060495Z",
     "shell.execute_reply": "2024-03-28T12:14:42.096610Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:18:18.566587400Z",
     "start_time": "2024-03-31T20:18:18.542019200Z"
    }
   },
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "       X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n0            584        590     909972     909977            16            8   \n1            808        816     728350     728372           433           20   \n2             39        192    2212076    2212144         11388          705   \n3            781        789    3353146    3353173           210           16   \n4           1540       1560     618457     618502           521           72   \n...          ...        ...        ...        ...           ...          ...   \n19214        749        757     143210     143219            17            4   \n19215        723        735    2488529    2488541           231           17   \n19216          6         31    1578055    1578129           780          114   \n19217          9         18    1713172    1713184           126           13   \n19218       1505       1525    1733458    1733471           182           24   \n\n       Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n0                5               2274                    113   \n1               54              44478                     70   \n2              420            1311391                     29   \n3               29               3202                    114   \n4               67              48231                     82   \n...            ...                ...                    ...   \n19214            4               2193                    122   \n19215           26              27135                    104   \n19216           98              71112                     41   \n19217           26              14808                     88   \n19218           33              22785                     98   \n\n       Maximum_of_Luminosity  ...  Orientation_Index  Luminosity_Index  \\\n0                        140  ...            -0.5000           -0.0104   \n1                        111  ...             0.7419           -0.2997   \n2                        141  ...            -0.0105           -0.0944   \n3                        134  ...             0.6667           -0.0402   \n4                        111  ...             0.9158           -0.2455   \n...                      ...  ...                ...               ...   \n19214                    140  ...            -0.1429            0.0044   \n19215                    133  ...             0.7222           -0.0989   \n19216                     94  ...             0.7719           -0.4283   \n19217                    132  ...             0.9610           -0.1162   \n19218                    143  ...             0.5263           -0.1120   \n\n       SigmoidOfAreas  Pastry  Z_Scratch  K_Scatch  Stains  Dirtiness  Bumps  \\\n0              0.1417       0          0         0       1          0      0   \n1              0.9491       0          0         0       0          0      0   \n2              1.0000       0          0         1       0          0      0   \n3              0.4025       0          0         1       0          0      0   \n4              0.9998       0          0         0       0          0      0   \n...               ...     ...        ...       ...     ...        ...    ...   \n19214          0.2901       0          0         0       1          0      0   \n19215          0.5378       0          0         0       0          0      0   \n19216          0.9997       1          0         0       0          0      0   \n19217          0.3509       0          0         0       0          0      0   \n19218          0.6619       0          0         0       0          0      1   \n\n       Other_Faults  \n0                 0  \n1                 1  \n2                 0  \n3                 0  \n4                 1  \n...             ...  \n19214             0  \n19215             1  \n19216             0  \n19217             1  \n19218             0  \n\n[19219 rows x 34 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X_Minimum</th>\n      <th>X_Maximum</th>\n      <th>Y_Minimum</th>\n      <th>Y_Maximum</th>\n      <th>Pixels_Areas</th>\n      <th>X_Perimeter</th>\n      <th>Y_Perimeter</th>\n      <th>Sum_of_Luminosity</th>\n      <th>Minimum_of_Luminosity</th>\n      <th>Maximum_of_Luminosity</th>\n      <th>...</th>\n      <th>Orientation_Index</th>\n      <th>Luminosity_Index</th>\n      <th>SigmoidOfAreas</th>\n      <th>Pastry</th>\n      <th>Z_Scratch</th>\n      <th>K_Scatch</th>\n      <th>Stains</th>\n      <th>Dirtiness</th>\n      <th>Bumps</th>\n      <th>Other_Faults</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>584</td>\n      <td>590</td>\n      <td>909972</td>\n      <td>909977</td>\n      <td>16</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2274</td>\n      <td>113</td>\n      <td>140</td>\n      <td>...</td>\n      <td>-0.5000</td>\n      <td>-0.0104</td>\n      <td>0.1417</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>808</td>\n      <td>816</td>\n      <td>728350</td>\n      <td>728372</td>\n      <td>433</td>\n      <td>20</td>\n      <td>54</td>\n      <td>44478</td>\n      <td>70</td>\n      <td>111</td>\n      <td>...</td>\n      <td>0.7419</td>\n      <td>-0.2997</td>\n      <td>0.9491</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>39</td>\n      <td>192</td>\n      <td>2212076</td>\n      <td>2212144</td>\n      <td>11388</td>\n      <td>705</td>\n      <td>420</td>\n      <td>1311391</td>\n      <td>29</td>\n      <td>141</td>\n      <td>...</td>\n      <td>-0.0105</td>\n      <td>-0.0944</td>\n      <td>1.0000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>781</td>\n      <td>789</td>\n      <td>3353146</td>\n      <td>3353173</td>\n      <td>210</td>\n      <td>16</td>\n      <td>29</td>\n      <td>3202</td>\n      <td>114</td>\n      <td>134</td>\n      <td>...</td>\n      <td>0.6667</td>\n      <td>-0.0402</td>\n      <td>0.4025</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1540</td>\n      <td>1560</td>\n      <td>618457</td>\n      <td>618502</td>\n      <td>521</td>\n      <td>72</td>\n      <td>67</td>\n      <td>48231</td>\n      <td>82</td>\n      <td>111</td>\n      <td>...</td>\n      <td>0.9158</td>\n      <td>-0.2455</td>\n      <td>0.9998</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19214</th>\n      <td>749</td>\n      <td>757</td>\n      <td>143210</td>\n      <td>143219</td>\n      <td>17</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2193</td>\n      <td>122</td>\n      <td>140</td>\n      <td>...</td>\n      <td>-0.1429</td>\n      <td>0.0044</td>\n      <td>0.2901</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19215</th>\n      <td>723</td>\n      <td>735</td>\n      <td>2488529</td>\n      <td>2488541</td>\n      <td>231</td>\n      <td>17</td>\n      <td>26</td>\n      <td>27135</td>\n      <td>104</td>\n      <td>133</td>\n      <td>...</td>\n      <td>0.7222</td>\n      <td>-0.0989</td>\n      <td>0.5378</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19216</th>\n      <td>6</td>\n      <td>31</td>\n      <td>1578055</td>\n      <td>1578129</td>\n      <td>780</td>\n      <td>114</td>\n      <td>98</td>\n      <td>71112</td>\n      <td>41</td>\n      <td>94</td>\n      <td>...</td>\n      <td>0.7719</td>\n      <td>-0.4283</td>\n      <td>0.9997</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19217</th>\n      <td>9</td>\n      <td>18</td>\n      <td>1713172</td>\n      <td>1713184</td>\n      <td>126</td>\n      <td>13</td>\n      <td>26</td>\n      <td>14808</td>\n      <td>88</td>\n      <td>132</td>\n      <td>...</td>\n      <td>0.9610</td>\n      <td>-0.1162</td>\n      <td>0.3509</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19218</th>\n      <td>1505</td>\n      <td>1525</td>\n      <td>1733458</td>\n      <td>1733471</td>\n      <td>182</td>\n      <td>24</td>\n      <td>33</td>\n      <td>22785</td>\n      <td>98</td>\n      <td>143</td>\n      <td>...</td>\n      <td>0.5263</td>\n      <td>-0.1120</td>\n      <td>0.6619</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>19219 rows × 34 columns</p>\n</div>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "id": "eb5b6af24a3dd493"
  },
  {
   "cell_type": "code",
   "source": [
    "train.shape, test.shape, sub.shape"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:14:44.149946Z",
     "iopub.execute_input": "2024-03-28T12:14:44.150405Z",
     "iopub.status.idle": "2024-03-28T12:14:44.157052Z",
     "shell.execute_reply.started": "2024-03-28T12:14:44.150367Z",
     "shell.execute_reply": "2024-03-28T12:14:44.156070Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:18:21.233263200Z",
     "start_time": "2024-03-31T20:18:21.176227800Z"
    }
   },
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "((19219, 34), (12814, 27), (12814, 7))"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "id": "ee885990865ff7c7"
  },
  {
   "cell_type": "code",
   "source": [
    "ys = list(train.columns[-7:])"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:14:45.166730Z",
     "iopub.execute_input": "2024-03-28T12:14:45.167119Z",
     "iopub.status.idle": "2024-03-28T12:14:45.171906Z",
     "shell.execute_reply.started": "2024-03-28T12:14:45.167089Z",
     "shell.execute_reply": "2024-03-28T12:14:45.171024Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:18:22.895394400Z",
     "start_time": "2024-03-31T20:18:22.881328200Z"
    }
   },
   "execution_count": 105,
   "outputs": [],
   "id": "969b54e5dfd30c7a"
  },
  {
   "cell_type": "code",
   "source": [
    "Y = train.loc[:, ys]\n",
    "X = train.drop(ys, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:14:46.141634Z",
     "iopub.execute_input": "2024-03-28T12:14:46.142024Z",
     "iopub.status.idle": "2024-03-28T12:14:46.149800Z",
     "shell.execute_reply.started": "2024-03-28T12:14:46.141982Z",
     "shell.execute_reply": "2024-03-28T12:14:46.148897Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:18:24.001926Z",
     "start_time": "2024-03-31T20:18:23.993159400Z"
    }
   },
   "execution_count": 106,
   "outputs": [],
   "id": "1eb826efe30cfe7b"
  },
  {
   "cell_type": "code",
   "source": [
    "X.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:14:46.819991Z",
     "iopub.execute_input": "2024-03-28T12:14:46.820356Z",
     "iopub.status.idle": "2024-03-28T12:14:46.830723Z",
     "shell.execute_reply.started": "2024-03-28T12:14:46.820323Z",
     "shell.execute_reply": "2024-03-28T12:14:46.829594Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:18:24.988231400Z",
     "start_time": "2024-03-31T20:18:24.981565100Z"
    }
   },
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "X_Minimum                0\nX_Maximum                0\nY_Minimum                0\nY_Maximum                0\nPixels_Areas             0\nX_Perimeter              0\nY_Perimeter              0\nSum_of_Luminosity        0\nMinimum_of_Luminosity    0\nMaximum_of_Luminosity    0\nLength_of_Conveyer       0\nTypeOfSteel_A300         0\nTypeOfSteel_A400         0\nSteel_Plate_Thickness    0\nEdges_Index              0\nEmpty_Index              0\nSquare_Index             0\nOutside_X_Index          0\nEdges_X_Index            0\nEdges_Y_Index            0\nOutside_Global_Index     0\nLogOfAreas               0\nLog_X_Index              0\nLog_Y_Index              0\nOrientation_Index        0\nLuminosity_Index         0\nSigmoidOfAreas           0\ndtype: int64"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "id": "ee5f2aabd4884dab"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# target = np.asarray(Y.apply(lambda x: np.argmax(x), axis=1))\n",
    "# target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T16:45:25.073291900Z",
     "start_time": "2024-03-31T16:45:25.062642400Z"
    }
   },
   "id": "31cb574263e0d9b9"
  },
  {
   "cell_type": "code",
   "source": [
    "# pd.Series(mutual_info_classif(train.iloc[:, :-7], target), index=train.columns[:-7])"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:14:47.877693Z",
     "iopub.execute_input": "2024-03-28T12:14:47.878076Z",
     "iopub.status.idle": "2024-03-28T12:15:03.547034Z",
     "shell.execute_reply.started": "2024-03-28T12:14:47.878049Z",
     "shell.execute_reply": "2024-03-28T12:15:03.546023Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T16:45:26.553048100Z",
     "start_time": "2024-03-31T16:45:26.532854400Z"
    }
   },
   "execution_count": 9,
   "outputs": [],
   "id": "22c3ff27fd663162"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                       X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  \\\nX_Minimum               1.000000   0.989767   0.016071   0.014247   \nX_Maximum               0.989767   1.000000   0.018909   0.016513   \nY_Minimum               0.016071   0.018909   1.000000   0.969552   \nY_Maximum               0.014247   0.016513   0.969552   1.000000   \nPixels_Areas           -0.464759  -0.391937  -0.007370  -0.007019   \nX_Perimeter            -0.451961  -0.378434  -0.012712  -0.012377   \nY_Perimeter            -0.426514  -0.356528  -0.024876  -0.024798   \nSum_of_Luminosity      -0.430073  -0.363092  -0.008189  -0.007809   \nMinimum_of_Luminosity   0.337748   0.275571  -0.017321  -0.018739   \nMaximum_of_Luminosity  -0.132955  -0.129669  -0.029160  -0.028312   \nLength_of_Conveyer      0.308740   0.293466   0.016586   0.015735   \nTypeOfSteel_A300        0.220151   0.189802   0.044781   0.044867   \nTypeOfSteel_A400       -0.218122  -0.188033  -0.044328  -0.044422   \nSteel_Plate_Thickness   0.188764   0.164789  -0.054389  -0.058683   \nEdges_Index             0.167358   0.129800   0.035762   0.034222   \nEmpty_Index            -0.175624  -0.146167  -0.033792  -0.032824   \nSquare_Index            0.045635   0.035124   0.033952   0.034552   \nOutside_X_Index        -0.522112  -0.432545   0.019685   0.017271   \nEdges_X_Index           0.112746   0.095799   0.052710   0.051546   \nEdges_Y_Index           0.460421   0.391743  -0.002647  -0.001382   \nOutside_Global_Index    0.222109   0.190474  -0.025374  -0.023285   \nLogOfAreas             -0.505024  -0.428875  -0.001754  -0.000995   \nLog_X_Index            -0.530728  -0.448348   0.015116   0.015624   \nLog_Y_Index            -0.375324  -0.316770  -0.023702  -0.022941   \nOrientation_Index       0.276871   0.237157  -0.044202  -0.042490   \nLuminosity_Index       -0.068844  -0.079235  -0.023000  -0.022869   \nSigmoidOfAreas         -0.376973  -0.319598  -0.031511  -0.030345   \n\n                       Pixels_Areas  X_Perimeter  Y_Perimeter  \\\nX_Minimum                 -0.464759    -0.451961    -0.426514   \nX_Maximum                 -0.391937    -0.378434    -0.356528   \nY_Minimum                 -0.007370    -0.012712    -0.024876   \nY_Maximum                 -0.007019    -0.012377    -0.024798   \nPixels_Areas               1.000000     0.835079     0.834543   \nX_Perimeter                0.835079     1.000000     0.912579   \nY_Perimeter                0.834543     0.912579     1.000000   \nSum_of_Luminosity          0.797843     0.802072     0.809171   \nMinimum_of_Luminosity     -0.622867    -0.603891    -0.602826   \nMaximum_of_Luminosity      0.130499     0.158036     0.160831   \nLength_of_Conveyer        -0.208256    -0.206060    -0.188716   \nTypeOfSteel_A300          -0.304635    -0.300883    -0.304057   \nTypeOfSteel_A400           0.300308     0.296467     0.299557   \nSteel_Plate_Thickness     -0.232467    -0.225757    -0.189628   \nEdges_Index               -0.337258    -0.326388    -0.320950   \nEmpty_Index                0.269263     0.322417     0.338079   \nSquare_Index               0.024658     0.050052     0.003372   \nOutside_X_Index            0.764810     0.752470     0.700036   \nEdges_X_Index             -0.303335    -0.378672    -0.469092   \nEdges_Y_Index             -0.650704    -0.664781    -0.612157   \nOutside_Global_Index      -0.205579    -0.174615    -0.081225   \nLogOfAreas                 0.774580     0.771546     0.790863   \nLog_X_Index                0.749731     0.750418     0.705657   \nLog_Y_Index                0.640033     0.667441     0.761117   \nOrientation_Index         -0.269013    -0.234969    -0.113968   \nLuminosity_Index          -0.015081     0.005212    -0.005650   \nSigmoidOfAreas             0.542672     0.561256     0.608167   \n\n                       Sum_of_Luminosity  Minimum_of_Luminosity  \\\nX_Minimum                      -0.430073               0.337748   \nX_Maximum                      -0.363092               0.275571   \nY_Minimum                      -0.008189              -0.017321   \nY_Maximum                      -0.007809              -0.018739   \nPixels_Areas                    0.797843              -0.622867   \nX_Perimeter                     0.802072              -0.603891   \nY_Perimeter                     0.809171              -0.602826   \nSum_of_Luminosity               1.000000              -0.580857   \nMinimum_of_Luminosity          -0.580857               1.000000   \nMaximum_of_Luminosity           0.128569               0.397265   \nLength_of_Conveyer             -0.194282               0.018612   \nTypeOfSteel_A300               -0.282051               0.103835   \nTypeOfSteel_A400                0.278000              -0.100916   \nSteel_Plate_Thickness          -0.215082               0.133881   \nEdges_Index                    -0.309055               0.397904   \nEmpty_Index                     0.271448              -0.096133   \nSquare_Index                    0.031948               0.062940   \nOutside_X_Index                 0.703912              -0.638549   \nEdges_X_Index                  -0.315125               0.234592   \nEdges_Y_Index                  -0.608297               0.467841   \nOutside_Global_Index           -0.177048               0.112480   \nLogOfAreas                      0.726483              -0.691406   \nLog_X_Index                     0.698035              -0.637711   \nLog_Y_Index                     0.615651              -0.585194   \nOrientation_Index              -0.234625               0.179385   \nLuminosity_Index               -0.013845               0.619174   \nSigmoidOfAreas                  0.520282              -0.504692   \n\n                       Maximum_of_Luminosity  ...  Outside_X_Index  \\\nX_Minimum                          -0.132955  ...        -0.522112   \nX_Maximum                          -0.129669  ...        -0.432545   \nY_Minimum                          -0.029160  ...         0.019685   \nY_Maximum                          -0.028312  ...         0.017271   \nPixels_Areas                        0.130499  ...         0.764810   \nX_Perimeter                         0.158036  ...         0.752470   \nY_Perimeter                         0.160831  ...         0.700036   \nSum_of_Luminosity                   0.128569  ...         0.703912   \nMinimum_of_Luminosity               0.397265  ...        -0.638549   \nMaximum_of_Luminosity               1.000000  ...         0.074610   \nLength_of_Conveyer                 -0.181411  ...        -0.272466   \nTypeOfSteel_A300                   -0.221093  ...        -0.333026   \nTypeOfSteel_A400                    0.220088  ...         0.329806   \nSteel_Plate_Thickness              -0.113917  ...        -0.270063   \nEdges_Index                         0.153931  ...        -0.362471   \nEmpty_Index                         0.108878  ...         0.293223   \nSquare_Index                        0.061480  ...        -0.098957   \nOutside_X_Index                     0.074610  ...         1.000000   \nEdges_X_Index                      -0.014785  ...        -0.156802   \nEdges_Y_Index                      -0.153276  ...        -0.760021   \nOutside_Global_Index               -0.120083  ...        -0.382777   \nLogOfAreas                          0.033191  ...         0.811960   \nLog_X_Index                         0.079426  ...         0.898341   \nLog_Y_Index                         0.004650  ...         0.598918   \nOrientation_Index                  -0.113531  ...        -0.467688   \nLuminosity_Index                    0.853856  ...        -0.050740   \nSigmoidOfAreas                      0.018501  ...         0.609049   \n\n                       Edges_X_Index  Edges_Y_Index  Outside_Global_Index  \\\nX_Minimum                   0.112746       0.460421              0.222109   \nX_Maximum                   0.095799       0.391743              0.190474   \nY_Minimum                   0.052710      -0.002647             -0.025374   \nY_Maximum                   0.051546      -0.001382             -0.023285   \nPixels_Areas               -0.303335      -0.650704             -0.205579   \nX_Perimeter                -0.378672      -0.664781             -0.174615   \nY_Perimeter                -0.469092      -0.612157             -0.081225   \nSum_of_Luminosity          -0.315125      -0.608297             -0.177048   \nMinimum_of_Luminosity       0.234592       0.467841              0.112480   \nMaximum_of_Luminosity      -0.014785      -0.153276             -0.120083   \nLength_of_Conveyer          0.110726       0.296749              0.182721   \nTypeOfSteel_A300            0.198026       0.286424              0.062285   \nTypeOfSteel_A400           -0.196268      -0.283340             -0.061767   \nSteel_Plate_Thickness      -0.036774       0.255632              0.200674   \nEdges_Index                 0.224152       0.313508              0.048415   \nEmpty_Index                -0.323494      -0.465523             -0.205664   \nSquare_Index                0.299610       0.083152             -0.099019   \nOutside_X_Index            -0.156802      -0.760021             -0.382777   \nEdges_X_Index               1.000000       0.136147             -0.336322   \nEdges_Y_Index               0.136147       1.000000              0.529914   \nOutside_Global_Index       -0.336322       0.529914              1.000000   \nLogOfAreas                 -0.462665      -0.713607             -0.168963   \nLog_X_Index                -0.207693      -0.851813             -0.436422   \nLog_Y_Index                -0.651384      -0.464314              0.127741   \nOrientation_Index          -0.412696       0.607271              0.863987   \nLuminosity_Index            0.072659      -0.053778             -0.115506   \nSigmoidOfAreas             -0.538678      -0.594737             -0.105986   \n\n                       LogOfAreas  Log_X_Index  Log_Y_Index  \\\nX_Minimum               -0.505024    -0.530728    -0.375324   \nX_Maximum               -0.428875    -0.448348    -0.316770   \nY_Minimum               -0.001754     0.015116    -0.023702   \nY_Maximum               -0.000995     0.015624    -0.022941   \nPixels_Areas             0.774580     0.749731     0.640033   \nX_Perimeter              0.771546     0.750418     0.667441   \nY_Perimeter              0.790863     0.705657     0.761117   \nSum_of_Luminosity        0.726483     0.698035     0.615651   \nMinimum_of_Luminosity   -0.691406    -0.637711    -0.585194   \nMaximum_of_Luminosity    0.033191     0.079426     0.004650   \nLength_of_Conveyer      -0.254979    -0.287967    -0.195315   \nTypeOfSteel_A300        -0.362923    -0.321869    -0.334782   \nTypeOfSteel_A400         0.359392     0.318857     0.331959   \nSteel_Plate_Thickness   -0.202286    -0.267696    -0.094453   \nEdges_Index             -0.420367    -0.383782    -0.373661   \nEmpty_Index              0.379479     0.421585     0.360459   \nSquare_Index            -0.234846    -0.111598    -0.322514   \nOutside_X_Index          0.811960     0.898341     0.598918   \nEdges_X_Index           -0.462665    -0.207693    -0.651384   \nEdges_Y_Index           -0.713607    -0.851813    -0.464314   \nOutside_Global_Index    -0.168963    -0.436422     0.127741   \nLogOfAreas               1.000000     0.888239     0.879228   \nLog_X_Index              0.888239     1.000000     0.667899   \nLog_Y_Index              0.879228     0.667899     1.000000   \nOrientation_Index       -0.214866    -0.520981     0.144861   \nLuminosity_Index        -0.133567    -0.058458    -0.157437   \nSigmoidOfAreas           0.872453     0.748741     0.852450   \n\n                       Orientation_Index  Luminosity_Index  SigmoidOfAreas  \nX_Minimum                       0.276871         -0.068844       -0.376973  \nX_Maximum                       0.237157         -0.079235       -0.319598  \nY_Minimum                      -0.044202         -0.023000       -0.031511  \nY_Maximum                      -0.042490         -0.022869       -0.030345  \nPixels_Areas                   -0.269013         -0.015081        0.542672  \nX_Perimeter                    -0.234969          0.005212        0.561256  \nY_Perimeter                    -0.113968         -0.005650        0.608167  \nSum_of_Luminosity              -0.234625         -0.013845        0.520282  \nMinimum_of_Luminosity           0.179385          0.619174       -0.504692  \nMaximum_of_Luminosity          -0.113531          0.853856        0.018501  \nLength_of_Conveyer              0.180770         -0.210456       -0.260468  \nTypeOfSteel_A300                0.065726         -0.215409       -0.346852  \nTypeOfSteel_A400               -0.065357          0.214970        0.344353  \nSteel_Plate_Thickness           0.240923         -0.102066       -0.125354  \nEdges_Index                     0.080225          0.213547       -0.350934  \nEmpty_Index                    -0.179199          0.085117        0.480116  \nSquare_Index                   -0.209706          0.082997       -0.361511  \nOutside_X_Index                -0.467688         -0.050740        0.609049  \nEdges_X_Index                  -0.412696          0.072659       -0.538678  \nEdges_Y_Index                   0.607271         -0.053778       -0.594737  \nOutside_Global_Index            0.863987         -0.115506       -0.105986  \nLogOfAreas                     -0.214866         -0.133567        0.872453  \nLog_X_Index                    -0.520981         -0.058458        0.748741  \nLog_Y_Index                     0.144861         -0.157437        0.852450  \nOrientation_Index               1.000000         -0.104336       -0.089470  \nLuminosity_Index               -0.104336          1.000000       -0.119099  \nSigmoidOfAreas                 -0.089470         -0.119099        1.000000  \n\n[27 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X_Minimum</th>\n      <th>X_Maximum</th>\n      <th>Y_Minimum</th>\n      <th>Y_Maximum</th>\n      <th>Pixels_Areas</th>\n      <th>X_Perimeter</th>\n      <th>Y_Perimeter</th>\n      <th>Sum_of_Luminosity</th>\n      <th>Minimum_of_Luminosity</th>\n      <th>Maximum_of_Luminosity</th>\n      <th>...</th>\n      <th>Outside_X_Index</th>\n      <th>Edges_X_Index</th>\n      <th>Edges_Y_Index</th>\n      <th>Outside_Global_Index</th>\n      <th>LogOfAreas</th>\n      <th>Log_X_Index</th>\n      <th>Log_Y_Index</th>\n      <th>Orientation_Index</th>\n      <th>Luminosity_Index</th>\n      <th>SigmoidOfAreas</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>X_Minimum</th>\n      <td>1.000000</td>\n      <td>0.989767</td>\n      <td>0.016071</td>\n      <td>0.014247</td>\n      <td>-0.464759</td>\n      <td>-0.451961</td>\n      <td>-0.426514</td>\n      <td>-0.430073</td>\n      <td>0.337748</td>\n      <td>-0.132955</td>\n      <td>...</td>\n      <td>-0.522112</td>\n      <td>0.112746</td>\n      <td>0.460421</td>\n      <td>0.222109</td>\n      <td>-0.505024</td>\n      <td>-0.530728</td>\n      <td>-0.375324</td>\n      <td>0.276871</td>\n      <td>-0.068844</td>\n      <td>-0.376973</td>\n    </tr>\n    <tr>\n      <th>X_Maximum</th>\n      <td>0.989767</td>\n      <td>1.000000</td>\n      <td>0.018909</td>\n      <td>0.016513</td>\n      <td>-0.391937</td>\n      <td>-0.378434</td>\n      <td>-0.356528</td>\n      <td>-0.363092</td>\n      <td>0.275571</td>\n      <td>-0.129669</td>\n      <td>...</td>\n      <td>-0.432545</td>\n      <td>0.095799</td>\n      <td>0.391743</td>\n      <td>0.190474</td>\n      <td>-0.428875</td>\n      <td>-0.448348</td>\n      <td>-0.316770</td>\n      <td>0.237157</td>\n      <td>-0.079235</td>\n      <td>-0.319598</td>\n    </tr>\n    <tr>\n      <th>Y_Minimum</th>\n      <td>0.016071</td>\n      <td>0.018909</td>\n      <td>1.000000</td>\n      <td>0.969552</td>\n      <td>-0.007370</td>\n      <td>-0.012712</td>\n      <td>-0.024876</td>\n      <td>-0.008189</td>\n      <td>-0.017321</td>\n      <td>-0.029160</td>\n      <td>...</td>\n      <td>0.019685</td>\n      <td>0.052710</td>\n      <td>-0.002647</td>\n      <td>-0.025374</td>\n      <td>-0.001754</td>\n      <td>0.015116</td>\n      <td>-0.023702</td>\n      <td>-0.044202</td>\n      <td>-0.023000</td>\n      <td>-0.031511</td>\n    </tr>\n    <tr>\n      <th>Y_Maximum</th>\n      <td>0.014247</td>\n      <td>0.016513</td>\n      <td>0.969552</td>\n      <td>1.000000</td>\n      <td>-0.007019</td>\n      <td>-0.012377</td>\n      <td>-0.024798</td>\n      <td>-0.007809</td>\n      <td>-0.018739</td>\n      <td>-0.028312</td>\n      <td>...</td>\n      <td>0.017271</td>\n      <td>0.051546</td>\n      <td>-0.001382</td>\n      <td>-0.023285</td>\n      <td>-0.000995</td>\n      <td>0.015624</td>\n      <td>-0.022941</td>\n      <td>-0.042490</td>\n      <td>-0.022869</td>\n      <td>-0.030345</td>\n    </tr>\n    <tr>\n      <th>Pixels_Areas</th>\n      <td>-0.464759</td>\n      <td>-0.391937</td>\n      <td>-0.007370</td>\n      <td>-0.007019</td>\n      <td>1.000000</td>\n      <td>0.835079</td>\n      <td>0.834543</td>\n      <td>0.797843</td>\n      <td>-0.622867</td>\n      <td>0.130499</td>\n      <td>...</td>\n      <td>0.764810</td>\n      <td>-0.303335</td>\n      <td>-0.650704</td>\n      <td>-0.205579</td>\n      <td>0.774580</td>\n      <td>0.749731</td>\n      <td>0.640033</td>\n      <td>-0.269013</td>\n      <td>-0.015081</td>\n      <td>0.542672</td>\n    </tr>\n    <tr>\n      <th>X_Perimeter</th>\n      <td>-0.451961</td>\n      <td>-0.378434</td>\n      <td>-0.012712</td>\n      <td>-0.012377</td>\n      <td>0.835079</td>\n      <td>1.000000</td>\n      <td>0.912579</td>\n      <td>0.802072</td>\n      <td>-0.603891</td>\n      <td>0.158036</td>\n      <td>...</td>\n      <td>0.752470</td>\n      <td>-0.378672</td>\n      <td>-0.664781</td>\n      <td>-0.174615</td>\n      <td>0.771546</td>\n      <td>0.750418</td>\n      <td>0.667441</td>\n      <td>-0.234969</td>\n      <td>0.005212</td>\n      <td>0.561256</td>\n    </tr>\n    <tr>\n      <th>Y_Perimeter</th>\n      <td>-0.426514</td>\n      <td>-0.356528</td>\n      <td>-0.024876</td>\n      <td>-0.024798</td>\n      <td>0.834543</td>\n      <td>0.912579</td>\n      <td>1.000000</td>\n      <td>0.809171</td>\n      <td>-0.602826</td>\n      <td>0.160831</td>\n      <td>...</td>\n      <td>0.700036</td>\n      <td>-0.469092</td>\n      <td>-0.612157</td>\n      <td>-0.081225</td>\n      <td>0.790863</td>\n      <td>0.705657</td>\n      <td>0.761117</td>\n      <td>-0.113968</td>\n      <td>-0.005650</td>\n      <td>0.608167</td>\n    </tr>\n    <tr>\n      <th>Sum_of_Luminosity</th>\n      <td>-0.430073</td>\n      <td>-0.363092</td>\n      <td>-0.008189</td>\n      <td>-0.007809</td>\n      <td>0.797843</td>\n      <td>0.802072</td>\n      <td>0.809171</td>\n      <td>1.000000</td>\n      <td>-0.580857</td>\n      <td>0.128569</td>\n      <td>...</td>\n      <td>0.703912</td>\n      <td>-0.315125</td>\n      <td>-0.608297</td>\n      <td>-0.177048</td>\n      <td>0.726483</td>\n      <td>0.698035</td>\n      <td>0.615651</td>\n      <td>-0.234625</td>\n      <td>-0.013845</td>\n      <td>0.520282</td>\n    </tr>\n    <tr>\n      <th>Minimum_of_Luminosity</th>\n      <td>0.337748</td>\n      <td>0.275571</td>\n      <td>-0.017321</td>\n      <td>-0.018739</td>\n      <td>-0.622867</td>\n      <td>-0.603891</td>\n      <td>-0.602826</td>\n      <td>-0.580857</td>\n      <td>1.000000</td>\n      <td>0.397265</td>\n      <td>...</td>\n      <td>-0.638549</td>\n      <td>0.234592</td>\n      <td>0.467841</td>\n      <td>0.112480</td>\n      <td>-0.691406</td>\n      <td>-0.637711</td>\n      <td>-0.585194</td>\n      <td>0.179385</td>\n      <td>0.619174</td>\n      <td>-0.504692</td>\n    </tr>\n    <tr>\n      <th>Maximum_of_Luminosity</th>\n      <td>-0.132955</td>\n      <td>-0.129669</td>\n      <td>-0.029160</td>\n      <td>-0.028312</td>\n      <td>0.130499</td>\n      <td>0.158036</td>\n      <td>0.160831</td>\n      <td>0.128569</td>\n      <td>0.397265</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.074610</td>\n      <td>-0.014785</td>\n      <td>-0.153276</td>\n      <td>-0.120083</td>\n      <td>0.033191</td>\n      <td>0.079426</td>\n      <td>0.004650</td>\n      <td>-0.113531</td>\n      <td>0.853856</td>\n      <td>0.018501</td>\n    </tr>\n    <tr>\n      <th>Length_of_Conveyer</th>\n      <td>0.308740</td>\n      <td>0.293466</td>\n      <td>0.016586</td>\n      <td>0.015735</td>\n      <td>-0.208256</td>\n      <td>-0.206060</td>\n      <td>-0.188716</td>\n      <td>-0.194282</td>\n      <td>0.018612</td>\n      <td>-0.181411</td>\n      <td>...</td>\n      <td>-0.272466</td>\n      <td>0.110726</td>\n      <td>0.296749</td>\n      <td>0.182721</td>\n      <td>-0.254979</td>\n      <td>-0.287967</td>\n      <td>-0.195315</td>\n      <td>0.180770</td>\n      <td>-0.210456</td>\n      <td>-0.260468</td>\n    </tr>\n    <tr>\n      <th>TypeOfSteel_A300</th>\n      <td>0.220151</td>\n      <td>0.189802</td>\n      <td>0.044781</td>\n      <td>0.044867</td>\n      <td>-0.304635</td>\n      <td>-0.300883</td>\n      <td>-0.304057</td>\n      <td>-0.282051</td>\n      <td>0.103835</td>\n      <td>-0.221093</td>\n      <td>...</td>\n      <td>-0.333026</td>\n      <td>0.198026</td>\n      <td>0.286424</td>\n      <td>0.062285</td>\n      <td>-0.362923</td>\n      <td>-0.321869</td>\n      <td>-0.334782</td>\n      <td>0.065726</td>\n      <td>-0.215409</td>\n      <td>-0.346852</td>\n    </tr>\n    <tr>\n      <th>TypeOfSteel_A400</th>\n      <td>-0.218122</td>\n      <td>-0.188033</td>\n      <td>-0.044328</td>\n      <td>-0.044422</td>\n      <td>0.300308</td>\n      <td>0.296467</td>\n      <td>0.299557</td>\n      <td>0.278000</td>\n      <td>-0.100916</td>\n      <td>0.220088</td>\n      <td>...</td>\n      <td>0.329806</td>\n      <td>-0.196268</td>\n      <td>-0.283340</td>\n      <td>-0.061767</td>\n      <td>0.359392</td>\n      <td>0.318857</td>\n      <td>0.331959</td>\n      <td>-0.065357</td>\n      <td>0.214970</td>\n      <td>0.344353</td>\n    </tr>\n    <tr>\n      <th>Steel_Plate_Thickness</th>\n      <td>0.188764</td>\n      <td>0.164789</td>\n      <td>-0.054389</td>\n      <td>-0.058683</td>\n      <td>-0.232467</td>\n      <td>-0.225757</td>\n      <td>-0.189628</td>\n      <td>-0.215082</td>\n      <td>0.133881</td>\n      <td>-0.113917</td>\n      <td>...</td>\n      <td>-0.270063</td>\n      <td>-0.036774</td>\n      <td>0.255632</td>\n      <td>0.200674</td>\n      <td>-0.202286</td>\n      <td>-0.267696</td>\n      <td>-0.094453</td>\n      <td>0.240923</td>\n      <td>-0.102066</td>\n      <td>-0.125354</td>\n    </tr>\n    <tr>\n      <th>Edges_Index</th>\n      <td>0.167358</td>\n      <td>0.129800</td>\n      <td>0.035762</td>\n      <td>0.034222</td>\n      <td>-0.337258</td>\n      <td>-0.326388</td>\n      <td>-0.320950</td>\n      <td>-0.309055</td>\n      <td>0.397904</td>\n      <td>0.153931</td>\n      <td>...</td>\n      <td>-0.362471</td>\n      <td>0.224152</td>\n      <td>0.313508</td>\n      <td>0.048415</td>\n      <td>-0.420367</td>\n      <td>-0.383782</td>\n      <td>-0.373661</td>\n      <td>0.080225</td>\n      <td>0.213547</td>\n      <td>-0.350934</td>\n    </tr>\n    <tr>\n      <th>Empty_Index</th>\n      <td>-0.175624</td>\n      <td>-0.146167</td>\n      <td>-0.033792</td>\n      <td>-0.032824</td>\n      <td>0.269263</td>\n      <td>0.322417</td>\n      <td>0.338079</td>\n      <td>0.271448</td>\n      <td>-0.096133</td>\n      <td>0.108878</td>\n      <td>...</td>\n      <td>0.293223</td>\n      <td>-0.323494</td>\n      <td>-0.465523</td>\n      <td>-0.205664</td>\n      <td>0.379479</td>\n      <td>0.421585</td>\n      <td>0.360459</td>\n      <td>-0.179199</td>\n      <td>0.085117</td>\n      <td>0.480116</td>\n    </tr>\n    <tr>\n      <th>Square_Index</th>\n      <td>0.045635</td>\n      <td>0.035124</td>\n      <td>0.033952</td>\n      <td>0.034552</td>\n      <td>0.024658</td>\n      <td>0.050052</td>\n      <td>0.003372</td>\n      <td>0.031948</td>\n      <td>0.062940</td>\n      <td>0.061480</td>\n      <td>...</td>\n      <td>-0.098957</td>\n      <td>0.299610</td>\n      <td>0.083152</td>\n      <td>-0.099019</td>\n      <td>-0.234846</td>\n      <td>-0.111598</td>\n      <td>-0.322514</td>\n      <td>-0.209706</td>\n      <td>0.082997</td>\n      <td>-0.361511</td>\n    </tr>\n    <tr>\n      <th>Outside_X_Index</th>\n      <td>-0.522112</td>\n      <td>-0.432545</td>\n      <td>0.019685</td>\n      <td>0.017271</td>\n      <td>0.764810</td>\n      <td>0.752470</td>\n      <td>0.700036</td>\n      <td>0.703912</td>\n      <td>-0.638549</td>\n      <td>0.074610</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>-0.156802</td>\n      <td>-0.760021</td>\n      <td>-0.382777</td>\n      <td>0.811960</td>\n      <td>0.898341</td>\n      <td>0.598918</td>\n      <td>-0.467688</td>\n      <td>-0.050740</td>\n      <td>0.609049</td>\n    </tr>\n    <tr>\n      <th>Edges_X_Index</th>\n      <td>0.112746</td>\n      <td>0.095799</td>\n      <td>0.052710</td>\n      <td>0.051546</td>\n      <td>-0.303335</td>\n      <td>-0.378672</td>\n      <td>-0.469092</td>\n      <td>-0.315125</td>\n      <td>0.234592</td>\n      <td>-0.014785</td>\n      <td>...</td>\n      <td>-0.156802</td>\n      <td>1.000000</td>\n      <td>0.136147</td>\n      <td>-0.336322</td>\n      <td>-0.462665</td>\n      <td>-0.207693</td>\n      <td>-0.651384</td>\n      <td>-0.412696</td>\n      <td>0.072659</td>\n      <td>-0.538678</td>\n    </tr>\n    <tr>\n      <th>Edges_Y_Index</th>\n      <td>0.460421</td>\n      <td>0.391743</td>\n      <td>-0.002647</td>\n      <td>-0.001382</td>\n      <td>-0.650704</td>\n      <td>-0.664781</td>\n      <td>-0.612157</td>\n      <td>-0.608297</td>\n      <td>0.467841</td>\n      <td>-0.153276</td>\n      <td>...</td>\n      <td>-0.760021</td>\n      <td>0.136147</td>\n      <td>1.000000</td>\n      <td>0.529914</td>\n      <td>-0.713607</td>\n      <td>-0.851813</td>\n      <td>-0.464314</td>\n      <td>0.607271</td>\n      <td>-0.053778</td>\n      <td>-0.594737</td>\n    </tr>\n    <tr>\n      <th>Outside_Global_Index</th>\n      <td>0.222109</td>\n      <td>0.190474</td>\n      <td>-0.025374</td>\n      <td>-0.023285</td>\n      <td>-0.205579</td>\n      <td>-0.174615</td>\n      <td>-0.081225</td>\n      <td>-0.177048</td>\n      <td>0.112480</td>\n      <td>-0.120083</td>\n      <td>...</td>\n      <td>-0.382777</td>\n      <td>-0.336322</td>\n      <td>0.529914</td>\n      <td>1.000000</td>\n      <td>-0.168963</td>\n      <td>-0.436422</td>\n      <td>0.127741</td>\n      <td>0.863987</td>\n      <td>-0.115506</td>\n      <td>-0.105986</td>\n    </tr>\n    <tr>\n      <th>LogOfAreas</th>\n      <td>-0.505024</td>\n      <td>-0.428875</td>\n      <td>-0.001754</td>\n      <td>-0.000995</td>\n      <td>0.774580</td>\n      <td>0.771546</td>\n      <td>0.790863</td>\n      <td>0.726483</td>\n      <td>-0.691406</td>\n      <td>0.033191</td>\n      <td>...</td>\n      <td>0.811960</td>\n      <td>-0.462665</td>\n      <td>-0.713607</td>\n      <td>-0.168963</td>\n      <td>1.000000</td>\n      <td>0.888239</td>\n      <td>0.879228</td>\n      <td>-0.214866</td>\n      <td>-0.133567</td>\n      <td>0.872453</td>\n    </tr>\n    <tr>\n      <th>Log_X_Index</th>\n      <td>-0.530728</td>\n      <td>-0.448348</td>\n      <td>0.015116</td>\n      <td>0.015624</td>\n      <td>0.749731</td>\n      <td>0.750418</td>\n      <td>0.705657</td>\n      <td>0.698035</td>\n      <td>-0.637711</td>\n      <td>0.079426</td>\n      <td>...</td>\n      <td>0.898341</td>\n      <td>-0.207693</td>\n      <td>-0.851813</td>\n      <td>-0.436422</td>\n      <td>0.888239</td>\n      <td>1.000000</td>\n      <td>0.667899</td>\n      <td>-0.520981</td>\n      <td>-0.058458</td>\n      <td>0.748741</td>\n    </tr>\n    <tr>\n      <th>Log_Y_Index</th>\n      <td>-0.375324</td>\n      <td>-0.316770</td>\n      <td>-0.023702</td>\n      <td>-0.022941</td>\n      <td>0.640033</td>\n      <td>0.667441</td>\n      <td>0.761117</td>\n      <td>0.615651</td>\n      <td>-0.585194</td>\n      <td>0.004650</td>\n      <td>...</td>\n      <td>0.598918</td>\n      <td>-0.651384</td>\n      <td>-0.464314</td>\n      <td>0.127741</td>\n      <td>0.879228</td>\n      <td>0.667899</td>\n      <td>1.000000</td>\n      <td>0.144861</td>\n      <td>-0.157437</td>\n      <td>0.852450</td>\n    </tr>\n    <tr>\n      <th>Orientation_Index</th>\n      <td>0.276871</td>\n      <td>0.237157</td>\n      <td>-0.044202</td>\n      <td>-0.042490</td>\n      <td>-0.269013</td>\n      <td>-0.234969</td>\n      <td>-0.113968</td>\n      <td>-0.234625</td>\n      <td>0.179385</td>\n      <td>-0.113531</td>\n      <td>...</td>\n      <td>-0.467688</td>\n      <td>-0.412696</td>\n      <td>0.607271</td>\n      <td>0.863987</td>\n      <td>-0.214866</td>\n      <td>-0.520981</td>\n      <td>0.144861</td>\n      <td>1.000000</td>\n      <td>-0.104336</td>\n      <td>-0.089470</td>\n    </tr>\n    <tr>\n      <th>Luminosity_Index</th>\n      <td>-0.068844</td>\n      <td>-0.079235</td>\n      <td>-0.023000</td>\n      <td>-0.022869</td>\n      <td>-0.015081</td>\n      <td>0.005212</td>\n      <td>-0.005650</td>\n      <td>-0.013845</td>\n      <td>0.619174</td>\n      <td>0.853856</td>\n      <td>...</td>\n      <td>-0.050740</td>\n      <td>0.072659</td>\n      <td>-0.053778</td>\n      <td>-0.115506</td>\n      <td>-0.133567</td>\n      <td>-0.058458</td>\n      <td>-0.157437</td>\n      <td>-0.104336</td>\n      <td>1.000000</td>\n      <td>-0.119099</td>\n    </tr>\n    <tr>\n      <th>SigmoidOfAreas</th>\n      <td>-0.376973</td>\n      <td>-0.319598</td>\n      <td>-0.031511</td>\n      <td>-0.030345</td>\n      <td>0.542672</td>\n      <td>0.561256</td>\n      <td>0.608167</td>\n      <td>0.520282</td>\n      <td>-0.504692</td>\n      <td>0.018501</td>\n      <td>...</td>\n      <td>0.609049</td>\n      <td>-0.538678</td>\n      <td>-0.594737</td>\n      <td>-0.105986</td>\n      <td>0.872453</td>\n      <td>0.748741</td>\n      <td>0.852450</td>\n      <td>-0.089470</td>\n      <td>-0.119099</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>27 rows × 27 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.corr()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T16:45:28.673241800Z",
     "start_time": "2024-03-31T16:45:28.610522300Z"
    }
   },
   "id": "6e3771ab81f9ec7"
  },
  {
   "cell_type": "code",
   "source": [
    "X['col_1'] = np.sqrt(X['Pixels_Areas'])\n",
    "X['col_2'] = np.exp(X['LogOfAreas'])\n",
    "X['col_2_1'] = np.exp(X['Log_X_Index'])\n",
    "X['col_2_2'] = np.exp(X['Log_Y_Index'])\n",
    "X['col_3'] = X['X_Perimeter'] / X['Y_Perimeter']\n",
    "X['col_4'] = (X['X_Maximum'] - X['X_Minimum']) * (X['Y_Maximum'] - X['Y_Minimum'])\n",
    "X['col_4_1'] = np.abs(X['X_Maximum'] - X['X_Minimum'])\n",
    "X['col_4_2'] = np.abs(X['Y_Maximum'] - X['Y_Minimum'])\n",
    "X['col_4_3'] = np.log1p(np.abs(X['X_Maximum'] - X['X_Minimum']))\n",
    "X['col_4_4'] = np.log1p(np.abs(X['Y_Maximum'] - X['Y_Minimum']))\n",
    "X[['col_5', 'col_51']] = np.exp(X[['Log_X_Index', 'Log_Y_Index']])\n",
    "\n",
    "_, bins_1 = pd.qcut(X['LogOfAreas'], q=10, retbins=True, duplicates='drop')\n",
    "_, bins_2 = pd.qcut(X['Pixels_Areas'], q=10, retbins=True, duplicates='drop')\n",
    "_, bins_3 = pd.qcut(X['Sum_of_Luminosity'], q=10, retbins=True, duplicates='drop')\n",
    "_, bins_4 = pd.qcut(X['Steel_Plate_Thickness'], q=10, retbins=True, duplicates='drop')\n",
    "_, bins_5 = pd.qcut(X['Length_of_Conveyer'], q=10, retbins=True, duplicates='drop')\n",
    "\n",
    "X['col_6'] = pd.cut(X['LogOfAreas'], bins_1, labels=False, include_lowest=True)\n",
    "X['col_7'] = pd.cut(X['Pixels_Areas'], bins_2, labels=False, include_lowest=True)\n",
    "X['col_8'] = pd.cut(X['Sum_of_Luminosity'], bins_3, labels=False, include_lowest=True)\n",
    "X['col_9'] = pd.cut(X['Steel_Plate_Thickness'], bins_4, labels=False, include_lowest=True)\n",
    "X['col_10'] = pd.cut(X['Length_of_Conveyer'], bins_5, labels=False, include_lowest=True)\n",
    "\n",
    "X['col_11'] = X['X_Minimum'] / X['X_Maximum']\n",
    "X['col_12'] = X['Y_Minimum'] / X['Y_Maximum']\n",
    "X['col_13'] = X['Sum_of_Luminosity'] / X['Pixels_Areas']\n",
    "X['col_14'] = X['Minimum_of_Luminosity'] / X['Maximum_of_Luminosity']\n",
    "X['col_15'] = X['X_Perimeter'] / X['Y_Perimeter']\n",
    "\n",
    "X['col_16'] = np.cos(np.exp(X['LogOfAreas']))\n",
    "X['col_17'] = X['Maximum_of_Luminosity'] - X['Minimum_of_Luminosity']\n",
    "X['col_18'] = np.log1p(X['Sum_of_Luminosity'])\n",
    "X['col_19'] = np.log1p(X['Length_of_Conveyer'])\n",
    "X['col_20'] = np.log1p(X['Steel_Plate_Thickness'])\n",
    "\n",
    "X['col_21'] = (X['Outside_Global_Index'] - X['Edges_Y_Index']) / (X['Outside_X_Index'] * X['Log_X_Index'] ** 2)\n",
    "X['col_22'] = X['Steel_Plate_Thickness'] / X['Length_of_Conveyer']\n",
    "X['col_23'] = X['Steel_Plate_Thickness'] / X['Edges_Y_Index'] * X['Outside_X_Index']\n",
    "X['col_24'] = (X['Log_X_Index'] * X['LogOfAreas']) / X['Edges_Y_Index']\n",
    "X['col_25'] = X['Pixels_Areas'] / (X['X_Perimeter'] + X['Y_Perimeter'])\n",
    "X['col_26'] = (X['Pixels_Areas'] / (X['Y_Perimeter'] * X['Edges_Y_Index'])) / (\n",
    "        X['Sum_of_Luminosity'] - X['Minimum_of_Luminosity'])"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:15:12.706813Z",
     "iopub.execute_input": "2024-03-28T12:15:12.707206Z",
     "iopub.status.idle": "2024-03-28T12:15:12.807819Z",
     "shell.execute_reply.started": "2024-03-28T12:15:12.707176Z",
     "shell.execute_reply": "2024-03-28T12:15:12.807056Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:18:29.313511600Z",
     "start_time": "2024-03-31T20:18:29.267581100Z"
    }
   },
   "execution_count": 108,
   "outputs": [],
   "id": "d97101f97e09a204"
  },
  {
   "cell_type": "code",
   "source": [
    "# test dataset\n",
    "test['col_1'] = np.sqrt(test['Pixels_Areas'])\n",
    "test['col_2'] = np.exp(test['LogOfAreas'])\n",
    "test['col_2_1'] = np.exp(test['Log_X_Index'])\n",
    "test['col_2_2'] = np.exp(test['Log_Y_Index'])\n",
    "test['col_3'] = test['X_Perimeter'] / test['Y_Perimeter']\n",
    "test['col_4'] = (test['X_Maximum'] - test['X_Minimum']) * (test['Y_Maximum'] - test['Y_Minimum'])\n",
    "test['col_4_1'] = np.abs(test['X_Maximum'] - test['X_Minimum'])\n",
    "test['col_4_2'] = np.abs(test['Y_Maximum'] - test['Y_Minimum'])\n",
    "test['col_4_3'] = np.log1p(np.abs(test['X_Maximum'] - test['X_Minimum']))\n",
    "test['col_4_4'] = np.log1p(np.abs(test['Y_Maximum'] - test['Y_Minimum']))\n",
    "test[['col_5', 'col_51']] = np.exp(test[['Log_X_Index', 'Log_Y_Index']])\n",
    "\n",
    "test['col_6'] = pd.cut(test['LogOfAreas'], bins_1, labels=False, include_lowest=True)\n",
    "test['col_7'] = pd.cut(test['Pixels_Areas'], bins_2, labels=False, include_lowest=True)\n",
    "test['col_8'] = pd.cut(test['Sum_of_Luminosity'], bins_3, labels=False, include_lowest=True)\n",
    "test['col_9'] = pd.cut(test['Steel_Plate_Thickness'], bins_4, labels=False, include_lowest=True)\n",
    "test['col_10'] = pd.cut(test['Length_of_Conveyer'], bins_5, labels=False, include_lowest=True)\n",
    "\n",
    "test['col_11'] = test['X_Minimum'] / test['X_Maximum']\n",
    "test['col_12'] = test['Y_Minimum'] / test['Y_Maximum']\n",
    "test['col_13'] = test['Sum_of_Luminosity'] / test['Pixels_Areas']\n",
    "test['col_14'] = test['Minimum_of_Luminosity'] / test['Maximum_of_Luminosity']\n",
    "test['col_15'] = test['X_Perimeter'] / test['Y_Perimeter']\n",
    "\n",
    "test['col_16'] = np.cos(np.exp(test['LogOfAreas']))\n",
    "test['col_17'] = test['Maximum_of_Luminosity'] - test['Minimum_of_Luminosity']\n",
    "test['col_18'] = np.log1p(test['Sum_of_Luminosity'])\n",
    "test['col_19'] = np.log1p(test['Length_of_Conveyer'])\n",
    "test['col_20'] = np.log1p(test['Steel_Plate_Thickness'])\n",
    "\n",
    "test['col_21'] = (test['Outside_Global_Index'] - test['Edges_Y_Index']) / (\n",
    "        test['Outside_X_Index'] * test['Log_X_Index'] ** 2)\n",
    "test['col_22'] = test['Steel_Plate_Thickness'] / test['Length_of_Conveyer']\n",
    "test['col_23'] = test['Steel_Plate_Thickness'] / test['Edges_Y_Index'] * test['Outside_X_Index']\n",
    "test['col_24'] = (test['Log_X_Index'] * test['LogOfAreas']) / test['Edges_Y_Index']\n",
    "test['col_25'] = test['Pixels_Areas'] / (test['X_Perimeter'] + test['Y_Perimeter']) * test['Edges_Y_Index']\n",
    "test['col_26'] = (test['Pixels_Areas'] / (test['Y_Perimeter'] * test['Edges_Y_Index'])) / (\n",
    "        test['Sum_of_Luminosity'] - test['Minimum_of_Luminosity'])"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:15:13.218697Z",
     "iopub.execute_input": "2024-03-28T12:15:13.219097Z",
     "iopub.status.idle": "2024-03-28T12:15:13.285672Z",
     "shell.execute_reply.started": "2024-03-28T12:15:13.219066Z",
     "shell.execute_reply": "2024-03-28T12:15:13.284773Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:18:30.482926900Z",
     "start_time": "2024-03-31T20:18:30.462825400Z"
    }
   },
   "execution_count": 109,
   "outputs": [],
   "id": "61457b72e32b48d8"
  },
  {
   "cell_type": "code",
   "source": [
    "test = test.fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:15:14.390209Z",
     "iopub.execute_input": "2024-03-28T12:15:14.390905Z",
     "iopub.status.idle": "2024-03-28T12:15:14.405494Z",
     "shell.execute_reply.started": "2024-03-28T12:15:14.390871Z",
     "shell.execute_reply": "2024-03-28T12:15:14.404671Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:18:31.349137Z",
     "start_time": "2024-03-31T20:18:31.337684200Z"
    }
   },
   "execution_count": 110,
   "outputs": [],
   "id": "6313fad2c40f7e63"
  },
  {
   "cell_type": "code",
   "source": [
    "X.shape, test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:15:14.932875Z",
     "iopub.execute_input": "2024-03-28T12:15:14.933716Z",
     "iopub.status.idle": "2024-03-28T12:15:14.939586Z",
     "shell.execute_reply.started": "2024-03-28T12:15:14.933683Z",
     "shell.execute_reply": "2024-03-28T12:15:14.938615Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:18:32.125320500Z",
     "start_time": "2024-03-31T20:18:32.106943600Z"
    }
   },
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "((19219, 60), (12814, 60))"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "id": "6a8ad2f460959e72"
  },
  {
   "cell_type": "code",
   "source": [
    "pd.Series(ss.kurtosis(X), index=X.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:15:16.538998Z",
     "iopub.execute_input": "2024-03-28T12:15:16.539386Z",
     "iopub.status.idle": "2024-03-28T12:15:16.585151Z",
     "shell.execute_reply.started": "2024-03-28T12:15:16.539358Z",
     "shell.execute_reply": "2024-03-28T12:15:16.584208Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:18:33.648363700Z",
     "start_time": "2024-03-31T20:18:33.607907Z"
    }
   },
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "X_Minimum                   -1.327648\nX_Maximum                   -1.257175\nY_Minimum                    8.865337\nY_Maximum                    8.839496\nPixels_Areas               181.689607\nX_Perimeter                167.364618\nY_Perimeter                  9.289275\nSum_of_Luminosity          121.178595\nMinimum_of_Luminosity       -0.003005\nMaximum_of_Luminosity        9.781119\nLength_of_Conveyer          -1.214170\nTypeOfSteel_A300            -1.842475\nTypeOfSteel_A400            -1.845782\nSteel_Plate_Thickness        5.757569\nEdges_Index                 -1.206891\nEmpty_Index                 -0.174450\nSquare_Index                -1.154852\nOutside_X_Index             20.005039\nEdges_X_Index               -0.779575\nEdges_Y_Index               -0.561567\nOutside_Global_Index        -1.819354\nLogOfAreas                  -0.253556\nLog_X_Index                 -0.064777\nLog_Y_Index                 -0.173621\nOrientation_Index           -1.093678\nLuminosity_Index             6.899609\nSigmoidOfAreas              -1.637538\ncol_1                        3.607200\ncol_2                        1.733053\ncol_2_1                      1.447408\ncol_2_2                     27.279967\ncol_3                      494.542567\ncol_4                     3046.381179\ncol_4_1                     67.202902\ncol_4_2                    340.462945\ncol_4_3                      0.116616\ncol_4_4                     22.010224\ncol_5                        1.447408\ncol_51                      27.279967\ncol_6                       -1.235557\ncol_7                       -1.236198\ncol_8                       -1.224468\ncol_9                       -0.752388\ncol_10                      -1.389386\ncol_11                   13728.634414\ncol_12                     918.375310\ncol_13                     977.175048\ncol_14                      -0.162323\ncol_15                     494.542567\ncol_16                      -1.507958\ncol_17                       1.104294\ncol_18                      -0.223669\ncol_19                      -1.225692\ncol_20                       0.601207\ncol_21                    1506.905019\ncol_22                       6.037107\ncol_23                    4200.415083\ncol_24                       9.348244\ncol_25                    2245.527037\ncol_26                    3641.620968\ndtype: float64"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "id": "345050b4e4522762"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "test['col_7'] = test['col_7'].astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:18:35.928680300Z",
     "start_time": "2024-03-31T20:18:35.925367700Z"
    }
   },
   "id": "93383f4df94daaa3"
  },
  {
   "cell_type": "code",
   "source": [
    "# cap_cols = []\n",
    "# \n",
    "# for c in X.columns:\n",
    "#     if c not in ['col_6', 'col_7', 'col_8', 'col_9', 'col_10', 'TypeOfSteel_A300', 'TypeOfSteel_A400']:\n",
    "#         cap_cols.append(c)\n",
    "# \n",
    "# capper = Winsorizer(capping_method='iqr')\n",
    "# capper.fit(X[cap_cols])"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:15:18.049290Z",
     "iopub.execute_input": "2024-03-28T12:15:18.050140Z",
     "iopub.status.idle": "2024-03-28T12:15:18.133693Z",
     "shell.execute_reply.started": "2024-03-28T12:15:18.050110Z",
     "shell.execute_reply": "2024-03-28T12:15:18.132663Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:04:31.350049500Z",
     "start_time": "2024-03-31T14:04:31.340671900Z"
    }
   },
   "execution_count": 17,
   "outputs": [],
   "id": "47463f477457d5fb"
  },
  {
   "cell_type": "code",
   "source": [
    "# X.loc[:, cap_cols] = capper.transform(X[cap_cols])\n",
    "# test.loc[:, cap_cols] = capper.transform(test[cap_cols])"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:15:19.558065Z",
     "iopub.execute_input": "2024-03-28T12:15:19.558411Z",
     "iopub.status.idle": "2024-03-28T12:15:19.774900Z",
     "shell.execute_reply.started": "2024-03-28T12:15:19.558385Z",
     "shell.execute_reply": "2024-03-28T12:15:19.774071Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:04:31.783441Z",
     "start_time": "2024-03-31T14:04:31.776281Z"
    }
   },
   "execution_count": 18,
   "outputs": [],
   "id": "3c2d5975f90c857"
  },
  {
   "cell_type": "code",
   "source": [
    "# scalable_cols = []\n",
    "# \n",
    "# for c in X.columns:\n",
    "#     if c not in ['col_6', 'col_7', 'col_8', 'col_9', 'col_10', 'TypeOfSteel_A300', 'TypeOfSteel_A400']:\n",
    "#         scalable_cols.append(c)\n",
    "# \n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(X[scalable_cols])"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:15:20.307651Z",
     "iopub.execute_input": "2024-03-28T12:15:20.308037Z",
     "iopub.status.idle": "2024-03-28T12:15:20.331631Z",
     "shell.execute_reply.started": "2024-03-28T12:15:20.307996Z",
     "shell.execute_reply": "2024-03-28T12:15:20.330735Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:04:32.166074400Z",
     "start_time": "2024-03-31T14:04:32.159346300Z"
    }
   },
   "execution_count": 19,
   "outputs": [],
   "id": "1aeb96064da651a6"
  },
  {
   "cell_type": "code",
   "source": [
    "# X.loc[:, scalable_cols] = scaler.transform(X[scalable_cols])\n",
    "# test.loc[:, scalable_cols] = scaler.transform(test[scalable_cols])"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:15:20.945908Z",
     "iopub.execute_input": "2024-03-28T12:15:20.946818Z",
     "iopub.status.idle": "2024-03-28T12:15:20.992296Z",
     "shell.execute_reply.started": "2024-03-28T12:15:20.946785Z",
     "shell.execute_reply": "2024-03-28T12:15:20.991418Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:04:33.047159800Z",
     "start_time": "2024-03-31T14:04:33.038837700Z"
    }
   },
   "execution_count": 20,
   "outputs": [],
   "id": "2056f3ceedd54c50"
  },
  {
   "cell_type": "code",
   "source": [
    "high_informative = ['Pixels_Areas', 'LogOfAreas', 'Outside_X_Index', 'Sum_of_Luminosity', 'Y_Perimeter', 'X_Perimeter',\n",
    "                    'SigmoidOfAreas', 'X_Minimum', 'X_Maximum', 'Log_X_Index', 'Edges_Index', 'Steel_Plate_Thickness',\n",
    "                    'Log_Y_Index', 'Minimum_of_Luminosity', 'Edges_Y_Index', 'Length_of_Conveyer',\n",
    "                    'Edges_X_Index', ]"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:15:22.867636Z",
     "iopub.execute_input": "2024-03-28T12:15:22.867971Z",
     "iopub.status.idle": "2024-03-28T12:15:22.873190Z",
     "shell.execute_reply.started": "2024-03-28T12:15:22.867947Z",
     "shell.execute_reply": "2024-03-28T12:15:22.871961Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:18:39.762740100Z",
     "start_time": "2024-03-31T20:18:39.759228200Z"
    }
   },
   "execution_count": 114,
   "outputs": [],
   "id": "7615ff9d87c1fee0"
  },
  {
   "cell_type": "code",
   "source": [
    "lda = make_pipeline(LatentDirichletAllocation(9, n_jobs=-1)).fit(X[high_informative])\n",
    "\n",
    "X.loc[:, [f'lda_{i}' for i in range(9)]] = lda.transform(X[high_informative])\n",
    "test.loc[:, [f'lda_{i}' for i in range(9)]] = lda.transform(np.abs(test[high_informative]))"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:15:23.483278Z",
     "iopub.execute_input": "2024-03-28T12:15:23.484001Z",
     "iopub.status.idle": "2024-03-28T12:15:57.707767Z",
     "shell.execute_reply.started": "2024-03-28T12:15:23.483970Z",
     "shell.execute_reply": "2024-03-28T12:15:57.706557Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:19:13.190247100Z",
     "start_time": "2024-03-31T20:18:40.980939700Z"
    }
   },
   "execution_count": 115,
   "outputs": [],
   "id": "2a4aef4b0c753930"
  },
  {
   "cell_type": "code",
   "source": [
    "svd = make_pipeline(StandardScaler(),\n",
    "                    TruncatedSVD(n_components=3)).fit(X[high_informative])\n",
    "\n",
    "X.loc[:, [f'svd_{i}' for i in range(3)]] = svd.transform(X[high_informative])\n",
    "test.loc[:, [f'svd_{i}' for i in range(3)]] = svd.transform(test[high_informative])"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:15:57.709741Z",
     "iopub.execute_input": "2024-03-28T12:15:57.710085Z",
     "iopub.status.idle": "2024-03-28T12:15:58.047888Z",
     "shell.execute_reply.started": "2024-03-28T12:15:57.710057Z",
     "shell.execute_reply": "2024-03-28T12:15:58.046180Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:19:13.244158Z",
     "start_time": "2024-03-31T20:19:13.194235Z"
    }
   },
   "execution_count": 116,
   "outputs": [],
   "id": "edb3e98a238340e1"
  },
  {
   "cell_type": "code",
   "source": [
    "cluster = make_pipeline(StandardScaler(),\n",
    "                        KMeans(n_clusters=5)).fit(X[high_informative])\n",
    "\n",
    "X.loc[:, 'clus'] = cluster.predict(X[high_informative])\n",
    "test.loc[:, 'clus'] = cluster.predict(test[high_informative])"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:15:58.051226Z",
     "iopub.execute_input": "2024-03-28T12:15:58.053377Z",
     "iopub.status.idle": "2024-03-28T12:15:58.285772Z",
     "shell.execute_reply.started": "2024-03-28T12:15:58.053310Z",
     "shell.execute_reply": "2024-03-28T12:15:58.284862Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:19:13.348904200Z",
     "start_time": "2024-03-31T20:19:13.245644600Z"
    }
   },
   "execution_count": 117,
   "outputs": [],
   "id": "4a84e14f38174913"
  },
  {
   "cell_type": "code",
   "source": [
    "agg = make_pipeline(StandardScaler(),\n",
    "                    FeatureAgglomeration(3)).fit(X[high_informative])\n",
    "\n",
    "X.loc[:, [f'agg_{i}' for i in range(3)]] = agg.transform(X[high_informative])\n",
    "test.loc[:, [f'agg_{i}' for i in range(3)]] = agg.transform(test[high_informative])"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:15:58.288307Z",
     "iopub.execute_input": "2024-03-28T12:15:58.288891Z",
     "iopub.status.idle": "2024-03-28T12:15:58.492106Z",
     "shell.execute_reply.started": "2024-03-28T12:15:58.288853Z",
     "shell.execute_reply": "2024-03-28T12:15:58.491249Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:19:13.458863800Z",
     "start_time": "2024-03-31T20:19:13.350904Z"
    }
   },
   "execution_count": 118,
   "outputs": [],
   "id": "6743cad52fd065bc"
  },
  {
   "cell_type": "code",
   "source": [
    "X.shape, test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:18:25.219187Z",
     "iopub.execute_input": "2024-03-28T12:18:25.219575Z",
     "iopub.status.idle": "2024-03-28T12:18:25.226967Z",
     "shell.execute_reply.started": "2024-03-28T12:18:25.219541Z",
     "shell.execute_reply": "2024-03-28T12:18:25.225899Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:19:13.465033500Z",
     "start_time": "2024-03-31T20:19:13.458863800Z"
    }
   },
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "((19219, 76), (12814, 76))"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "id": "8b986a797c2d4738"
  },
  {
   "cell_type": "code",
   "source": [
    "# pd.Series(mutual_info_classif(X, target), index=X.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:18:25.228390Z",
     "iopub.execute_input": "2024-03-28T12:18:25.228701Z",
     "iopub.status.idle": "2024-03-28T12:19:18.447512Z",
     "shell.execute_reply.started": "2024-03-28T12:18:25.228678Z",
     "shell.execute_reply": "2024-03-28T12:19:18.446584Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T16:46:13.027582600Z",
     "start_time": "2024-03-31T16:46:13.017585800Z"
    }
   },
   "execution_count": 23,
   "outputs": [],
   "id": "5779e283ddcd744c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## models"
   ],
   "metadata": {},
   "id": "5165d7965ec6106f"
  },
  {
   "cell_type": "code",
   "source": [
    "cv = MultilabelStratifiedKFold(3, shuffle=True, random_state=48)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T12:21:05.517184Z",
     "iopub.execute_input": "2024-03-28T12:21:05.517563Z",
     "iopub.status.idle": "2024-03-28T12:21:05.522422Z",
     "shell.execute_reply.started": "2024-03-28T12:21:05.517535Z",
     "shell.execute_reply": "2024-03-28T12:21:05.521370Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T16:46:18.855228500Z",
     "start_time": "2024-03-31T16:46:18.825247300Z"
    }
   },
   "execution_count": 24,
   "outputs": [],
   "id": "2ee8f1ddd708737f"
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "data": {
      "text/plain": "66"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = RandomForestClassifier(max_depth=5, n_jobs=-1, random_state=48)\n",
    "\n",
    "selector = RFECV(est, min_features_to_select=19, cv=cv, scoring='roc_auc')\n",
    "selector.fit(X, Y)\n",
    "\n",
    "selector.n_features_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:30:16.174919200Z",
     "start_time": "2024-03-31T20:21:36.947091900Z"
    }
   },
   "id": "8275308e7d5aed81"
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "X = selector.transform(X)\n",
    "test = selector.transform(test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:30:35.369992100Z",
     "start_time": "2024-03-31T20:30:35.340727100Z"
    }
   },
   "id": "f684b22dee1b3efb"
  },
  {
   "cell_type": "code",
   "source": [
    "def object(trial):\n",
    "    params = dict(num_iterations=1000,  #trial.suggest_int('n_estimators ', 100, 1500),\n",
    "                  max_depth=trial.suggest_int('max_depth', 1, 5),\n",
    "                  # num_leaves=trial.suggest_int('num_leaves ', 3, 15),\n",
    "                  # bagging_freq=trial.suggest_int('bagging_freq', 32, 256),\n",
    "                  subsample=trial.suggest_float('subsample ', 1e-3, 1e-1),\n",
    "                  learning_rate=trial.suggest_float('learning_rate', 1e-4, 1e-2),\n",
    "                  # gamma=trial.suggest_float('gamma ', 1e-3, 1e-1),\n",
    "                  feature_fraction=trial.suggest_float('feature_fraction ', 7e-1, 9e-1),\n",
    "                  colsample_bytree=trial.suggest_float('colsample_bytree', 5e-1, 9e-1),\n",
    "                  colsample_bylevel=trial.suggest_float('colsample_bylevel ', 5e-1, 9e-1),\n",
    "                  reg_lambda=trial.suggest_float('reg_lambda ', 1e-2, 1),\n",
    "                  # lambda_l1=trial.suggest_float('reg_lambda ', 1e-3, 1),\n",
    "                  )\n",
    "\n",
    "    estimator = MultiOutputClassifier(LGBMClassifier(**params,\n",
    "                                                     objective='binary',\n",
    "                                                     device_type='gpu',\n",
    "                                                     verbosity=-1,\n",
    "                                                     # task_type=\"GPU\",\n",
    "                                                     # cat_features=['col_7', 'col_9', 'col_10',\n",
    "                                                     #               'TypeOfSteel_A300',\n",
    "                                                     #               'TypeOfSteel_A400'],\n",
    "                                                     # silent=True,\n",
    "                                                     # thread_count=-1\n",
    "                                                     # n_jobs=-1\n",
    "                                                     ))\n",
    "    score = []\n",
    "\n",
    "    for i, (t_idx, v_idx) in enumerate(cv.split(X, Y)):\n",
    "        train_x, valid_x = X[t_idx, :], X[v_idx, :]\n",
    "        train_y, valid_y = Y.loc[t_idx, :], Y.loc[v_idx, :]\n",
    "        preds = np.zeros((len(valid_y), len(ys)))\n",
    "\n",
    "        # weights = compute_sample_weight(class_weight='balanced', y=train_y)\n",
    "        estimator.fit(train_x, train_y)\n",
    "\n",
    "        pred_vals = estimator.predict_proba(valid_x)\n",
    "\n",
    "        for i in range(len(ys)):\n",
    "            preds[:, i] = pred_vals[i][:, 1]\n",
    "\n",
    "        avg_auc = roc_auc_score(valid_y, preds)\n",
    "        score.append(avg_auc)\n",
    "\n",
    "    return np.mean(score)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(object, n_trials=30)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-28T13:06:57.475165Z",
     "iopub.execute_input": "2024-03-28T13:06:57.475939Z",
     "iopub.status.idle": "2024-03-28T13:13:59.336659Z",
     "shell.execute_reply.started": "2024-03-28T13:06:57.475904Z",
     "shell.execute_reply": "2024-03-28T13:13:59.335469Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": [],
   "id": "2eae427a81a7458f"
  },
  {
   "cell_type": "code",
   "source": [
    "study.best_params"
   ],
   "metadata": {
    "collapsed": false,
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T18:40:15.959312700Z",
     "start_time": "2024-03-31T18:40:15.954987100Z"
    }
   },
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "{'max_depth': 4,\n 'subsample ': 0.03329071650502599,\n 'learning_rate': 0.007696872860687134,\n 'feature_fraction ': 0.7042302378231268,\n 'colsample_bytree': 0.7270310744955015,\n 'colsample_bylevel ': 0.8125773066822667,\n 'reg_lambda ': 0.8751327285847716}"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "id": "54cf7236d6459134"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def test_params(model, x, y):\n",
    "    scores = []\n",
    "\n",
    "    for i, (t_idx, v_idx) in enumerate(cv.split(x, y)):\n",
    "        train_x, valid_x = x[t_idx, :], x[v_idx, :]\n",
    "        train_y, valid_y = y.loc[t_idx, :], y.loc[v_idx, :]\n",
    "        preds = np.zeros((len(valid_y), len(ys)))\n",
    "\n",
    "        # weights = compute_sample_weight(class_weight='balanced', y=train_y)\n",
    "\n",
    "        estimator = model\n",
    "        estimator.fit(train_x, train_y)\n",
    "\n",
    "        pred_vals = estimator.predict_proba(valid_x)\n",
    "\n",
    "        print(f'fold: {i}')\n",
    "\n",
    "        for _ in range(len(ys)):\n",
    "            preds[:, _] = pred_vals[_][:, 1]\n",
    "\n",
    "        score = roc_auc_score(valid_y, preds)\n",
    "\n",
    "        print(score)\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T18:46:23.125088400Z",
     "start_time": "2024-03-31T18:46:22.736148400Z"
    }
   },
   "id": "7a68bce44e144412"
  },
  {
   "cell_type": "code",
   "source": [
    "cv = MultilabelStratifiedKFold(n_splits=7, shuffle=True, random_state=48)\n",
    "\n",
    "model = MultiOutputClassifier(XGBClassifier(n_estimators=1250,\n",
    "                                            max_depth=5,\n",
    "                                            subsample=0.4145,\n",
    "                                            learning_rate=0.0049,\n",
    "                                            colsample_bytree=0.741,\n",
    "                                            colsample_bylevel=0.819,\n",
    "                                            reg_alpha=0.755,\n",
    "                                            device='cuda:0',\n",
    "                                            verbosity=0))\n",
    "\n",
    "test_params(model, X, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:34:58.974664300Z",
     "start_time": "2024-03-31T20:31:52.707293900Z"
    }
   },
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "0.8890829335146392\n",
      "fold: 1\n",
      "0.886287420107052\n",
      "fold: 2\n",
      "0.8849303843952063\n",
      "fold: 3\n",
      "0.8851378610638203\n",
      "fold: 4\n",
      "0.8860683882267136\n",
      "fold: 5\n",
      "0.8862083525016927\n",
      "fold: 6\n",
      "0.8947708045921342\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8874980206287513"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "id": "d33c79019e7c3ace"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "0.8858640195631161\n",
      "fold: 1\n",
      "0.8819759597861881\n",
      "fold: 2\n",
      "0.8828870833924807\n",
      "fold: 3\n",
      "0.8836551114498385\n",
      "fold: 4\n",
      "0.8843797538071213\n",
      "fold: 5\n",
      "0.88199927072007\n",
      "fold: 6\n",
      "0.8900359940351085\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8843995989648462"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiOutputClassifier(LGBMClassifier(num_iterations=500,\n",
    "                                             max_depth=7,\n",
    "                                             subsample=0.03329071650502599,\n",
    "                                             learning_rate=0.01366872860687134,\n",
    "                                             feature_fraction=0.7042302378231268,\n",
    "                                             colsample_bytree=0.7270310744955015,\n",
    "                                             colsample_bylevel=0.8125773066822667,\n",
    "                                             reg_lambda=0.8751327285847716,\n",
    "                                             device=\"gpu\",\n",
    "                                             verbose=-1))\n",
    "\n",
    "test_params(model, X, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T19:42:07.805447600Z",
     "start_time": "2024-03-31T19:39:55.580343900Z"
    }
   },
   "id": "c64db212871c0e3f"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "0.8858840673429729\n",
      "fold: 1\n",
      "0.8813748674944472\n",
      "fold: 2\n",
      "0.8788335216017941\n",
      "fold: 3\n",
      "0.8786451460461441\n",
      "fold: 4\n",
      "0.8833795037075305\n",
      "fold: 5\n",
      "0.8836285910142415\n",
      "fold: 6\n",
      "0.8884995822289395\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8828921827765813"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiOutputClassifier(CatBoostClassifier(iterations=39,\n",
    "                                                 depth=5,\n",
    "                                                 learning_rate=0.15551739,\n",
    "                                                 task_type=\"GPU\",\n",
    "                                                 silent=True))\n",
    "\n",
    "test_params(model, X, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:11:32.913345900Z",
     "start_time": "2024-03-31T20:10:44.642795500Z"
    }
   },
   "id": "51067c127f5d9df"
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "class SteelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x.reset_index(drop=True)\n",
    "        self.y = y.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        xs = self.x.loc[idx, :]\n",
    "        ys = self.y.loc[idx, :]\n",
    "\n",
    "        return torch.tensor(xs.values, dtype=torch.float32), torch.tensor(ys.values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "class SteelModel(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SteelModel, self).__init__()\n",
    "\n",
    "        self.h_channels = 64\n",
    "        self.lstm_channels = 128\n",
    "\n",
    "        self.tail = nn.Sequential(nn.Linear(in_channels, self.h_channels),\n",
    "                                  nn.LeakyReLU(),\n",
    "                                  nn.BatchNorm1d(self.h_channels),\n",
    "                                  nn.Linear(self.h_channels, self.h_channels),\n",
    "                                  nn.LeakyReLU(),\n",
    "                                  nn.BatchNorm1d(self.h_channels),\n",
    "                                  nn.Dropout(0.3))\n",
    "        self.lstm = nn.LSTM(self.h_channels, self.lstm_channels, batch_first=True, bidirectional=True)\n",
    "        self.head = nn.Sequential(nn.Linear(2 * self.lstm_channels, self.h_channels),\n",
    "                                  nn.LeakyReLU(),\n",
    "                                  nn.BatchNorm1d(self.h_channels),\n",
    "                                  nn.Dropout(0.2),\n",
    "                                  nn.Linear(self.h_channels, out_channels),\n",
    "                                  nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tail(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T10:24:04.493746100Z",
     "start_time": "2024-03-31T10:24:04.486652400Z"
    }
   },
   "id": "df3b8b18f2892291"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "def move_to(obj, device):\n",
    "    \"\"\"\n",
    "    move data from tensor from back and forth\n",
    "\n",
    "    :param obj: the python object to move to a device, or to move its\n",
    "                contents to a device\n",
    "    :param device: the compute device to move objects to\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if isinstance(obj, list):\n",
    "        return [move_to(x, device) for x in obj]\n",
    "\n",
    "    elif isinstance(obj, tuple):\n",
    "        return tuple(move_to(list(obj), device))\n",
    "\n",
    "    elif isinstance(obj, set):\n",
    "        return set(move_to(list(obj), device))\n",
    "\n",
    "    elif isinstance(obj, dict):\n",
    "        to_ret = dict()\n",
    "\n",
    "        for key, value in obj.items():\n",
    "            to_ret[move_to(key, device)] = move_to(value, device)\n",
    "\n",
    "        return to_ret\n",
    "\n",
    "    elif hasattr(obj, \"to\"):\n",
    "        return obj.to(device)\n",
    "\n",
    "    else:\n",
    "        return obj"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T09:13:11.927163200Z",
     "start_time": "2024-03-31T09:13:11.919053800Z"
    }
   },
   "id": "a2ef2fe5d590a7bf"
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat: 0\n",
      "fold: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22cb44e723644045b9db053a13e64736"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train loss: 0.633056640625 train AUC: 0.721029335821105\n",
      "val loss: 0.6180182099342346 val AUC: 0.7746270599767734\n",
      "best checkpoint updated\n",
      "epoch: 1\n",
      "train loss: 0.5799828171730042 train AUC: 0.7818356681695446\n",
      "val loss: 0.5525301098823547 val AUC: 0.8255102821837389\n",
      "best checkpoint updated\n",
      "epoch: 2\n",
      "train loss: 0.5335808396339417 train AUC: 0.7943458096179207\n",
      "val loss: 0.4868198335170746 val AUC: 0.8306506804113093\n",
      "best checkpoint updated\n",
      "epoch: 3\n",
      "train loss: 0.47123634815216064 train AUC: 0.8015069480809615\n",
      "val loss: 0.4268195629119873 val AUC: 0.8453807477296147\n",
      "best checkpoint updated\n",
      "epoch: 4\n",
      "train loss: 0.3995712697505951 train AUC: 0.8002645363193162\n",
      "val loss: 0.35513123869895935 val AUC: 0.8442518634724704\n",
      "best checkpoint updated\n",
      "epoch: 5\n",
      "train loss: 0.3403877913951874 train AUC: 0.8055000703585656\n",
      "val loss: 0.3086388409137726 val AUC: 0.8532436798958742\n",
      "best checkpoint updated\n",
      "epoch: 6\n",
      "train loss: 0.3009088635444641 train AUC: 0.819546818454243\n",
      "val loss: 0.27542272210121155 val AUC: 0.8606000483305921\n",
      "best checkpoint updated\n",
      "epoch: 7\n",
      "train loss: 0.27742233872413635 train AUC: 0.8273294391174083\n",
      "val loss: 0.2627195417881012 val AUC: 0.8616139964124673\n",
      "best checkpoint updated\n",
      "epoch: 8\n",
      "train loss: 0.26224666833877563 train AUC: 0.8349833707266849\n",
      "val loss: 0.24781109392642975 val AUC: 0.8625811487681688\n",
      "best checkpoint updated\n",
      "epoch: 9\n",
      "train loss: 0.2546180784702301 train AUC: 0.8402746279592336\n",
      "val loss: 0.24404962360858917 val AUC: 0.8689179159764611\n",
      "best checkpoint updated\n",
      "epoch: 10\n",
      "train loss: 0.24809566140174866 train AUC: 0.8508026041230917\n",
      "val loss: 0.2387305647134781 val AUC: 0.8692965920489603\n",
      "best checkpoint updated\n",
      "epoch: 11\n",
      "train loss: 0.24511444568634033 train AUC: 0.8491768188096154\n",
      "val loss: 0.23705743253231049 val AUC: 0.865649774925322\n",
      "best checkpoint updated\n",
      "epoch: 12\n",
      "train loss: 0.24093769490718842 train AUC: 0.8579453812040532\n",
      "val loss: 0.23569583892822266 val AUC: 0.8679734906613575\n",
      "best checkpoint updated\n",
      "epoch: 13\n",
      "train loss: 0.23904982209205627 train AUC: 0.8564089733514393\n",
      "val loss: 0.23356719315052032 val AUC: 0.8696905338219697\n",
      "best checkpoint updated\n",
      "epoch: 14\n",
      "train loss: 0.2371283322572708 train AUC: 0.8615204464410624\n",
      "val loss: 0.2331572324037552 val AUC: 0.8694732932510497\n",
      "best checkpoint updated\n",
      "epoch: 15\n",
      "train loss: 0.23650658130645752 train AUC: 0.8632909445263093\n",
      "val loss: 0.23245078325271606 val AUC: 0.8693263171035587\n",
      "best checkpoint updated\n",
      "epoch: 16\n",
      "train loss: 0.2343287467956543 train AUC: 0.864584877369715\n",
      "val loss: 0.23119096457958221 val AUC: 0.8732650959300409\n",
      "best checkpoint updated\n",
      "epoch: 17\n",
      "train loss: 0.23419572412967682 train AUC: 0.8669510444085676\n",
      "val loss: 0.23208026587963104 val AUC: 0.8701860259445814\n",
      "epoch: 18\n",
      "train loss: 0.232915997505188 train AUC: 0.8700259109747401\n",
      "val loss: 0.23084135353565216 val AUC: 0.8723549035547977\n",
      "best checkpoint updated\n",
      "epoch: 19\n",
      "train loss: 0.2323659062385559 train AUC: 0.8686621090123096\n",
      "val loss: 0.23045583069324493 val AUC: 0.8745392196473759\n",
      "best checkpoint updated\n",
      "epoch: 20\n",
      "train loss: 0.2308809906244278 train AUC: 0.8724060940259963\n",
      "val loss: 0.2311391979455948 val AUC: 0.8729256105568547\n",
      "epoch: 21\n",
      "train loss: 0.23068177700042725 train AUC: 0.8727418088266323\n",
      "val loss: 0.2306382656097412 val AUC: 0.8736424278285884\n",
      "epoch: 22\n",
      "train loss: 0.2292032241821289 train AUC: 0.8741973428627813\n",
      "val loss: 0.23049046099185944 val AUC: 0.8733327837543601\n",
      "epoch: 23\n",
      "train loss: 0.2288149893283844 train AUC: 0.8738768426910274\n",
      "val loss: 0.2299918532371521 val AUC: 0.8755748473220234\n",
      "best checkpoint updated\n",
      "epoch: 24\n",
      "train loss: 0.2284567505121231 train AUC: 0.8755178517819183\n",
      "val loss: 0.2288351207971573 val AUC: 0.8752321555485582\n",
      "best checkpoint updated\n",
      "epoch: 25\n",
      "train loss: 0.22719231247901917 train AUC: 0.8777121738488489\n",
      "val loss: 0.22985194623470306 val AUC: 0.874925598829341\n",
      "epoch: 26\n",
      "train loss: 0.22662729024887085 train AUC: 0.8778691967527176\n",
      "val loss: 0.2306438535451889 val AUC: 0.8744008762771287\n",
      "epoch: 27\n",
      "train loss: 0.22597245872020721 train AUC: 0.8781892749016035\n",
      "val loss: 0.22993379831314087 val AUC: 0.8770156593979027\n",
      "epoch: 28\n",
      "train loss: 0.2263929545879364 train AUC: 0.8795909655211817\n",
      "val loss: 0.22808629274368286 val AUC: 0.8774311441911444\n",
      "best checkpoint updated\n",
      "epoch: 29\n",
      "train loss: 0.22565607726573944 train AUC: 0.8799910555141368\n",
      "val loss: 0.2293831706047058 val AUC: 0.8754084931041235\n",
      "epoch: 30\n",
      "train loss: 0.22503574192523956 train AUC: 0.8825521893172555\n",
      "val loss: 0.22739601135253906 val AUC: 0.8762910136361147\n",
      "best checkpoint updated\n",
      "epoch: 31\n",
      "train loss: 0.22407762706279755 train AUC: 0.8828050513974329\n",
      "val loss: 0.22913692891597748 val AUC: 0.8747134656691906\n",
      "epoch: 32\n",
      "train loss: 0.22396957874298096 train AUC: 0.8836229092356586\n",
      "val loss: 0.2303902953863144 val AUC: 0.8765763911201092\n",
      "epoch: 33\n",
      "train loss: 0.22339969873428345 train AUC: 0.883334826410981\n",
      "val loss: 0.229304239153862 val AUC: 0.8756583748889822\n",
      "epoch: 34\n",
      "train loss: 0.22333309054374695 train AUC: 0.8847638897176309\n",
      "Epoch 00035: reducing learning rate of group 0 to 3.3000e-04.\n",
      "val loss: 0.22908027470111847 val AUC: 0.877532378621189\n",
      "epoch: 35\n",
      "train loss: 0.22137363255023956 train AUC: 0.8865275090821375\n",
      "val loss: 0.22877424955368042 val AUC: 0.8771891612195354\n",
      "epoch: 36\n",
      "train loss: 0.22049009799957275 train AUC: 0.889179987498897\n",
      "val loss: 0.2286759465932846 val AUC: 0.877476074776121\n",
      "epoch: 37\n",
      "train loss: 0.22051496803760529 train AUC: 0.8883585847829393\n",
      "val loss: 0.22882936894893646 val AUC: 0.8764741419952674\n",
      "epoch: 38\n",
      "train loss: 0.22024747729301453 train AUC: 0.8886722386461728\n",
      "val loss: 0.2288767546415329 val AUC: 0.8764417694091288\n",
      "epoch: 39\n",
      "train loss: 0.2199525088071823 train AUC: 0.8904116696662223\n",
      "val loss: 0.22934246063232422 val AUC: 0.8771403309481635\n",
      "epoch: 40\n",
      "train loss: 0.21962188184261322 train AUC: 0.8890340813841127\n",
      "val loss: 0.22880040109157562 val AUC: 0.8767977228128379\n",
      "epoch: 41\n",
      "train loss: 0.21936103701591492 train AUC: 0.8900783522240506\n",
      "Epoch 00042: reducing learning rate of group 0 to 1.0890e-04.\n",
      "val loss: 0.2288922667503357 val AUC: 0.8766631609894665\n",
      "epoch: 42\n",
      "train loss: 0.21853893995285034 train AUC: 0.8905023148449628\n",
      "val loss: 0.22911250591278076 val AUC: 0.875527655357694\n",
      "epoch: 43\n",
      "train loss: 0.21916449069976807 train AUC: 0.8891376678341123\n",
      "val loss: 0.22959409654140472 val AUC: 0.8779894299918581\n",
      "epoch: 44\n",
      "train loss: 0.217967227101326 train AUC: 0.8900426667228162\n",
      "val loss: 0.22844405472278595 val AUC: 0.8771537778642698\n",
      "epoch: 45\n",
      "train loss: 0.21761487424373627 train AUC: 0.8922737601743087\n",
      "val loss: 0.22836069762706757 val AUC: 0.8769436770196264\n",
      "epoch: 46\n",
      "train loss: 0.21773217618465424 train AUC: 0.8917749050341599\n",
      "val loss: 0.22883717715740204 val AUC: 0.8765768139721217\n",
      "epoch: 47\n",
      "train loss: 0.2180497795343399 train AUC: 0.892138808594924\n",
      "val loss: 0.22805547714233398 val AUC: 0.8771702297433261\n",
      "epoch: 48\n",
      "train loss: 0.21798214316368103 train AUC: 0.892576801229888\n",
      "Epoch 00049: reducing learning rate of group 0 to 3.5937e-05.\n",
      "val loss: 0.22900842130184174 val AUC: 0.8764327717089722\n",
      "epoch: 49\n",
      "train loss: 0.21723821759223938 train AUC: 0.8923928642110163\n",
      "val loss: 0.22965757548809052 val AUC: 0.87755082877764\n",
      "fold: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0bde43c5bb4a45ea920585877754526a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train loss: 0.6531344652175903 train AUC: 0.7219315346264972\n",
      "val loss: 0.6454449892044067 val AUC: 0.7896642840709488\n",
      "best checkpoint updated\n",
      "epoch: 1\n",
      "train loss: 0.5966870784759521 train AUC: 0.7776177991787112\n",
      "val loss: 0.5703415870666504 val AUC: 0.8193157632895808\n",
      "best checkpoint updated\n",
      "epoch: 2\n",
      "train loss: 0.5473779439926147 train AUC: 0.784618053106325\n",
      "val loss: 0.5061435103416443 val AUC: 0.8302752502607468\n",
      "best checkpoint updated\n",
      "epoch: 3\n",
      "train loss: 0.4811159074306488 train AUC: 0.7901166233967296\n",
      "val loss: 0.4411843717098236 val AUC: 0.8353945569498467\n",
      "best checkpoint updated\n",
      "epoch: 4\n",
      "train loss: 0.4052644371986389 train AUC: 0.7911779852943419\n",
      "val loss: 0.3728468716144562 val AUC: 0.8497075028355855\n",
      "best checkpoint updated\n",
      "epoch: 5\n",
      "train loss: 0.3510490655899048 train AUC: 0.7989317319391541\n",
      "val loss: 0.3231152594089508 val AUC: 0.8535714502106312\n",
      "best checkpoint updated\n",
      "epoch: 6\n",
      "train loss: 0.30675673484802246 train AUC: 0.8095254705539254\n",
      "val loss: 0.2860061228275299 val AUC: 0.8546584169655196\n",
      "best checkpoint updated\n",
      "epoch: 7\n",
      "train loss: 0.29126033186912537 train AUC: 0.8175823377915995\n",
      "val loss: 0.2909776568412781 val AUC: 0.8619945279996792\n",
      "epoch: 8\n",
      "train loss: 0.27345311641693115 train AUC: 0.8299100413179663\n",
      "val loss: 0.25787362456321716 val AUC: 0.8608290121233594\n",
      "best checkpoint updated\n",
      "epoch: 9\n",
      "train loss: 0.2639137804508209 train AUC: 0.8371126134949134\n",
      "val loss: 0.2482977658510208 val AUC: 0.864474832689417\n",
      "best checkpoint updated\n",
      "epoch: 10\n",
      "train loss: 0.2543019950389862 train AUC: 0.8393102557741767\n",
      "val loss: 0.24082183837890625 val AUC: 0.863094188620563\n",
      "best checkpoint updated\n",
      "epoch: 11\n",
      "train loss: 0.24946902692317963 train AUC: 0.8477230868905318\n",
      "val loss: 0.23940551280975342 val AUC: 0.8677301433576972\n",
      "best checkpoint updated\n",
      "epoch: 12\n",
      "train loss: 0.24426759779453278 train AUC: 0.8523944410379508\n",
      "val loss: 0.23617559671401978 val AUC: 0.8712680181928564\n",
      "best checkpoint updated\n",
      "epoch: 13\n",
      "train loss: 0.24180863797664642 train AUC: 0.8572651985505777\n",
      "val loss: 0.23473091423511505 val AUC: 0.8708434306945433\n",
      "best checkpoint updated\n",
      "epoch: 14\n",
      "train loss: 0.24014024436473846 train AUC: 0.8575712723461493\n",
      "val loss: 0.23604322969913483 val AUC: 0.8698551800902684\n",
      "epoch: 15\n",
      "train loss: 0.23819167912006378 train AUC: 0.8620518817956214\n",
      "val loss: 0.23321962356567383 val AUC: 0.8709130089019838\n",
      "best checkpoint updated\n",
      "epoch: 16\n",
      "train loss: 0.23604097962379456 train AUC: 0.8639536966953016\n",
      "val loss: 0.23419474065303802 val AUC: 0.8736768516713904\n",
      "epoch: 17\n",
      "train loss: 0.2351410984992981 train AUC: 0.8653784964559295\n",
      "val loss: 0.2316417545080185 val AUC: 0.8736533862047354\n",
      "best checkpoint updated\n",
      "epoch: 18\n",
      "train loss: 0.2343241274356842 train AUC: 0.8670505556746755\n",
      "val loss: 0.23109769821166992 val AUC: 0.8731900746725435\n",
      "best checkpoint updated\n",
      "epoch: 19\n",
      "train loss: 0.2331525981426239 train AUC: 0.867625528372408\n",
      "val loss: 0.22970740497112274 val AUC: 0.8753818646510064\n",
      "best checkpoint updated\n",
      "epoch: 20\n",
      "train loss: 0.23248964548110962 train AUC: 0.8687491376739976\n",
      "val loss: 0.22994284331798553 val AUC: 0.8756011830253163\n",
      "epoch: 21\n",
      "train loss: 0.23170657455921173 train AUC: 0.8712813607504137\n",
      "val loss: 0.2315872758626938 val AUC: 0.8725382890953869\n",
      "epoch: 22\n",
      "train loss: 0.23057012259960175 train AUC: 0.8721436492480263\n",
      "val loss: 0.22914282977581024 val AUC: 0.8781985540805558\n",
      "best checkpoint updated\n",
      "epoch: 23\n",
      "train loss: 0.2299475520849228 train AUC: 0.8723470102046362\n",
      "val loss: 0.22889119386672974 val AUC: 0.8772865745398768\n",
      "best checkpoint updated\n",
      "epoch: 24\n",
      "train loss: 0.22911114990711212 train AUC: 0.8732122215637718\n",
      "val loss: 0.22996701300144196 val AUC: 0.8754164763247237\n",
      "epoch: 25\n",
      "train loss: 0.22869564592838287 train AUC: 0.8747431905345482\n",
      "val loss: 0.2289787083864212 val AUC: 0.8751958529249833\n",
      "epoch: 26\n",
      "train loss: 0.22834497690200806 train AUC: 0.8757032278153415\n",
      "val loss: 0.2296963334083557 val AUC: 0.8766263305679235\n",
      "epoch: 27\n",
      "train loss: 0.22826915979385376 train AUC: 0.876688363124915\n",
      "val loss: 0.2280440777540207 val AUC: 0.8783878921962782\n",
      "best checkpoint updated\n",
      "epoch: 28\n",
      "train loss: 0.22724340856075287 train AUC: 0.8770964875068664\n",
      "val loss: 0.22906172275543213 val AUC: 0.877076886841684\n",
      "epoch: 29\n",
      "train loss: 0.2263893187046051 train AUC: 0.8779857289828518\n",
      "val loss: 0.22777873277664185 val AUC: 0.8788816731985004\n",
      "best checkpoint updated\n",
      "epoch: 30\n",
      "train loss: 0.2254297137260437 train AUC: 0.8802247585007967\n",
      "val loss: 0.22936289012432098 val AUC: 0.8769259757419773\n",
      "epoch: 31\n",
      "train loss: 0.22591958940029144 train AUC: 0.8802190821735316\n",
      "val loss: 0.2299850732088089 val AUC: 0.8768882729739845\n",
      "epoch: 32\n",
      "train loss: 0.22489959001541138 train AUC: 0.8814028331398892\n",
      "val loss: 0.2286955714225769 val AUC: 0.8764902519300434\n",
      "epoch: 33\n",
      "train loss: 0.22451068460941315 train AUC: 0.8812358532591884\n",
      "Epoch 00034: reducing learning rate of group 0 to 3.3000e-04.\n",
      "val loss: 0.22896622121334076 val AUC: 0.8761912379360695\n",
      "epoch: 34\n",
      "train loss: 0.22348535060882568 train AUC: 0.8838411794879758\n",
      "val loss: 0.2262268215417862 val AUC: 0.8797371092915375\n",
      "best checkpoint updated\n",
      "epoch: 35\n",
      "train loss: 0.22175756096839905 train AUC: 0.8868281312392667\n",
      "val loss: 0.22705544531345367 val AUC: 0.8801840568814444\n",
      "epoch: 36\n",
      "train loss: 0.2216365784406662 train AUC: 0.8856685764812576\n",
      "val loss: 0.22805343568325043 val AUC: 0.8789983388069617\n",
      "epoch: 37\n",
      "train loss: 0.22138355672359467 train AUC: 0.8864381093540331\n",
      "val loss: 0.2270074486732483 val AUC: 0.8805808082517071\n",
      "epoch: 38\n",
      "train loss: 0.22162260115146637 train AUC: 0.8872206661592683\n",
      "val loss: 0.22755669057369232 val AUC: 0.8790516820067364\n",
      "epoch: 39\n",
      "train loss: 0.22127500176429749 train AUC: 0.8864386135607822\n",
      "val loss: 0.22753305733203888 val AUC: 0.8794645753204855\n",
      "epoch: 40\n",
      "train loss: 0.221183180809021 train AUC: 0.8874770180039822\n",
      "Epoch 00041: reducing learning rate of group 0 to 1.0890e-04.\n",
      "val loss: 0.2275313138961792 val AUC: 0.8786272609326063\n",
      "epoch: 41\n",
      "train loss: 0.21926717460155487 train AUC: 0.8896368443387133\n",
      "val loss: 0.22757388651371002 val AUC: 0.8791390296098628\n",
      "epoch: 42\n",
      "train loss: 0.21959346532821655 train AUC: 0.8889124022655678\n",
      "val loss: 0.2277747392654419 val AUC: 0.8789233607085721\n",
      "epoch: 43\n",
      "train loss: 0.21918977797031403 train AUC: 0.890212344384239\n",
      "val loss: 0.22710824012756348 val AUC: 0.8799867278604108\n",
      "epoch: 44\n",
      "train loss: 0.21906909346580505 train AUC: 0.8909043471798713\n",
      "val loss: 0.2280421406030655 val AUC: 0.8787427640510281\n",
      "epoch: 45\n",
      "train loss: 0.21916170418262482 train AUC: 0.889888572858935\n",
      "val loss: 0.2277287393808365 val AUC: 0.8795461606958003\n",
      "epoch: 46\n",
      "train loss: 0.21874845027923584 train AUC: 0.8911573458615922\n",
      "val loss: 0.2281894087791443 val AUC: 0.8795526430293868\n",
      "epoch: 47\n",
      "train loss: 0.21891802549362183 train AUC: 0.8911109343740558\n",
      "Epoch 00048: reducing learning rate of group 0 to 3.5937e-05.\n",
      "val loss: 0.22738732397556305 val AUC: 0.8805125353439124\n",
      "epoch: 48\n",
      "train loss: 0.21798640489578247 train AUC: 0.8907756743863063\n",
      "val loss: 0.2281549721956253 val AUC: 0.8789226309118549\n",
      "epoch: 49\n",
      "train loss: 0.21816518902778625 train AUC: 0.8905379112038132\n",
      "val loss: 0.2273259311914444 val AUC: 0.880430977355816\n",
      "fold: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfa5c8779b674637bc5847a03922cd45"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train loss: 0.646848738193512 train AUC: 0.7251867839530665\n",
      "val loss: 0.6364520192146301 val AUC: 0.7909587956668603\n",
      "best checkpoint updated\n",
      "epoch: 1\n",
      "train loss: 0.5943664312362671 train AUC: 0.7844810356633348\n",
      "val loss: 0.5682149529457092 val AUC: 0.8192691814965335\n",
      "best checkpoint updated\n",
      "epoch: 2\n",
      "train loss: 0.5465068221092224 train AUC: 0.7989727835334632\n",
      "val loss: 0.5117641091346741 val AUC: 0.8306337075160286\n",
      "best checkpoint updated\n",
      "epoch: 3\n",
      "train loss: 0.48123931884765625 train AUC: 0.8002218825703928\n",
      "val loss: 0.4342896640300751 val AUC: 0.8398943417539998\n",
      "best checkpoint updated\n",
      "epoch: 4\n",
      "train loss: 0.4088532626628876 train AUC: 0.8027230777722337\n",
      "val loss: 0.38399526476860046 val AUC: 0.84334275953738\n",
      "best checkpoint updated\n",
      "epoch: 5\n",
      "train loss: 0.3467254340648651 train AUC: 0.8064677486945979\n",
      "val loss: 0.315582811832428 val AUC: 0.8474539403443505\n",
      "best checkpoint updated\n",
      "epoch: 6\n",
      "train loss: 0.30312055349349976 train AUC: 0.8147733184718254\n",
      "val loss: 0.27631014585494995 val AUC: 0.84957916794255\n",
      "best checkpoint updated\n",
      "epoch: 7\n",
      "train loss: 0.2796606719493866 train AUC: 0.8235125324801024\n",
      "val loss: 0.2641301453113556 val AUC: 0.8562814457514992\n",
      "best checkpoint updated\n",
      "epoch: 8\n",
      "train loss: 0.26479828357696533 train AUC: 0.8295031971531215\n",
      "val loss: 0.25279030203819275 val AUC: 0.8606225015753076\n",
      "best checkpoint updated\n",
      "epoch: 9\n",
      "train loss: 0.25604158639907837 train AUC: 0.8388194560778653\n",
      "val loss: 0.25188639760017395 val AUC: 0.8622382878796921\n",
      "best checkpoint updated\n",
      "epoch: 10\n",
      "train loss: 0.2501946985721588 train AUC: 0.8434087372831587\n",
      "val loss: 0.24485474824905396 val AUC: 0.8668776501065261\n",
      "best checkpoint updated\n",
      "epoch: 11\n",
      "train loss: 0.24563106894493103 train AUC: 0.8515525265511721\n",
      "val loss: 0.23748791217803955 val AUC: 0.8666042084268747\n",
      "best checkpoint updated\n",
      "epoch: 12\n",
      "train loss: 0.24306465685367584 train AUC: 0.851565047440085\n",
      "val loss: 0.23738610744476318 val AUC: 0.8669670515638548\n",
      "best checkpoint updated\n",
      "epoch: 13\n",
      "train loss: 0.2406296283006668 train AUC: 0.8568824015168617\n",
      "val loss: 0.23534934222698212 val AUC: 0.8677967652835297\n",
      "best checkpoint updated\n",
      "epoch: 14\n",
      "train loss: 0.2375892996788025 train AUC: 0.8611887202840048\n",
      "val loss: 0.2359285205602646 val AUC: 0.865737083004175\n",
      "epoch: 15\n",
      "train loss: 0.2374795377254486 train AUC: 0.8625838880664444\n",
      "val loss: 0.23530256748199463 val AUC: 0.8698251676985452\n",
      "best checkpoint updated\n",
      "epoch: 16\n",
      "train loss: 0.2353326827287674 train AUC: 0.8653176204778675\n",
      "val loss: 0.23150362074375153 val AUC: 0.8723829790799299\n",
      "best checkpoint updated\n",
      "epoch: 17\n",
      "train loss: 0.23430761694908142 train AUC: 0.8652093317696312\n",
      "val loss: 0.2327529937028885 val AUC: 0.8702221204262696\n",
      "epoch: 18\n",
      "train loss: 0.2337828129529953 train AUC: 0.8664901284067811\n",
      "val loss: 0.23502255976200104 val AUC: 0.8709483712112275\n",
      "epoch: 19\n",
      "train loss: 0.2327001392841339 train AUC: 0.8713422196559608\n",
      "val loss: 0.23179101943969727 val AUC: 0.8718215050716821\n",
      "epoch: 20\n",
      "train loss: 0.23090948164463043 train AUC: 0.8706829095409223\n",
      "Epoch 00021: reducing learning rate of group 0 to 3.3000e-04.\n",
      "val loss: 0.23224277794361115 val AUC: 0.870844468787351\n",
      "epoch: 21\n",
      "train loss: 0.22999908030033112 train AUC: 0.8740424839320814\n",
      "val loss: 0.23108625411987305 val AUC: 0.8708792030789886\n",
      "best checkpoint updated\n",
      "epoch: 22\n",
      "train loss: 0.22823594510555267 train AUC: 0.8759307928228544\n",
      "val loss: 0.22965557873249054 val AUC: 0.8721619104905871\n",
      "best checkpoint updated\n",
      "epoch: 23\n",
      "train loss: 0.2278907597064972 train AUC: 0.8779334890114747\n",
      "val loss: 0.22979103028774261 val AUC: 0.8728480042044038\n",
      "epoch: 24\n",
      "train loss: 0.22757932543754578 train AUC: 0.8769067331001537\n",
      "val loss: 0.23134995996952057 val AUC: 0.8710870421257089\n",
      "epoch: 25\n",
      "train loss: 0.22738942503929138 train AUC: 0.8780744077959138\n",
      "val loss: 0.23048673570156097 val AUC: 0.8725594695720069\n",
      "epoch: 26\n",
      "train loss: 0.22697725892066956 train AUC: 0.8788242939525166\n",
      "val loss: 0.2305135279893875 val AUC: 0.8730871116972553\n",
      "epoch: 27\n",
      "train loss: 0.2279525250196457 train AUC: 0.8766759297869701\n",
      "val loss: 0.229075089097023 val AUC: 0.8739677111545393\n",
      "best checkpoint updated\n",
      "epoch: 28\n",
      "train loss: 0.22669397294521332 train AUC: 0.8804663152811477\n",
      "val loss: 0.23036153614521027 val AUC: 0.8738436450860073\n",
      "epoch: 29\n",
      "train loss: 0.22637437283992767 train AUC: 0.881166491599826\n",
      "val loss: 0.22973991930484772 val AUC: 0.8739871773246891\n",
      "epoch: 30\n",
      "train loss: 0.22667525708675385 train AUC: 0.8784950017587864\n",
      "val loss: 0.23002268373966217 val AUC: 0.8730930380816143\n",
      "epoch: 31\n",
      "train loss: 0.22515788674354553 train AUC: 0.8804403638837326\n",
      "Epoch 00032: reducing learning rate of group 0 to 1.0890e-04.\n",
      "val loss: 0.23005656898021698 val AUC: 0.8730507712649073\n",
      "epoch: 32\n",
      "train loss: 0.22548425197601318 train AUC: 0.8816711830976872\n",
      "val loss: 0.2292173057794571 val AUC: 0.8729995063119947\n",
      "epoch: 33\n",
      "train loss: 0.22438396513462067 train AUC: 0.8822668732920751\n",
      "val loss: 0.22976647317409515 val AUC: 0.8732048028270997\n",
      "epoch: 34\n",
      "train loss: 0.22434909641742706 train AUC: 0.8822827270138986\n",
      "val loss: 0.22937969863414764 val AUC: 0.8741689731177407\n",
      "epoch: 35\n",
      "train loss: 0.2245953530073166 train AUC: 0.8817605142187879\n",
      "val loss: 0.2296162247657776 val AUC: 0.8737308880787314\n",
      "epoch: 36\n",
      "train loss: 0.22390533983707428 train AUC: 0.8840931324151492\n",
      "val loss: 0.23055016994476318 val AUC: 0.8720515843056355\n",
      "epoch: 37\n",
      "train loss: 0.22399815917015076 train AUC: 0.8823035658934577\n",
      "val loss: 0.2301795929670334 val AUC: 0.8731620327252788\n",
      "epoch: 38\n",
      "train loss: 0.22475309669971466 train AUC: 0.8821693412718742\n",
      "Epoch 00039: reducing learning rate of group 0 to 3.5937e-05.\n",
      "val loss: 0.22981619834899902 val AUC: 0.8728213870629324\n",
      "epoch: 39\n",
      "train loss: 0.2242375612258911 train AUC: 0.8809244369887504\n",
      "val loss: 0.2299138307571411 val AUC: 0.8720379180723986\n",
      "epoch: 40\n",
      "train loss: 0.22425760328769684 train AUC: 0.8820909731577012\n",
      "val loss: 0.22917963564395905 val AUC: 0.8743093404302975\n",
      "epoch: 41\n",
      "train loss: 0.22332940995693207 train AUC: 0.8845314597940711\n",
      "val loss: 0.2299150675535202 val AUC: 0.8749740510965377\n",
      "epoch: 42\n",
      "train loss: 0.2248019427061081 train AUC: 0.8822093215064474\n",
      "val loss: 0.2294677346944809 val AUC: 0.8734737513802823\n",
      "epoch: 43\n",
      "train loss: 0.22357147932052612 train AUC: 0.8838505260454477\n",
      "val loss: 0.22971577942371368 val AUC: 0.8737273151869647\n",
      "epoch: 44\n",
      "train loss: 0.22232642769813538 train AUC: 0.883776911692183\n",
      "val loss: 0.22900433838367462 val AUC: 0.8744024017965263\n",
      "best checkpoint updated\n",
      "epoch: 45\n",
      "train loss: 0.2234291434288025 train AUC: 0.8845985644325307\n",
      "val loss: 0.22947867214679718 val AUC: 0.8747069657941524\n",
      "epoch: 46\n",
      "train loss: 0.223283588886261 train AUC: 0.8839089925594504\n",
      "val loss: 0.22920437157154083 val AUC: 0.8738116835033151\n",
      "epoch: 47\n",
      "train loss: 0.2238580882549286 train AUC: 0.8832346130734156\n",
      "val loss: 0.22974400222301483 val AUC: 0.8733305136678782\n",
      "epoch: 48\n",
      "train loss: 0.2235017716884613 train AUC: 0.8838610464446701\n",
      "Epoch 00049: reducing learning rate of group 0 to 1.1859e-05.\n",
      "val loss: 0.22994685173034668 val AUC: 0.8733387736293353\n",
      "epoch: 49\n",
      "train loss: 0.22386598587036133 train AUC: 0.8818164800942664\n",
      "val loss: 0.22923783957958221 val AUC: 0.8749428182529627\n",
      "repeat: 1\n",
      "fold: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26af67014ef941e5a30719a4b69919ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train loss: 0.6651259064674377 train AUC: 0.7341636489610132\n",
      "val loss: 0.6476588845252991 val AUC: 0.8132568951138902\n",
      "best checkpoint updated\n",
      "epoch: 1\n",
      "train loss: 0.6057060360908508 train AUC: 0.7849659000464771\n",
      "val loss: 0.5545868277549744 val AUC: 0.822710307183193\n",
      "best checkpoint updated\n",
      "epoch: 2\n",
      "train loss: 0.5542331337928772 train AUC: 0.7950063470451532\n",
      "val loss: 0.49515581130981445 val AUC: 0.8432441899374262\n",
      "best checkpoint updated\n",
      "epoch: 3\n",
      "train loss: 0.48989278078079224 train AUC: 0.8017501098044215\n",
      "val loss: 0.4431029260158539 val AUC: 0.8472245067938028\n",
      "best checkpoint updated\n",
      "epoch: 4\n",
      "train loss: 0.4158393442630768 train AUC: 0.8036030461439663\n",
      "val loss: 0.3744240701198578 val AUC: 0.8504856986163712\n",
      "best checkpoint updated\n",
      "epoch: 5\n",
      "train loss: 0.35152187943458557 train AUC: 0.8105012691581729\n",
      "val loss: 0.3102446496486664 val AUC: 0.8529106922179174\n",
      "best checkpoint updated\n",
      "epoch: 6\n",
      "train loss: 0.3077363073825836 train AUC: 0.8167391527877256\n",
      "val loss: 0.2784350514411926 val AUC: 0.8587072676952179\n",
      "best checkpoint updated\n",
      "epoch: 7\n",
      "train loss: 0.27938777208328247 train AUC: 0.8277676596320828\n",
      "val loss: 0.2609911262989044 val AUC: 0.8617574190537329\n",
      "best checkpoint updated\n",
      "epoch: 8\n",
      "train loss: 0.26380446553230286 train AUC: 0.8358854425424834\n",
      "val loss: 0.2502812445163727 val AUC: 0.8618752020011972\n",
      "best checkpoint updated\n",
      "epoch: 9\n",
      "train loss: 0.25414517521858215 train AUC: 0.8429508847460505\n",
      "val loss: 0.24427056312561035 val AUC: 0.8620787441718337\n",
      "best checkpoint updated\n",
      "epoch: 10\n",
      "train loss: 0.24958495795726776 train AUC: 0.8477969375510943\n",
      "val loss: 0.24091367423534393 val AUC: 0.8635470123287412\n",
      "best checkpoint updated\n",
      "epoch: 11\n",
      "train loss: 0.24497704207897186 train AUC: 0.8534136876041606\n",
      "val loss: 0.23525917530059814 val AUC: 0.8695754842308975\n",
      "best checkpoint updated\n",
      "epoch: 12\n",
      "train loss: 0.24172715842723846 train AUC: 0.8576338873368615\n",
      "val loss: 0.23519575595855713 val AUC: 0.8708380305785575\n",
      "best checkpoint updated\n",
      "epoch: 13\n",
      "train loss: 0.238953098654747 train AUC: 0.8610741338034354\n",
      "val loss: 0.23397648334503174 val AUC: 0.8719961239655337\n",
      "best checkpoint updated\n",
      "epoch: 14\n",
      "train loss: 0.23781120777130127 train AUC: 0.8616537644898754\n",
      "val loss: 0.23220288753509521 val AUC: 0.8723873919082022\n",
      "best checkpoint updated\n",
      "epoch: 15\n",
      "train loss: 0.23662306368350983 train AUC: 0.8618664592491893\n",
      "val loss: 0.2334415465593338 val AUC: 0.8702397286646336\n",
      "epoch: 16\n",
      "train loss: 0.2351045459508896 train AUC: 0.865421042102429\n",
      "val loss: 0.22930073738098145 val AUC: 0.8733477317580084\n",
      "best checkpoint updated\n",
      "epoch: 17\n",
      "train loss: 0.23302611708641052 train AUC: 0.8682237168492861\n",
      "val loss: 0.2318413108587265 val AUC: 0.8717860133001052\n",
      "epoch: 18\n",
      "train loss: 0.23165248334407806 train AUC: 0.8697405467490974\n",
      "val loss: 0.22912414371967316 val AUC: 0.8758489291873374\n",
      "best checkpoint updated\n",
      "epoch: 19\n",
      "train loss: 0.23077596724033356 train AUC: 0.870132710903589\n",
      "val loss: 0.2304479330778122 val AUC: 0.8715119548275269\n",
      "epoch: 20\n",
      "train loss: 0.23069369792938232 train AUC: 0.8736744685101177\n",
      "val loss: 0.22989808022975922 val AUC: 0.8717007159287561\n",
      "epoch: 21\n",
      "train loss: 0.23004892468452454 train AUC: 0.8741580199212331\n",
      "val loss: 0.23058779537677765 val AUC: 0.873105632130399\n",
      "epoch: 22\n",
      "train loss: 0.2293350249528885 train AUC: 0.8748978063454217\n",
      "val loss: 0.22805269062519073 val AUC: 0.8760393829025284\n",
      "best checkpoint updated\n",
      "epoch: 23\n",
      "train loss: 0.22850392758846283 train AUC: 0.8763195663137311\n",
      "val loss: 0.23181243240833282 val AUC: 0.8730661867913646\n",
      "epoch: 24\n",
      "train loss: 0.22781816124916077 train AUC: 0.8771199463206859\n",
      "val loss: 0.22871720790863037 val AUC: 0.8748707818720173\n",
      "epoch: 25\n",
      "train loss: 0.22707781195640564 train AUC: 0.8771402291890316\n",
      "val loss: 0.2295851707458496 val AUC: 0.8738322831785649\n",
      "epoch: 26\n",
      "train loss: 0.2271665632724762 train AUC: 0.8778226347653418\n",
      "Epoch 00027: reducing learning rate of group 0 to 3.3000e-04.\n",
      "val loss: 0.22920697927474976 val AUC: 0.8752733156202619\n",
      "epoch: 27\n",
      "train loss: 0.2251245081424713 train AUC: 0.8810620643613423\n",
      "val loss: 0.2282765656709671 val AUC: 0.8750331154303241\n",
      "epoch: 28\n",
      "train loss: 0.22410129010677338 train AUC: 0.88285164499179\n",
      "val loss: 0.22726412117481232 val AUC: 0.8757286885074819\n",
      "best checkpoint updated\n",
      "epoch: 29\n",
      "train loss: 0.22342859208583832 train AUC: 0.8821074017789015\n",
      "val loss: 0.22793583571910858 val AUC: 0.874263208599825\n",
      "epoch: 30\n",
      "train loss: 0.2229960411787033 train AUC: 0.8841636828494238\n",
      "val loss: 0.22804377973079681 val AUC: 0.8750077018907777\n",
      "epoch: 31\n",
      "train loss: 0.2230561375617981 train AUC: 0.8850065260622846\n",
      "val loss: 0.2276441603899002 val AUC: 0.8749505857914439\n",
      "epoch: 32\n",
      "train loss: 0.22304342687129974 train AUC: 0.8839901650240914\n",
      "val loss: 0.2276613563299179 val AUC: 0.8744196955910338\n",
      "epoch: 33\n",
      "train loss: 0.22294685244560242 train AUC: 0.8830667227375067\n",
      "Epoch 00034: reducing learning rate of group 0 to 1.0890e-04.\n",
      "val loss: 0.2280930131673813 val AUC: 0.8754365828292191\n",
      "epoch: 34\n",
      "train loss: 0.22204077243804932 train AUC: 0.8866661445098495\n",
      "val loss: 0.22793364524841309 val AUC: 0.8756446860630902\n",
      "epoch: 35\n",
      "train loss: 0.2215902954339981 train AUC: 0.885317179966713\n",
      "val loss: 0.22862453758716583 val AUC: 0.875051921373878\n",
      "epoch: 36\n",
      "train loss: 0.22106733918190002 train AUC: 0.8865861872822274\n",
      "val loss: 0.228363037109375 val AUC: 0.8766911287877037\n",
      "epoch: 37\n",
      "train loss: 0.221039280295372 train AUC: 0.8862006923853086\n",
      "val loss: 0.22744645178318024 val AUC: 0.8759032497125464\n",
      "epoch: 38\n",
      "train loss: 0.22076374292373657 train AUC: 0.8883283380531314\n",
      "val loss: 0.22786639630794525 val AUC: 0.8748580365941968\n",
      "epoch: 39\n",
      "train loss: 0.22146274149417877 train AUC: 0.8861573816499374\n",
      "val loss: 0.22795546054840088 val AUC: 0.874842407527313\n",
      "epoch: 40\n",
      "train loss: 0.2213951051235199 train AUC: 0.8866775038021842\n",
      "Epoch 00041: reducing learning rate of group 0 to 3.5937e-05.\n",
      "val loss: 0.2273053526878357 val AUC: 0.8765161988415874\n",
      "epoch: 41\n",
      "train loss: 0.22062698006629944 train AUC: 0.888065736358389\n",
      "val loss: 0.22805845737457275 val AUC: 0.8763556735020148\n",
      "epoch: 42\n",
      "train loss: 0.22104881703853607 train AUC: 0.8872825582932359\n",
      "val loss: 0.2279946357011795 val AUC: 0.8753129403146226\n",
      "epoch: 43\n",
      "train loss: 0.2208501696586609 train AUC: 0.8881514552149915\n",
      "val loss: 0.22736550867557526 val AUC: 0.8759805692660562\n",
      "epoch: 44\n",
      "train loss: 0.22089697420597076 train AUC: 0.8874417256768354\n",
      "val loss: 0.22799645364284515 val AUC: 0.8752369687955484\n",
      "epoch: 45\n",
      "train loss: 0.22103101015090942 train AUC: 0.8870115043027382\n",
      "val loss: 0.22811345756053925 val AUC: 0.8753698277444739\n",
      "epoch: 46\n",
      "train loss: 0.21985889971256256 train AUC: 0.8883890046238864\n",
      "val loss: 0.2281579226255417 val AUC: 0.8767271275515167\n",
      "epoch: 47\n",
      "train loss: 0.22058779001235962 train AUC: 0.8876931123876817\n",
      "Epoch 00048: reducing learning rate of group 0 to 1.1859e-05.\n",
      "val loss: 0.22851543128490448 val AUC: 0.874854662881662\n",
      "epoch: 48\n",
      "train loss: 0.22019684314727783 train AUC: 0.8884707704480985\n",
      "val loss: 0.22859610617160797 val AUC: 0.8753926710585401\n",
      "epoch: 49\n",
      "train loss: 0.22051353752613068 train AUC: 0.8889011227357219\n",
      "val loss: 0.22822964191436768 val AUC: 0.8767412467365551\n",
      "fold: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55e336a450e24122b371fd13b1cc8baf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train loss: 0.6656854152679443 train AUC: 0.7243930609753861\n",
      "val loss: 0.6584485173225403 val AUC: 0.7095246271758247\n",
      "best checkpoint updated\n",
      "epoch: 1\n",
      "train loss: 0.6075164675712585 train AUC: 0.7750683983760394\n",
      "val loss: 0.5806612372398376 val AUC: 0.8092320398877378\n",
      "best checkpoint updated\n",
      "epoch: 2\n",
      "train loss: 0.5593525171279907 train AUC: 0.7823190589310611\n",
      "val loss: 0.5183331966400146 val AUC: 0.8243956614509402\n",
      "best checkpoint updated\n",
      "epoch: 3\n",
      "train loss: 0.49404945969581604 train AUC: 0.7919763134714259\n",
      "val loss: 0.4787944555282593 val AUC: 0.831303995611314\n",
      "best checkpoint updated\n",
      "epoch: 4\n",
      "train loss: 0.4191720187664032 train AUC: 0.7915594503031019\n",
      "val loss: 0.3818712532520294 val AUC: 0.8462462521426707\n",
      "best checkpoint updated\n",
      "epoch: 5\n",
      "train loss: 0.35309720039367676 train AUC: 0.791034831055839\n",
      "val loss: 0.32734644412994385 val AUC: 0.8508406549408681\n",
      "best checkpoint updated\n",
      "epoch: 6\n",
      "train loss: 0.3074924945831299 train AUC: 0.8056293280632616\n",
      "val loss: 0.28302323818206787 val AUC: 0.858990924064508\n",
      "best checkpoint updated\n",
      "epoch: 7\n",
      "train loss: 0.2801930606365204 train AUC: 0.8176445899018446\n",
      "val loss: 0.2657713294029236 val AUC: 0.8578198014028223\n",
      "best checkpoint updated\n",
      "epoch: 8\n",
      "train loss: 0.2664429545402527 train AUC: 0.8231340087101432\n",
      "val loss: 0.2520284950733185 val AUC: 0.8640779201666074\n",
      "best checkpoint updated\n",
      "epoch: 9\n",
      "train loss: 0.25715646147727966 train AUC: 0.8300856584429326\n",
      "val loss: 0.24862001836299896 val AUC: 0.866035064698209\n",
      "best checkpoint updated\n",
      "epoch: 10\n",
      "train loss: 0.2514446973800659 train AUC: 0.8392426696698194\n",
      "val loss: 0.24303090572357178 val AUC: 0.8663531136240659\n",
      "best checkpoint updated\n",
      "epoch: 11\n",
      "train loss: 0.24687182903289795 train AUC: 0.8442632229051691\n",
      "val loss: 0.23950040340423584 val AUC: 0.8708426676698249\n",
      "best checkpoint updated\n",
      "epoch: 12\n",
      "train loss: 0.24493202567100525 train AUC: 0.8455597779581829\n",
      "val loss: 0.23879243433475494 val AUC: 0.8694506682530957\n",
      "best checkpoint updated\n",
      "epoch: 13\n",
      "train loss: 0.24237631261348724 train AUC: 0.8496067857949935\n",
      "val loss: 0.2357463836669922 val AUC: 0.8710148243230683\n",
      "best checkpoint updated\n",
      "epoch: 14\n",
      "train loss: 0.24171912670135498 train AUC: 0.8526259634930051\n",
      "val loss: 0.2360549420118332 val AUC: 0.8708635183467371\n",
      "epoch: 15\n",
      "train loss: 0.23995119333267212 train AUC: 0.8529769375496942\n",
      "val loss: 0.23377738893032074 val AUC: 0.8728667730282255\n",
      "best checkpoint updated\n",
      "epoch: 16\n",
      "train loss: 0.23783132433891296 train AUC: 0.8576973550989743\n",
      "val loss: 0.2344963401556015 val AUC: 0.8714393657218377\n",
      "epoch: 17\n",
      "train loss: 0.23704779148101807 train AUC: 0.8607878922948322\n",
      "val loss: 0.23277848958969116 val AUC: 0.8724259567474194\n",
      "best checkpoint updated\n",
      "epoch: 18\n",
      "train loss: 0.23509030044078827 train AUC: 0.8644258154008376\n",
      "val loss: 0.23168723285198212 val AUC: 0.8757482365556077\n",
      "best checkpoint updated\n",
      "epoch: 19\n",
      "train loss: 0.23466825485229492 train AUC: 0.8667475056441276\n",
      "val loss: 0.23215019702911377 val AUC: 0.8767850414343923\n",
      "epoch: 20\n",
      "train loss: 0.23493017256259918 train AUC: 0.867882222692938\n",
      "val loss: 0.22985750436782837 val AUC: 0.8772995409275359\n",
      "best checkpoint updated\n",
      "epoch: 21\n",
      "train loss: 0.2332318276166916 train AUC: 0.868059143899712\n",
      "val loss: 0.23023808002471924 val AUC: 0.8763025073976602\n",
      "epoch: 22\n",
      "train loss: 0.23195718228816986 train AUC: 0.8683208710001695\n",
      "val loss: 0.2281956523656845 val AUC: 0.8794117308121899\n",
      "best checkpoint updated\n",
      "epoch: 23\n",
      "train loss: 0.23097719252109528 train AUC: 0.8717155380161802\n",
      "val loss: 0.22901971638202667 val AUC: 0.8777102942641597\n",
      "epoch: 24\n",
      "train loss: 0.23014043271541595 train AUC: 0.8721292168517443\n",
      "val loss: 0.22872750461101532 val AUC: 0.8771406197260173\n",
      "epoch: 25\n",
      "train loss: 0.2305145263671875 train AUC: 0.8719717285519453\n",
      "val loss: 0.23026953637599945 val AUC: 0.8763277930466421\n",
      "epoch: 26\n",
      "train loss: 0.2299579232931137 train AUC: 0.8740760517367885\n",
      "Epoch 00027: reducing learning rate of group 0 to 3.3000e-04.\n",
      "val loss: 0.228759765625 val AUC: 0.8771869506000284\n",
      "epoch: 27\n",
      "train loss: 0.22732849419116974 train AUC: 0.8746217016926162\n",
      "val loss: 0.22727864980697632 val AUC: 0.878131289467403\n",
      "best checkpoint updated\n",
      "epoch: 28\n",
      "train loss: 0.22720958292484283 train AUC: 0.8760073058746067\n",
      "val loss: 0.22797732055187225 val AUC: 0.8794935222956801\n",
      "epoch: 29\n",
      "train loss: 0.22645923495292664 train AUC: 0.8799127454759826\n",
      "val loss: 0.22781886160373688 val AUC: 0.879514010706265\n",
      "epoch: 30\n",
      "train loss: 0.22603081166744232 train AUC: 0.8785576435808418\n",
      "val loss: 0.22734196484088898 val AUC: 0.8795947418671104\n",
      "epoch: 31\n",
      "train loss: 0.22592096030712128 train AUC: 0.8805050698987409\n",
      "val loss: 0.22776900231838226 val AUC: 0.8790685043139291\n",
      "epoch: 32\n",
      "train loss: 0.22538860142230988 train AUC: 0.8807088124880389\n",
      "val loss: 0.2276586890220642 val AUC: 0.8789368661349264\n",
      "epoch: 33\n",
      "train loss: 0.2253076136112213 train AUC: 0.8801404948240612\n",
      "Epoch 00034: reducing learning rate of group 0 to 1.0890e-04.\n",
      "val loss: 0.22755958139896393 val AUC: 0.879892578482501\n",
      "epoch: 34\n",
      "train loss: 0.22448895871639252 train AUC: 0.8821518475944692\n",
      "val loss: 0.2274044305086136 val AUC: 0.879433306723565\n",
      "epoch: 35\n",
      "train loss: 0.22378376126289368 train AUC: 0.8826980821496064\n",
      "val loss: 0.2273630052804947 val AUC: 0.8800425618500926\n",
      "epoch: 36\n",
      "train loss: 0.22346101701259613 train AUC: 0.8842225067015653\n",
      "val loss: 0.2279602438211441 val AUC: 0.8789729145822788\n",
      "epoch: 37\n",
      "train loss: 0.22429271042346954 train AUC: 0.8822895514361181\n",
      "val loss: 0.22783870995044708 val AUC: 0.8792954888972263\n",
      "epoch: 38\n",
      "train loss: 0.22423404455184937 train AUC: 0.8847446595603362\n",
      "val loss: 0.22773265838623047 val AUC: 0.8785942126647526\n",
      "epoch: 39\n",
      "train loss: 0.22345714271068573 train AUC: 0.8831920831914253\n",
      "val loss: 0.2265787273645401 val AUC: 0.8795049870408617\n",
      "best checkpoint updated\n",
      "epoch: 40\n",
      "train loss: 0.22313405573368073 train AUC: 0.8824574944730332\n",
      "val loss: 0.22728930413722992 val AUC: 0.8801381756983705\n",
      "epoch: 41\n",
      "train loss: 0.22388190031051636 train AUC: 0.8824399932451615\n",
      "val loss: 0.22731870412826538 val AUC: 0.8793305250537843\n",
      "epoch: 42\n",
      "train loss: 0.2237938493490219 train AUC: 0.8819650831962323\n",
      "val loss: 0.2278149276971817 val AUC: 0.8810143426303435\n",
      "epoch: 43\n",
      "train loss: 0.2239992916584015 train AUC: 0.881827329802445\n",
      "Epoch 00044: reducing learning rate of group 0 to 3.5937e-05.\n",
      "val loss: 0.22755396366119385 val AUC: 0.88052654087711\n",
      "epoch: 44\n",
      "train loss: 0.22345051169395447 train AUC: 0.8827312441128841\n",
      "val loss: 0.22704215347766876 val AUC: 0.8791572962343323\n",
      "epoch: 45\n",
      "train loss: 0.22353322803974152 train AUC: 0.8829879789092213\n",
      "val loss: 0.22704917192459106 val AUC: 0.8795048332163699\n",
      "epoch: 46\n",
      "train loss: 0.2226952612400055 train AUC: 0.8830636239420676\n",
      "val loss: 0.2267874926328659 val AUC: 0.879723778746757\n",
      "epoch: 47\n",
      "train loss: 0.2231685072183609 train AUC: 0.8833175321968743\n",
      "val loss: 0.22686076164245605 val AUC: 0.8798284102395987\n",
      "epoch: 48\n",
      "train loss: 0.2231724113225937 train AUC: 0.8846860028699614\n",
      "val loss: 0.22674685716629028 val AUC: 0.878622928693459\n",
      "epoch: 49\n",
      "train loss: 0.22356919944286346 train AUC: 0.8829513491477192\n",
      "val loss: 0.228105828166008 val AUC: 0.8794181002670115\n",
      "fold: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3009647187e64b49a9d9d91e34979a16"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train loss: 0.6416073441505432 train AUC: 0.7210488910036079\n",
      "val loss: 0.631040096282959 val AUC: 0.7869336716623104\n",
      "best checkpoint updated\n",
      "epoch: 1\n",
      "train loss: 0.5836992859840393 train AUC: 0.7816580769446548\n",
      "val loss: 0.5562042593955994 val AUC: 0.8138007784807261\n",
      "best checkpoint updated\n",
      "epoch: 2\n",
      "train loss: 0.5372644066810608 train AUC: 0.791545116578916\n",
      "val loss: 0.4930833876132965 val AUC: 0.8252877667878514\n",
      "best checkpoint updated\n",
      "epoch: 3\n",
      "train loss: 0.473154753446579 train AUC: 0.7945282288415032\n",
      "val loss: 0.43294820189476013 val AUC: 0.8237683216599523\n",
      "best checkpoint updated\n",
      "epoch: 4\n",
      "train loss: 0.4047192335128784 train AUC: 0.802098840317\n",
      "val loss: 0.37173864245414734 val AUC: 0.8383386809037816\n",
      "best checkpoint updated\n",
      "epoch: 5\n",
      "train loss: 0.34079769253730774 train AUC: 0.8042332409938563\n",
      "val loss: 0.31101492047309875 val AUC: 0.8454857337264569\n",
      "best checkpoint updated\n",
      "epoch: 6\n",
      "train loss: 0.30650362372398376 train AUC: 0.8165753178802818\n",
      "val loss: 0.28773757815361023 val AUC: 0.8495003779606046\n",
      "best checkpoint updated\n",
      "epoch: 7\n",
      "train loss: 0.27880844473838806 train AUC: 0.8289593734629191\n",
      "val loss: 0.2639221251010895 val AUC: 0.8524886788703824\n",
      "best checkpoint updated\n",
      "epoch: 8\n",
      "train loss: 0.2656891942024231 train AUC: 0.831967457265197\n",
      "val loss: 0.2597101032733917 val AUC: 0.8552895284638969\n",
      "best checkpoint updated\n",
      "epoch: 9\n",
      "train loss: 0.25603586435317993 train AUC: 0.8404482725512225\n",
      "val loss: 0.24720896780490875 val AUC: 0.8554423882327176\n",
      "best checkpoint updated\n",
      "epoch: 10\n",
      "train loss: 0.2491709142923355 train AUC: 0.8469914357092001\n",
      "val loss: 0.24246370792388916 val AUC: 0.858467528217122\n",
      "best checkpoint updated\n",
      "epoch: 11\n",
      "train loss: 0.24468635022640228 train AUC: 0.8522478363586505\n",
      "val loss: 0.24017900228500366 val AUC: 0.8622948253897961\n",
      "best checkpoint updated\n",
      "epoch: 12\n",
      "train loss: 0.2420629858970642 train AUC: 0.8556989709375712\n",
      "val loss: 0.23813728988170624 val AUC: 0.8630331694214917\n",
      "best checkpoint updated\n",
      "epoch: 13\n",
      "train loss: 0.23947001993656158 train AUC: 0.8556351310200598\n",
      "val loss: 0.23893336951732635 val AUC: 0.865190815328453\n",
      "epoch: 14\n",
      "train loss: 0.23740795254707336 train AUC: 0.8615392216766128\n",
      "val loss: 0.23688898980617523 val AUC: 0.8660110377154869\n",
      "best checkpoint updated\n",
      "epoch: 15\n",
      "train loss: 0.2366529405117035 train AUC: 0.8637315131752691\n",
      "val loss: 0.23550860583782196 val AUC: 0.8646773163978939\n",
      "best checkpoint updated\n",
      "epoch: 16\n",
      "train loss: 0.23531337082386017 train AUC: 0.8651919834377513\n",
      "val loss: 0.23534531891345978 val AUC: 0.864971807126353\n",
      "best checkpoint updated\n",
      "epoch: 17\n",
      "train loss: 0.2342618703842163 train AUC: 0.8659591931521251\n",
      "val loss: 0.2343849390745163 val AUC: 0.8654408916758488\n",
      "best checkpoint updated\n",
      "epoch: 18\n",
      "train loss: 0.23265253007411957 train AUC: 0.8692324012316591\n",
      "val loss: 0.2343818098306656 val AUC: 0.8663641322535325\n",
      "best checkpoint updated\n",
      "epoch: 19\n",
      "train loss: 0.23189835250377655 train AUC: 0.869835164354318\n",
      "val loss: 0.23412925004959106 val AUC: 0.8649371054729249\n",
      "best checkpoint updated\n",
      "epoch: 20\n",
      "train loss: 0.23163190484046936 train AUC: 0.8691413328921378\n",
      "val loss: 0.2333083599805832 val AUC: 0.8658322615329227\n",
      "best checkpoint updated\n",
      "epoch: 21\n",
      "train loss: 0.23013707995414734 train AUC: 0.8743292994017744\n",
      "val loss: 0.23355959355831146 val AUC: 0.8680744833658177\n",
      "epoch: 22\n",
      "train loss: 0.2289929836988449 train AUC: 0.8753738732563641\n",
      "val loss: 0.23243439197540283 val AUC: 0.8664783575096564\n",
      "best checkpoint updated\n",
      "epoch: 23\n",
      "train loss: 0.22832979261875153 train AUC: 0.8755570727178181\n",
      "val loss: 0.23110640048980713 val AUC: 0.8682944358737285\n",
      "best checkpoint updated\n",
      "epoch: 24\n",
      "train loss: 0.2282668948173523 train AUC: 0.8752534123463132\n",
      "val loss: 0.23195068538188934 val AUC: 0.8672707523378618\n",
      "epoch: 25\n",
      "train loss: 0.22701051831245422 train AUC: 0.8783501961146385\n",
      "val loss: 0.23224188387393951 val AUC: 0.866467627442031\n",
      "epoch: 26\n",
      "train loss: 0.22693465650081635 train AUC: 0.8786650665328085\n",
      "val loss: 0.2314075082540512 val AUC: 0.8682156273274892\n",
      "epoch: 27\n",
      "train loss: 0.22608308494091034 train AUC: 0.8781858144170676\n",
      "Epoch 00028: reducing learning rate of group 0 to 3.3000e-04.\n",
      "val loss: 0.23258638381958008 val AUC: 0.8663883701780001\n",
      "epoch: 28\n",
      "train loss: 0.22513335943222046 train AUC: 0.8823421055493434\n",
      "val loss: 0.23178599774837494 val AUC: 0.8670878643895317\n",
      "epoch: 29\n",
      "train loss: 0.2235291600227356 train AUC: 0.8842497727268872\n",
      "val loss: 0.23071593046188354 val AUC: 0.868790211054011\n",
      "best checkpoint updated\n",
      "epoch: 30\n",
      "train loss: 0.223297581076622 train AUC: 0.8846329855986439\n",
      "val loss: 0.23097221553325653 val AUC: 0.8703499821476867\n",
      "epoch: 31\n",
      "train loss: 0.22344699501991272 train AUC: 0.8837922785154961\n",
      "val loss: 0.23091010749340057 val AUC: 0.8691033135515053\n",
      "epoch: 32\n",
      "train loss: 0.22325147688388824 train AUC: 0.8843187456036632\n",
      "val loss: 0.23112939298152924 val AUC: 0.8682408597013023\n",
      "epoch: 33\n",
      "train loss: 0.22282461822032928 train AUC: 0.8861889138778011\n",
      "val loss: 0.2309180051088333 val AUC: 0.8692922405505684\n",
      "epoch: 34\n",
      "train loss: 0.22175098955631256 train AUC: 0.8865621947959775\n",
      "Epoch 00035: reducing learning rate of group 0 to 1.0890e-04.\n",
      "val loss: 0.23130790889263153 val AUC: 0.8698712460702693\n",
      "epoch: 35\n",
      "train loss: 0.22142565250396729 train AUC: 0.8879618303809536\n",
      "val loss: 0.23132574558258057 val AUC: 0.8693966180249034\n",
      "epoch: 36\n",
      "train loss: 0.22136744856834412 train AUC: 0.8878224593877957\n",
      "val loss: 0.23067206144332886 val AUC: 0.8691764413138369\n",
      "best checkpoint updated\n",
      "epoch: 37\n",
      "train loss: 0.2220480889081955 train AUC: 0.887405827298708\n",
      "val loss: 0.2306521087884903 val AUC: 0.8706021489613626\n",
      "best checkpoint updated\n",
      "epoch: 38\n",
      "train loss: 0.22119739651679993 train AUC: 0.8869752832453921\n",
      "val loss: 0.23012137413024902 val AUC: 0.8717723054446745\n",
      "best checkpoint updated\n",
      "epoch: 39\n",
      "train loss: 0.2213146835565567 train AUC: 0.8873400948568123\n",
      "val loss: 0.23071284592151642 val AUC: 0.8695690881210694\n",
      "epoch: 40\n",
      "train loss: 0.22098670899868011 train AUC: 0.8863804744440372\n",
      "val loss: 0.2302100658416748 val AUC: 0.8708206297927572\n",
      "epoch: 41\n",
      "train loss: 0.22076313197612762 train AUC: 0.8875240280402218\n",
      "val loss: 0.23038338124752045 val AUC: 0.869682452334085\n",
      "epoch: 42\n",
      "train loss: 0.22143451869487762 train AUC: 0.8861031876270329\n",
      "val loss: 0.22989101707935333 val AUC: 0.8704775126922396\n",
      "best checkpoint updated\n",
      "epoch: 43\n",
      "train loss: 0.22060716152191162 train AUC: 0.8896903156642026\n",
      "val loss: 0.22950364649295807 val AUC: 0.8705475659134557\n",
      "best checkpoint updated\n",
      "epoch: 44\n",
      "train loss: 0.22087442874908447 train AUC: 0.8891217187254931\n",
      "val loss: 0.2302592396736145 val AUC: 0.8704561245278094\n",
      "epoch: 45\n",
      "train loss: 0.2217465192079544 train AUC: 0.8880851499613078\n",
      "val loss: 0.2315344214439392 val AUC: 0.8689652133504328\n",
      "epoch: 46\n",
      "train loss: 0.22064127027988434 train AUC: 0.888841087523131\n",
      "val loss: 0.2310464233160019 val AUC: 0.8699726426509535\n",
      "epoch: 47\n",
      "train loss: 0.2204892486333847 train AUC: 0.888464747792939\n",
      "Epoch 00048: reducing learning rate of group 0 to 3.5937e-05.\n",
      "val loss: 0.23085863888263702 val AUC: 0.8695670254352468\n",
      "epoch: 48\n",
      "train loss: 0.22055716812610626 train AUC: 0.8889933279828723\n",
      "val loss: 0.23020809888839722 val AUC: 0.8704621644900942\n",
      "epoch: 49\n",
      "train loss: 0.22024571895599365 train AUC: 0.8881051414758048\n",
      "val loss: 0.23072795569896698 val AUC: 0.8698244995406462\n",
      "repeat: 2\n",
      "fold: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dede847be8c34d0eb1a421d5d2dba338"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train loss: 0.666463315486908 train AUC: 0.7214961629399411\n",
      "val loss: 0.6504760980606079 val AUC: 0.7912350068394899\n",
      "best checkpoint updated\n",
      "epoch: 1\n",
      "train loss: 0.6066562533378601 train AUC: 0.7843592756375137\n",
      "val loss: 0.5738229751586914 val AUC: 0.8210314945591753\n",
      "best checkpoint updated\n",
      "epoch: 2\n",
      "train loss: 0.5593487024307251 train AUC: 0.7932167163566552\n",
      "val loss: 0.5163301229476929 val AUC: 0.8304913407686646\n",
      "best checkpoint updated\n",
      "epoch: 3\n",
      "train loss: 0.49409905076026917 train AUC: 0.7977944493095299\n",
      "val loss: 0.44765856862068176 val AUC: 0.8370527020944426\n",
      "best checkpoint updated\n",
      "epoch: 4\n",
      "train loss: 0.4183894395828247 train AUC: 0.8017316698615982\n",
      "val loss: 0.37071502208709717 val AUC: 0.835394085886461\n",
      "best checkpoint updated\n",
      "epoch: 5\n",
      "train loss: 0.3539106845855713 train AUC: 0.805687385106525\n",
      "val loss: 0.31628501415252686 val AUC: 0.8479575051855185\n",
      "best checkpoint updated\n",
      "epoch: 6\n",
      "train loss: 0.3089357018470764 train AUC: 0.8131550972674692\n",
      "val loss: 0.28231051564216614 val AUC: 0.8547109645555316\n",
      "best checkpoint updated\n",
      "epoch: 7\n",
      "train loss: 0.28189924359321594 train AUC: 0.8253844925321293\n",
      "val loss: 0.2635572850704193 val AUC: 0.8578813037602414\n",
      "best checkpoint updated\n",
      "epoch: 8\n",
      "train loss: 0.2663797438144684 train AUC: 0.8308195427141236\n",
      "val loss: 0.252104252576828 val AUC: 0.8590525879191334\n",
      "best checkpoint updated\n",
      "epoch: 9\n",
      "train loss: 0.2564000189304352 train AUC: 0.8410244176032928\n",
      "val loss: 0.2490043193101883 val AUC: 0.8607611300026471\n",
      "best checkpoint updated\n",
      "epoch: 10\n",
      "train loss: 0.251076340675354 train AUC: 0.8466336343223678\n",
      "val loss: 0.24161265790462494 val AUC: 0.8634920322052985\n",
      "best checkpoint updated\n",
      "epoch: 11\n",
      "train loss: 0.24603857100009918 train AUC: 0.8524176846509078\n",
      "val loss: 0.2398137003183365 val AUC: 0.8636577640870953\n",
      "best checkpoint updated\n",
      "epoch: 12\n",
      "train loss: 0.24362456798553467 train AUC: 0.8576370235180921\n",
      "val loss: 0.23625357449054718 val AUC: 0.8680692968711551\n",
      "best checkpoint updated\n",
      "epoch: 13\n",
      "train loss: 0.24046270549297333 train AUC: 0.8571783539482608\n",
      "val loss: 0.2348371148109436 val AUC: 0.8673903664808634\n",
      "best checkpoint updated\n",
      "epoch: 14\n",
      "train loss: 0.23839275538921356 train AUC: 0.8642483456121282\n",
      "val loss: 0.23496031761169434 val AUC: 0.8663497940572288\n",
      "epoch: 15\n",
      "train loss: 0.23790402710437775 train AUC: 0.859710073501376\n",
      "val loss: 0.23491744697093964 val AUC: 0.8672216019769627\n",
      "epoch: 16\n",
      "train loss: 0.23616516590118408 train AUC: 0.8657238045117827\n",
      "val loss: 0.23342399299144745 val AUC: 0.869544253616023\n",
      "best checkpoint updated\n",
      "epoch: 17\n",
      "train loss: 0.2344241738319397 train AUC: 0.867759975223752\n",
      "val loss: 0.2329387068748474 val AUC: 0.8672340125752451\n",
      "best checkpoint updated\n",
      "epoch: 18\n",
      "train loss: 0.23316790163516998 train AUC: 0.8702189516416692\n",
      "val loss: 0.232865571975708 val AUC: 0.8668403084748562\n",
      "best checkpoint updated\n",
      "epoch: 19\n",
      "train loss: 0.23280362784862518 train AUC: 0.8693429560798731\n",
      "val loss: 0.2322653979063034 val AUC: 0.8687765973899833\n",
      "best checkpoint updated\n",
      "epoch: 20\n",
      "train loss: 0.23205627501010895 train AUC: 0.8730912401475499\n",
      "val loss: 0.2317826896905899 val AUC: 0.8677509109736543\n",
      "best checkpoint updated\n",
      "epoch: 21\n",
      "train loss: 0.22966548800468445 train AUC: 0.8761245954887862\n",
      "val loss: 0.2321852594614029 val AUC: 0.8709098788644097\n",
      "epoch: 22\n",
      "train loss: 0.22974373400211334 train AUC: 0.8756449009860583\n",
      "val loss: 0.23152340948581696 val AUC: 0.8706548435151203\n",
      "best checkpoint updated\n",
      "epoch: 23\n",
      "train loss: 0.22907906770706177 train AUC: 0.876767085265773\n",
      "val loss: 0.23055033385753632 val AUC: 0.8682583187109415\n",
      "best checkpoint updated\n",
      "epoch: 24\n",
      "train loss: 0.22880403697490692 train AUC: 0.879454991735685\n",
      "val loss: 0.23212836682796478 val AUC: 0.8663485559800465\n",
      "epoch: 25\n",
      "train loss: 0.22880464792251587 train AUC: 0.8779499225790106\n",
      "val loss: 0.23120389878749847 val AUC: 0.8673509755806564\n",
      "epoch: 26\n",
      "train loss: 0.2280488908290863 train AUC: 0.8775296701925361\n",
      "val loss: 0.2298949956893921 val AUC: 0.8710384633781\n",
      "best checkpoint updated\n",
      "epoch: 27\n",
      "train loss: 0.22661282122135162 train AUC: 0.8798010566034081\n",
      "val loss: 0.23177570104599 val AUC: 0.8721652005487176\n",
      "epoch: 28\n",
      "train loss: 0.22659969329833984 train AUC: 0.8822712200025158\n",
      "val loss: 0.23194511234760284 val AUC: 0.8658146516714136\n",
      "epoch: 29\n",
      "train loss: 0.22582252323627472 train AUC: 0.8834996262108455\n",
      "val loss: 0.23170064389705658 val AUC: 0.8694368747831999\n",
      "epoch: 30\n",
      "train loss: 0.2253747433423996 train AUC: 0.8824508392519218\n",
      "Epoch 00031: reducing learning rate of group 0 to 3.3000e-04.\n",
      "val loss: 0.23179791867733002 val AUC: 0.8712286636750557\n",
      "epoch: 31\n",
      "train loss: 0.22417157888412476 train AUC: 0.8860887966751322\n",
      "val loss: 0.23030245304107666 val AUC: 0.8701218805005292\n",
      "epoch: 32\n",
      "train loss: 0.22266151010990143 train AUC: 0.8869433210652866\n",
      "val loss: 0.22927109897136688 val AUC: 0.8719478427873343\n",
      "best checkpoint updated\n",
      "epoch: 33\n",
      "train loss: 0.22207437455654144 train AUC: 0.8879847097003711\n",
      "val loss: 0.2299361675977707 val AUC: 0.8714915566615651\n",
      "epoch: 34\n",
      "train loss: 0.22273065149784088 train AUC: 0.8863967468777109\n",
      "val loss: 0.22955574095249176 val AUC: 0.8701334337442758\n",
      "epoch: 35\n",
      "train loss: 0.22268640995025635 train AUC: 0.8865702780506232\n",
      "val loss: 0.2298402041196823 val AUC: 0.869709151634727\n",
      "epoch: 36\n",
      "train loss: 0.22213827073574066 train AUC: 0.8862975032498162\n",
      "val loss: 0.22916996479034424 val AUC: 0.8718597612220185\n",
      "best checkpoint updated\n",
      "epoch: 37\n",
      "train loss: 0.22132991254329681 train AUC: 0.8882475352954151\n",
      "val loss: 0.22930563986301422 val AUC: 0.87252996572811\n",
      "epoch: 38\n",
      "train loss: 0.2209721952676773 train AUC: 0.8889139310693775\n",
      "val loss: 0.2299874871969223 val AUC: 0.871642555876739\n",
      "epoch: 39\n",
      "train loss: 0.22142450511455536 train AUC: 0.8907313595507855\n",
      "val loss: 0.23063957691192627 val AUC: 0.8695663644335325\n",
      "epoch: 40\n",
      "train loss: 0.22072497010231018 train AUC: 0.88943729728856\n",
      "Epoch 00041: reducing learning rate of group 0 to 1.0890e-04.\n",
      "val loss: 0.22998930513858795 val AUC: 0.8702685698877811\n",
      "epoch: 41\n",
      "train loss: 0.21995143592357635 train AUC: 0.8908801383820854\n",
      "val loss: 0.2301011085510254 val AUC: 0.8688904436480871\n",
      "epoch: 42\n",
      "train loss: 0.21967563033103943 train AUC: 0.8906870059009695\n",
      "val loss: 0.22955107688903809 val AUC: 0.8714487727617812\n",
      "epoch: 43\n",
      "train loss: 0.21912288665771484 train AUC: 0.8918913896697443\n",
      "val loss: 0.23013286292552948 val AUC: 0.8713723602046572\n",
      "epoch: 44\n",
      "train loss: 0.21921101212501526 train AUC: 0.8917559801209053\n",
      "val loss: 0.23120371997356415 val AUC: 0.8688004298373794\n",
      "epoch: 45\n",
      "train loss: 0.21956005692481995 train AUC: 0.8919389565322058\n",
      "val loss: 0.23076951503753662 val AUC: 0.8673770960837395\n",
      "epoch: 46\n",
      "train loss: 0.2189282923936844 train AUC: 0.8917333923296578\n",
      "val loss: 0.2302989512681961 val AUC: 0.8695131145769645\n",
      "epoch: 47\n",
      "train loss: 0.21938765048980713 train AUC: 0.8927455413218226\n",
      "Epoch 00048: reducing learning rate of group 0 to 3.5937e-05.\n",
      "val loss: 0.2301715612411499 val AUC: 0.8697959211167773\n",
      "epoch: 48\n",
      "train loss: 0.2195691168308258 train AUC: 0.8916340412230243\n",
      "val loss: 0.23093020915985107 val AUC: 0.8703705049954414\n",
      "epoch: 49\n",
      "train loss: 0.21913737058639526 train AUC: 0.8910758972224749\n",
      "val loss: 0.23076240718364716 val AUC: 0.8696370639716275\n",
      "fold: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9e8115bc10c448aa2bb1f538b6e4bb9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train loss: 0.6474987864494324 train AUC: 0.7345427769853816\n",
      "val loss: 0.6387002468109131 val AUC: 0.7733859628591141\n",
      "best checkpoint updated\n",
      "epoch: 1\n",
      "train loss: 0.5932794809341431 train AUC: 0.7830088147723964\n",
      "val loss: 0.5572831034660339 val AUC: 0.8274675409541726\n",
      "best checkpoint updated\n",
      "epoch: 2\n",
      "train loss: 0.5430582165718079 train AUC: 0.798857294490543\n",
      "val loss: 0.4947735369205475 val AUC: 0.8363252108307827\n",
      "best checkpoint updated\n",
      "epoch: 3\n",
      "train loss: 0.47787773609161377 train AUC: 0.7953283713184188\n",
      "val loss: 0.4175068140029907 val AUC: 0.848389006685708\n",
      "best checkpoint updated\n",
      "epoch: 4\n",
      "train loss: 0.4038950204849243 train AUC: 0.8052066722954936\n",
      "val loss: 0.3768129050731659 val AUC: 0.8451130245558341\n",
      "best checkpoint updated\n",
      "epoch: 5\n",
      "train loss: 0.34146472811698914 train AUC: 0.810558533423802\n",
      "val loss: 0.32505980134010315 val AUC: 0.8502037412833433\n",
      "best checkpoint updated\n",
      "epoch: 6\n",
      "train loss: 0.3042070269584656 train AUC: 0.8155587744395139\n",
      "val loss: 0.31225088238716125 val AUC: 0.8571178743081175\n",
      "best checkpoint updated\n",
      "epoch: 7\n",
      "train loss: 0.2788669466972351 train AUC: 0.8211648834992237\n",
      "val loss: 0.2633926570415497 val AUC: 0.8605789381416612\n",
      "best checkpoint updated\n",
      "epoch: 8\n",
      "train loss: 0.2636464834213257 train AUC: 0.8303928138510579\n",
      "val loss: 0.2554176151752472 val AUC: 0.8632790848243553\n",
      "best checkpoint updated\n",
      "epoch: 9\n",
      "train loss: 0.25498244166374207 train AUC: 0.8382577769554252\n",
      "val loss: 0.2453937977552414 val AUC: 0.8642287943233647\n",
      "best checkpoint updated\n",
      "epoch: 10\n",
      "train loss: 0.2489304095506668 train AUC: 0.84422240962226\n",
      "val loss: 0.24386125802993774 val AUC: 0.8639586449095166\n",
      "best checkpoint updated\n",
      "epoch: 11\n",
      "train loss: 0.24552305042743683 train AUC: 0.8527361886668693\n",
      "val loss: 0.23915736377239227 val AUC: 0.868327377670867\n",
      "best checkpoint updated\n",
      "epoch: 12\n",
      "train loss: 0.2426609992980957 train AUC: 0.8536817348175955\n",
      "val loss: 0.23642325401306152 val AUC: 0.8699213595364631\n",
      "best checkpoint updated\n",
      "epoch: 13\n",
      "train loss: 0.23960642516613007 train AUC: 0.8592625086539889\n",
      "val loss: 0.23458324372768402 val AUC: 0.8711764450352003\n",
      "best checkpoint updated\n",
      "epoch: 14\n",
      "train loss: 0.23864631354808807 train AUC: 0.85719276147772\n",
      "val loss: 0.23461724817752838 val AUC: 0.8701510464726564\n",
      "epoch: 15\n",
      "train loss: 0.23624439537525177 train AUC: 0.8610547087022025\n",
      "val loss: 0.23290912806987762 val AUC: 0.8732052388462157\n",
      "best checkpoint updated\n",
      "epoch: 16\n",
      "train loss: 0.23527541756629944 train AUC: 0.8633554162329709\n",
      "val loss: 0.23345305025577545 val AUC: 0.8713643019060883\n",
      "epoch: 17\n",
      "train loss: 0.23415525257587433 train AUC: 0.8680979345416446\n",
      "val loss: 0.23366765677928925 val AUC: 0.8704972538769243\n",
      "epoch: 18\n",
      "train loss: 0.2331516444683075 train AUC: 0.8683829660400617\n",
      "val loss: 0.23155008256435394 val AUC: 0.8716113416494072\n",
      "best checkpoint updated\n",
      "epoch: 19\n",
      "train loss: 0.23227207362651825 train AUC: 0.8686429706913432\n",
      "val loss: 0.23182524740695953 val AUC: 0.8751789024746515\n",
      "epoch: 20\n",
      "train loss: 0.23121792078018188 train AUC: 0.8706127270530233\n",
      "val loss: 0.23217511177062988 val AUC: 0.8736522988842198\n",
      "epoch: 21\n",
      "train loss: 0.23034721612930298 train AUC: 0.8710106917346385\n",
      "val loss: 0.22986042499542236 val AUC: 0.8736335858341694\n",
      "best checkpoint updated\n",
      "epoch: 22\n",
      "train loss: 0.22973740100860596 train AUC: 0.8740863055074697\n",
      "val loss: 0.23076540231704712 val AUC: 0.8761659046685932\n",
      "epoch: 23\n",
      "train loss: 0.22916318476200104 train AUC: 0.8752472149467638\n",
      "val loss: 0.23079152405261993 val AUC: 0.872724455147624\n",
      "epoch: 24\n",
      "train loss: 0.22850240767002106 train AUC: 0.875754256757677\n",
      "val loss: 0.231329083442688 val AUC: 0.8741447897600351\n",
      "epoch: 25\n",
      "train loss: 0.22859762609004974 train AUC: 0.8755510293075055\n",
      "Epoch 00026: reducing learning rate of group 0 to 3.3000e-04.\n",
      "val loss: 0.23113568127155304 val AUC: 0.8727009059274012\n",
      "epoch: 26\n",
      "train loss: 0.2268633395433426 train AUC: 0.8776396786508134\n",
      "val loss: 0.22946912050247192 val AUC: 0.8749028205982016\n",
      "best checkpoint updated\n",
      "epoch: 27\n",
      "train loss: 0.22565051913261414 train AUC: 0.8796794123350405\n",
      "val loss: 0.22989003360271454 val AUC: 0.8749361405588796\n",
      "epoch: 28\n",
      "train loss: 0.22445283830165863 train AUC: 0.8800575111603389\n",
      "val loss: 0.2289019078016281 val AUC: 0.8743010986532945\n",
      "best checkpoint updated\n",
      "epoch: 29\n",
      "train loss: 0.22543592751026154 train AUC: 0.8788591876233224\n",
      "val loss: 0.22867001593112946 val AUC: 0.8767203149017355\n",
      "best checkpoint updated\n",
      "epoch: 30\n",
      "train loss: 0.225509375333786 train AUC: 0.8802001977099555\n",
      "val loss: 0.2301691621541977 val AUC: 0.8752031014980735\n",
      "epoch: 31\n",
      "train loss: 0.22480282187461853 train AUC: 0.8817638587139109\n",
      "val loss: 0.22937358915805817 val AUC: 0.8748049777651681\n",
      "epoch: 32\n",
      "train loss: 0.22428010404109955 train AUC: 0.8821804432108047\n",
      "val loss: 0.2296290397644043 val AUC: 0.874827596731789\n",
      "epoch: 33\n",
      "train loss: 0.22450105845928192 train AUC: 0.8810120700862598\n",
      "Epoch 00034: reducing learning rate of group 0 to 1.0890e-04.\n",
      "val loss: 0.22961604595184326 val AUC: 0.8772475411982174\n",
      "epoch: 34\n",
      "train loss: 0.2241383045911789 train AUC: 0.8831478357838976\n",
      "val loss: 0.22895805537700653 val AUC: 0.8778536275293902\n",
      "epoch: 35\n",
      "train loss: 0.22270774841308594 train AUC: 0.8821442944828836\n",
      "val loss: 0.22872395813465118 val AUC: 0.8764140030510118\n",
      "epoch: 36\n",
      "train loss: 0.22282791137695312 train AUC: 0.8829912402025312\n",
      "val loss: 0.22968383133411407 val AUC: 0.8764290923308998\n",
      "epoch: 37\n",
      "train loss: 0.2238343358039856 train AUC: 0.8835204543001446\n",
      "val loss: 0.22930024564266205 val AUC: 0.8756864169589841\n",
      "epoch: 38\n",
      "train loss: 0.22296136617660522 train AUC: 0.8838291183865336\n",
      "val loss: 0.2293841689825058 val AUC: 0.8754469009630007\n",
      "epoch: 39\n",
      "train loss: 0.2227940559387207 train AUC: 0.8829961061905798\n",
      "val loss: 0.22934888303279877 val AUC: 0.8763522841467261\n",
      "epoch: 40\n",
      "train loss: 0.22317098081111908 train AUC: 0.883441010003309\n",
      "Epoch 00041: reducing learning rate of group 0 to 3.5937e-05.\n",
      "val loss: 0.22895294427871704 val AUC: 0.8752276514634832\n",
      "epoch: 41\n",
      "train loss: 0.22219711542129517 train AUC: 0.885138455559189\n",
      "val loss: 0.22887635231018066 val AUC: 0.8771051057065207\n",
      "epoch: 42\n",
      "train loss: 0.22249223291873932 train AUC: 0.8842835057039475\n",
      "val loss: 0.22915904223918915 val AUC: 0.8746036343270407\n",
      "epoch: 43\n",
      "train loss: 0.22285766899585724 train AUC: 0.8835553546907099\n",
      "val loss: 0.2295520305633545 val AUC: 0.8761704642551535\n",
      "epoch: 44\n",
      "train loss: 0.221727192401886 train AUC: 0.8860294860202046\n",
      "val loss: 0.22906632721424103 val AUC: 0.8765152168109993\n",
      "epoch: 45\n",
      "train loss: 0.2232019305229187 train AUC: 0.8829051253866773\n",
      "val loss: 0.22901220619678497 val AUC: 0.8770308139859675\n",
      "epoch: 46\n",
      "train loss: 0.2227969616651535 train AUC: 0.8848479366755749\n",
      "val loss: 0.22862784564495087 val AUC: 0.8758795272413807\n",
      "best checkpoint updated\n",
      "epoch: 47\n",
      "train loss: 0.22193486988544464 train AUC: 0.885401741127249\n",
      "val loss: 0.22907902300357819 val AUC: 0.8759247647934975\n",
      "epoch: 48\n",
      "train loss: 0.22187210619449615 train AUC: 0.8859910341677021\n",
      "val loss: 0.2294251173734665 val AUC: 0.8769817729968272\n",
      "epoch: 49\n",
      "train loss: 0.2219771146774292 train AUC: 0.8847471830084693\n",
      "val loss: 0.23028890788555145 val AUC: 0.8745235709203368\n",
      "fold: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "639c995cd23e4d5b92933017e51eb2ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train loss: 0.6539062261581421 train AUC: 0.7252673108486125\n",
      "val loss: 0.6417168974876404 val AUC: 0.7823715845153169\n",
      "best checkpoint updated\n",
      "epoch: 1\n",
      "train loss: 0.5954564809799194 train AUC: 0.7839793965087631\n",
      "val loss: 0.5548148155212402 val AUC: 0.8118465886202649\n",
      "best checkpoint updated\n",
      "epoch: 2\n",
      "train loss: 0.548616886138916 train AUC: 0.790397561810151\n",
      "val loss: 0.49916598200798035 val AUC: 0.8348581446008012\n",
      "best checkpoint updated\n",
      "epoch: 3\n",
      "train loss: 0.48421671986579895 train AUC: 0.7994962309941497\n",
      "val loss: 0.4385284185409546 val AUC: 0.8382663771139137\n",
      "best checkpoint updated\n",
      "epoch: 4\n",
      "train loss: 0.41081658005714417 train AUC: 0.7984596780013866\n",
      "val loss: 0.3641849756240845 val AUC: 0.850181671849141\n",
      "best checkpoint updated\n",
      "epoch: 5\n",
      "train loss: 0.34831303358078003 train AUC: 0.7986093184644798\n",
      "val loss: 0.3102281391620636 val AUC: 0.8517128622054747\n",
      "best checkpoint updated\n",
      "epoch: 6\n",
      "train loss: 0.3043479323387146 train AUC: 0.8106704317034819\n",
      "val loss: 0.2824123799800873 val AUC: 0.8565418100594343\n",
      "best checkpoint updated\n",
      "epoch: 7\n",
      "train loss: 0.2798408269882202 train AUC: 0.820888871323965\n",
      "val loss: 0.2621830999851227 val AUC: 0.8612527760844384\n",
      "best checkpoint updated\n",
      "epoch: 8\n",
      "train loss: 0.26522138714790344 train AUC: 0.827600426986493\n",
      "val loss: 0.2521800696849823 val AUC: 0.8603334955032654\n",
      "best checkpoint updated\n",
      "epoch: 9\n",
      "train loss: 0.2565991282463074 train AUC: 0.8325983558819758\n",
      "val loss: 0.2467638999223709 val AUC: 0.8618617926871969\n",
      "best checkpoint updated\n",
      "epoch: 10\n",
      "train loss: 0.24977965652942657 train AUC: 0.8426569708266721\n",
      "val loss: 0.24071140587329865 val AUC: 0.8655237631743674\n",
      "best checkpoint updated\n",
      "epoch: 11\n",
      "train loss: 0.24585524201393127 train AUC: 0.8477963358418726\n",
      "val loss: 0.2386579066514969 val AUC: 0.8684608294046293\n",
      "best checkpoint updated\n",
      "epoch: 12\n",
      "train loss: 0.24444721639156342 train AUC: 0.8519526905530037\n",
      "val loss: 0.2366194874048233 val AUC: 0.8689637396520903\n",
      "best checkpoint updated\n",
      "epoch: 13\n",
      "train loss: 0.2406693696975708 train AUC: 0.8575272950256878\n",
      "val loss: 0.23542730510234833 val AUC: 0.869469327543459\n",
      "best checkpoint updated\n",
      "epoch: 14\n",
      "train loss: 0.23926687240600586 train AUC: 0.8551983519744928\n",
      "val loss: 0.2341901659965515 val AUC: 0.8711682862330022\n",
      "best checkpoint updated\n",
      "epoch: 15\n",
      "train loss: 0.23840568959712982 train AUC: 0.8589255648249224\n",
      "val loss: 0.23468905687332153 val AUC: 0.8693684083280941\n",
      "epoch: 16\n",
      "train loss: 0.23647810518741608 train AUC: 0.8622379168027581\n",
      "val loss: 0.2321671098470688 val AUC: 0.8735342703984011\n",
      "best checkpoint updated\n",
      "epoch: 17\n",
      "train loss: 0.23532140254974365 train AUC: 0.8657221028855137\n",
      "val loss: 0.2321520447731018 val AUC: 0.8747508201635137\n",
      "best checkpoint updated\n",
      "epoch: 18\n",
      "train loss: 0.23349927365779877 train AUC: 0.8679023013437183\n",
      "val loss: 0.23071420192718506 val AUC: 0.8753648785428219\n",
      "best checkpoint updated\n",
      "epoch: 19\n",
      "train loss: 0.23375506699085236 train AUC: 0.8692560251385126\n",
      "val loss: 0.23062919080257416 val AUC: 0.8769087581191574\n",
      "best checkpoint updated\n",
      "epoch: 20\n",
      "train loss: 0.23171445727348328 train AUC: 0.8722667054000045\n",
      "val loss: 0.23064512014389038 val AUC: 0.874446891393157\n",
      "epoch: 21\n",
      "train loss: 0.2316441535949707 train AUC: 0.8705233503532135\n",
      "val loss: 0.2299831062555313 val AUC: 0.8738572672572368\n",
      "best checkpoint updated\n",
      "epoch: 22\n",
      "train loss: 0.23008272051811218 train AUC: 0.8736774769749762\n",
      "val loss: 0.23057977855205536 val AUC: 0.8746443716719964\n",
      "epoch: 23\n",
      "train loss: 0.22968736290931702 train AUC: 0.871889497425471\n",
      "val loss: 0.23164181411266327 val AUC: 0.8751417145330582\n",
      "epoch: 24\n",
      "train loss: 0.22960937023162842 train AUC: 0.8732993667600591\n",
      "val loss: 0.22977237403392792 val AUC: 0.873248079848956\n",
      "best checkpoint updated\n",
      "epoch: 25\n",
      "train loss: 0.22904087603092194 train AUC: 0.8745177521374069\n",
      "val loss: 0.22954080998897552 val AUC: 0.8771784173401115\n",
      "best checkpoint updated\n",
      "epoch: 26\n",
      "train loss: 0.22820787131786346 train AUC: 0.8753943268725586\n",
      "val loss: 0.23011012375354767 val AUC: 0.8723473009705632\n",
      "epoch: 27\n",
      "train loss: 0.22909143567085266 train AUC: 0.8742579748426212\n",
      "val loss: 0.22998417913913727 val AUC: 0.8734993635869741\n",
      "epoch: 28\n",
      "train loss: 0.22715400159358978 train AUC: 0.8763635409698636\n",
      "val loss: 0.2293635457754135 val AUC: 0.8765317900054748\n",
      "best checkpoint updated\n",
      "epoch: 29\n",
      "train loss: 0.2265520691871643 train AUC: 0.8780048272933447\n",
      "val loss: 0.22809380292892456 val AUC: 0.8770087920709884\n",
      "best checkpoint updated\n",
      "epoch: 30\n",
      "train loss: 0.22684641182422638 train AUC: 0.878138197864427\n",
      "val loss: 0.23237407207489014 val AUC: 0.8745045802497763\n",
      "epoch: 31\n",
      "train loss: 0.22585353255271912 train AUC: 0.8787557354367148\n",
      "val loss: 0.22950094938278198 val AUC: 0.874654601135321\n",
      "epoch: 32\n",
      "train loss: 0.22562944889068604 train AUC: 0.8800246740220601\n",
      "val loss: 0.2305544763803482 val AUC: 0.8744314564359327\n",
      "epoch: 33\n",
      "train loss: 0.2247503697872162 train AUC: 0.8827219171471598\n",
      "Epoch 00034: reducing learning rate of group 0 to 3.3000e-04.\n",
      "val loss: 0.22826151549816132 val AUC: 0.8773854648001892\n",
      "epoch: 34\n",
      "train loss: 0.22307196259498596 train AUC: 0.8854767223125368\n",
      "val loss: 0.22810101509094238 val AUC: 0.8779473650766034\n",
      "epoch: 35\n",
      "train loss: 0.22337812185287476 train AUC: 0.8831156504670801\n",
      "val loss: 0.22858862578868866 val AUC: 0.8763981980642105\n",
      "epoch: 36\n",
      "train loss: 0.22269828617572784 train AUC: 0.885242746867124\n",
      "val loss: 0.22864800691604614 val AUC: 0.876741536314586\n",
      "epoch: 37\n",
      "train loss: 0.22218988835811615 train AUC: 0.8853136565163205\n",
      "val loss: 0.2277066558599472 val AUC: 0.8787257005994316\n",
      "best checkpoint updated\n",
      "epoch: 38\n",
      "train loss: 0.22121068835258484 train AUC: 0.8874508705367128\n",
      "val loss: 0.2270236611366272 val AUC: 0.8787065105823957\n",
      "best checkpoint updated\n",
      "epoch: 39\n",
      "train loss: 0.22097541391849518 train AUC: 0.8872856643009243\n",
      "val loss: 0.22849251329898834 val AUC: 0.8763430710718253\n",
      "epoch: 40\n",
      "train loss: 0.22078131139278412 train AUC: 0.8865558759895525\n",
      "val loss: 0.22803376615047455 val AUC: 0.8790362924660581\n",
      "epoch: 41\n",
      "train loss: 0.22053377330303192 train AUC: 0.8871685816461601\n",
      "val loss: 0.2285236120223999 val AUC: 0.8765275920016714\n",
      "epoch: 42\n",
      "train loss: 0.22114567458629608 train AUC: 0.8874145790824108\n",
      "Epoch 00043: reducing learning rate of group 0 to 1.0890e-04.\n",
      "val loss: 0.2278537005186081 val AUC: 0.8778832020317647\n",
      "epoch: 43\n",
      "train loss: 0.21946214139461517 train AUC: 0.888684888890944\n",
      "val loss: 0.22861844301223755 val AUC: 0.8772850825428747\n",
      "epoch: 44\n",
      "train loss: 0.21960395574569702 train AUC: 0.8889090332611207\n",
      "val loss: 0.22880695760250092 val AUC: 0.8765472221753479\n",
      "epoch: 45\n",
      "train loss: 0.21921850740909576 train AUC: 0.8898345691816205\n",
      "val loss: 0.22893188893795013 val AUC: 0.8786602054932535\n",
      "epoch: 46\n",
      "train loss: 0.21957936882972717 train AUC: 0.8891527760798579\n",
      "val loss: 0.22781281173229218 val AUC: 0.8773176707810353\n",
      "epoch: 47\n",
      "train loss: 0.21952787041664124 train AUC: 0.8896879317189161\n",
      "val loss: 0.2283707708120346 val AUC: 0.877837848972582\n",
      "epoch: 48\n",
      "train loss: 0.22017112374305725 train AUC: 0.8876983072960932\n",
      "val loss: 0.22833161056041718 val AUC: 0.8770730162520048\n",
      "epoch: 49\n",
      "train loss: 0.2187226265668869 train AUC: 0.8891116780258757\n",
      "Epoch 00050: reducing learning rate of group 0 to 3.5937e-05.\n",
      "val loss: 0.2282048612833023 val AUC: 0.8767325775006617\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "test_preds = []\n",
    "\n",
    "for r in range(3):\n",
    "    print(f'repeat: {r}')\n",
    "\n",
    "    cv = MultilabelStratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "    for i, (t_idx, v_idx) in enumerate(cv.split(X, Y)):\n",
    "        train_x, valid_x = X.loc[t_idx, :], X.loc[v_idx, :]\n",
    "        train_y, valid_y = Y.loc[t_idx, :], Y.loc[v_idx, :]\n",
    "        pred_test = np.zeros((len(test), len(ys)))\n",
    "        best_loss = 1e5\n",
    "\n",
    "        train_dataset = SteelDataset(train_x, train_y)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, drop_last=True)\n",
    "        valid_dataset = SteelDataset(valid_x, valid_y)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=512, shuffle=True, drop_last=True)\n",
    "\n",
    "        loss_func = nn.BCELoss()\n",
    "        model = SteelModel(57, 7).cuda()\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.33, patience=3, cooldown=3,\n",
    "                                                                  verbose=True)\n",
    "\n",
    "        print(f'fold: {i}')\n",
    "\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            runing_t_loss = []\n",
    "            runing_t_auc = []\n",
    "            runing_v_loss = []\n",
    "            runing_v_auc = []\n",
    "\n",
    "            print(f'epoch: {epoch}')\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            for t_x, t_y in train_loader:\n",
    "                t_x = move_to(t_x, device='cuda')\n",
    "                t_y = move_to(t_y, device='cuda')\n",
    "\n",
    "                y_hat = model(t_x)\n",
    "                loss = loss_func(y_hat, t_y)\n",
    "                runing_t_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "                if model.training:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                runing_t_auc.append(\n",
    "                    np.mean(\n",
    "                        [roc_auc_score(t_y.detach().cpu().numpy()[:, i], y_hat.detach().cpu().numpy()[:, i]) for i in\n",
    "                         range(len(ys))]))\n",
    "\n",
    "            print(f'train loss: {np.mean(runing_t_loss)} train AUC: {np.mean(runing_t_auc)}')\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            for v_x, v_y in valid_loader:\n",
    "                v_x = move_to(v_x, device='cuda')\n",
    "                v_y = move_to(v_y, device='cuda')\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    val_hat = model(v_x)\n",
    "                    val_loss = loss_func(val_hat, v_y)\n",
    "                    runing_v_loss.append(val_loss.detach().cpu().numpy())\n",
    "\n",
    "                runing_v_auc.append(\n",
    "                    np.mean(\n",
    "                        [roc_auc_score(v_y.detach().cpu().numpy()[:, i], val_hat.detach().cpu().numpy()[:, i]) for i in\n",
    "                         range(len(ys))]))\n",
    "\n",
    "            lr_scheduler.step(np.mean(runing_v_loss))\n",
    "\n",
    "            print(f'val loss: {np.mean(runing_v_loss)} val AUC: {np.mean(runing_v_auc)}')\n",
    "\n",
    "            if np.mean(runing_v_loss) < best_loss:\n",
    "                best_loss = np.mean(runing_v_loss)\n",
    "\n",
    "                torch.save({'model_state_dict': model.state_dict()}, f'./ann_cps/checkpoint_{r}_{i}.pth')\n",
    "\n",
    "                print('best checkpoint updated')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_pred = model(torch.tensor(test.values, dtype=torch.float32, device='cuda'))\n",
    "\n",
    "        test_preds.append(test_pred.detach().cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T11:03:03.962693400Z",
     "start_time": "2024-03-31T10:34:45.163567200Z"
    }
   },
   "id": "e56cd37091349bbe"
  },
  {
   "cell_type": "code",
   "source": [
    "estimators = dict(lgb=LGBMClassifier(num_iterations=500,\n",
    "                                     max_depth=7,\n",
    "                                     subsample=0.03329071650502599,\n",
    "                                     learning_rate=0.01366872860687134,\n",
    "                                     feature_fraction=0.7042302378231268,\n",
    "                                     colsample_bytree=0.7270310744955015,\n",
    "                                     colsample_bylevel=0.8125773066822667,\n",
    "                                     reg_lambda=0.8751327285847716,\n",
    "                                     device=\"gpu\",\n",
    "                                     verbose=-1),\n",
    "                  xgb=XGBClassifier(n_estimators=1250,\n",
    "                                    max_depth=5,\n",
    "                                    subsample=0.4145,\n",
    "                                    learning_rate=0.0049,\n",
    "                                    colsample_bytree=0.741,\n",
    "                                    colsample_bylevel=0.819,\n",
    "                                    reg_alpha=0.755,\n",
    "                                    device='cuda:0',\n",
    "                                    verbosity=0),\n",
    "                  cgb=CatBoostClassifier(iterations=39,\n",
    "                                         depth=5,\n",
    "                                         learning_rate=0.15551739,\n",
    "                                         task_type=\"GPU\",\n",
    "                                         silent=True)\n",
    "                  )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:35:38.735539Z",
     "start_time": "2024-03-31T20:35:38.726446700Z"
    }
   },
   "execution_count": 129,
   "outputs": [],
   "id": "ca81620a4203857f"
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "def run(estimators_, x, y):\n",
    "    preds = {}\n",
    "\n",
    "    for k, est in estimators_.items():\n",
    "        m_preds = []\n",
    "        print(f'estimator: {k}')\n",
    "\n",
    "        for r in range(5):\n",
    "            print(f'repeat: {r}')\n",
    "\n",
    "            cv = MultilabelStratifiedKFold(n_splits=7, shuffle=True)\n",
    "\n",
    "            for i, (t_idx, v_idx) in enumerate(cv.split(x, y)):\n",
    "                train_x, valid_x = x[t_idx, :], x[v_idx, :]\n",
    "                train_y, valid_y = y.loc[t_idx, :], y.loc[v_idx, :]\n",
    "                pred_test = np.zeros((len(test), len(ys)))\n",
    "\n",
    "                estimator = make_pipeline(MultiOutputClassifier(est))\n",
    "                estimator.fit(train_x, train_y)\n",
    "\n",
    "                pred_vals = estimator.predict_proba(valid_x)\n",
    "\n",
    "                print(f'fold: {i}')\n",
    "                print(np.mean([roc_auc_score(valid_y.iloc[:, i], pred_vals[i][:, 1]) for i in range(len(ys))]))\n",
    "\n",
    "                for j in range(len(ys)):\n",
    "                    pred_test[:, j] = estimator.predict_proba(test)[j][:, 1]\n",
    "\n",
    "                m_preds.append(pred_test)\n",
    "\n",
    "        preds[k] = m_preds\n",
    "\n",
    "    return preds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:35:40.031794700Z",
     "start_time": "2024-03-31T20:35:40.023609400Z"
    }
   },
   "id": "38947c580f8de100"
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator: lgb\n",
      "repeat: 0\n",
      "fold: 0\n",
      "0.8850161298551269\n",
      "fold: 1\n",
      "0.8887909836908212\n",
      "fold: 2\n",
      "0.8874720632415666\n",
      "fold: 3\n",
      "0.8814420355848911\n",
      "fold: 4\n",
      "0.8843736463138594\n",
      "fold: 5\n",
      "0.8888730407538519\n",
      "fold: 6\n",
      "0.8829150828762089\n",
      "repeat: 1\n",
      "fold: 0\n",
      "0.8929253260937143\n",
      "fold: 1\n",
      "0.8809332086061294\n",
      "fold: 2\n",
      "0.8832010873857955\n",
      "fold: 3\n",
      "0.8944662143428027\n",
      "fold: 4\n",
      "0.8823926627955523\n",
      "fold: 5\n",
      "0.8841169241306048\n",
      "fold: 6\n",
      "0.8849855433016051\n",
      "repeat: 2\n",
      "fold: 0\n",
      "0.8810249067355429\n",
      "fold: 1\n",
      "0.8812835246223854\n",
      "fold: 2\n",
      "0.8834453453916432\n",
      "fold: 3\n",
      "0.8910583499858805\n",
      "fold: 4\n",
      "0.8843399250140769\n",
      "fold: 5\n",
      "0.8936923833094216\n",
      "fold: 6\n",
      "0.8912170910928066\n",
      "repeat: 3\n",
      "fold: 0\n",
      "0.8833895374550019\n",
      "fold: 1\n",
      "0.894965869717217\n",
      "fold: 2\n",
      "0.879010495626514\n",
      "fold: 3\n",
      "0.8822246577108181\n",
      "fold: 4\n",
      "0.8866189231115683\n",
      "fold: 5\n",
      "0.8869232859453698\n",
      "fold: 6\n",
      "0.886536623541838\n",
      "repeat: 4\n",
      "fold: 0\n",
      "0.8862111186459224\n",
      "fold: 1\n",
      "0.8940196230139846\n",
      "fold: 2\n",
      "0.8828918531662892\n",
      "fold: 3\n",
      "0.8852402729775601\n",
      "fold: 4\n",
      "0.8914164430188798\n",
      "fold: 5\n",
      "0.8750229295968743\n",
      "fold: 6\n",
      "0.8853314336151844\n",
      "estimator: xgb\n",
      "repeat: 0\n",
      "fold: 0\n",
      "0.8791975367027078\n",
      "fold: 1\n",
      "0.8890036923994863\n",
      "fold: 2\n",
      "0.887904727504097\n",
      "fold: 3\n",
      "0.8912764887098907\n",
      "fold: 4\n",
      "0.8898516863498277\n",
      "fold: 5\n",
      "0.8924427289627241\n",
      "fold: 6\n",
      "0.8854038640655812\n",
      "repeat: 1\n",
      "fold: 0\n",
      "0.8909151692023912\n",
      "fold: 1\n",
      "0.8854296638606064\n",
      "fold: 2\n",
      "0.8850595573755322\n",
      "fold: 3\n",
      "0.8838088151399893\n",
      "fold: 4\n",
      "0.8865921129279747\n",
      "fold: 5\n",
      "0.8868118122722917\n",
      "fold: 6\n",
      "0.8929545632938634\n",
      "repeat: 2\n",
      "fold: 0\n",
      "0.8850211332000938\n",
      "fold: 1\n",
      "0.8928242042039832\n",
      "fold: 2\n",
      "0.88713658267854\n",
      "fold: 3\n",
      "0.8866202754906404\n",
      "fold: 4\n",
      "0.8878140704948435\n",
      "fold: 5\n",
      "0.8848739100309311\n",
      "fold: 6\n",
      "0.8885575501982901\n",
      "repeat: 3\n",
      "fold: 0\n",
      "0.8920072836227243\n",
      "fold: 1\n",
      "0.8926057974567219\n",
      "fold: 2\n",
      "0.8862016400035557\n",
      "fold: 3\n",
      "0.8878820647152296\n",
      "fold: 4\n",
      "0.8834295234983156\n",
      "fold: 5\n",
      "0.888231821850322\n",
      "fold: 6\n",
      "0.8825151500995972\n",
      "repeat: 4\n",
      "fold: 0\n",
      "0.8884773574526924\n",
      "fold: 1\n",
      "0.8925337564689121\n",
      "fold: 2\n",
      "0.8880716263311074\n",
      "fold: 3\n",
      "0.880520980865723\n",
      "fold: 4\n",
      "0.8926736364344711\n",
      "fold: 5\n",
      "0.8883918737584068\n",
      "fold: 6\n",
      "0.8802547157212562\n",
      "estimator: cgb\n",
      "repeat: 0\n",
      "fold: 0\n",
      "0.8854377079794441\n",
      "fold: 1\n",
      "0.8942486456596335\n",
      "fold: 2\n",
      "0.8841109570054789\n",
      "fold: 3\n",
      "0.8779924175813983\n",
      "fold: 4\n",
      "0.8802000997692535\n",
      "fold: 5\n",
      "0.8811236329031067\n",
      "fold: 6\n",
      "0.8828089365611405\n",
      "repeat: 1\n",
      "fold: 0\n",
      "0.876442234592478\n",
      "fold: 1\n",
      "0.8902565259803978\n",
      "fold: 2\n",
      "0.8846843687446544\n",
      "fold: 3\n",
      "0.8804195357795876\n",
      "fold: 4\n",
      "0.8900642194147034\n",
      "fold: 5\n",
      "0.884759456810914\n",
      "fold: 6\n",
      "0.880381346691325\n",
      "repeat: 2\n",
      "fold: 0\n",
      "0.8801541378259744\n",
      "fold: 1\n",
      "0.883653969970869\n",
      "fold: 2\n",
      "0.8853381918434797\n",
      "fold: 3\n",
      "0.8862434104314326\n",
      "fold: 4\n",
      "0.8881973245111281\n",
      "fold: 5\n",
      "0.877628941348404\n",
      "fold: 6\n",
      "0.8833672003945298\n",
      "repeat: 3\n",
      "fold: 0\n",
      "0.883699798128419\n",
      "fold: 1\n",
      "0.8816422188243276\n",
      "fold: 2\n",
      "0.8868839930301216\n",
      "fold: 3\n",
      "0.8858073160310893\n",
      "fold: 4\n",
      "0.8851687890242944\n",
      "fold: 5\n",
      "0.8801297554639718\n",
      "fold: 6\n",
      "0.879907200986389\n",
      "repeat: 4\n",
      "fold: 0\n",
      "0.8757814218117027\n",
      "fold: 1\n",
      "0.8885643340107797\n",
      "fold: 2\n",
      "0.8872828504156935\n",
      "fold: 3\n",
      "0.8810434789154863\n",
      "fold: 4\n",
      "0.8818739702292832\n",
      "fold: 5\n",
      "0.8851215866664374\n",
      "fold: 6\n",
      "0.8863228396817224\n"
     ]
    }
   ],
   "source": [
    "preds = run(estimators, X, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T21:09:00.389267200Z",
     "start_time": "2024-03-31T20:35:42.539272600Z"
    }
   },
   "id": "b56666e02368ae33"
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "ann = np.mean(np.asarray(test_preds), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T11:16:03.754991800Z",
     "start_time": "2024-03-31T11:16:03.732095400Z"
    }
   },
   "id": "b6aeb60924bfbce6"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "submission = (np.mean(np.asarray(preds['lgb']), axis=0) +\n",
    "              # 0.2 * ann +\n",
    "              np.mean(np.asarray(preds['xgb']), axis=0) +\n",
    "              np.mean(np.asarray(preds['cgb']), axis=0))/ 3\n",
    "submission = pd.DataFrame(submission, columns=sub.columns).set_index(sub.index)\n",
    "submission.to_csv('submission_2.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T21:16:56.527145700Z",
     "start_time": "2024-03-31T21:16:56.390942200Z"
    }
   },
   "id": "861ff449348ac478"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## sudo labeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4c86066a0af00e7"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "       Pastry  Z_Scratch  K_Scatch  Stains  Dirtiness  Bumps  Other_Faults\n0           1          0         0       0          0      0             0\n1           0          0         0       0          0      0             1\n2           0          0         0       0          0      0             1\n3           0          0         0       0          0      0             1\n4           0          0         0       0          0      1             0\n...       ...        ...       ...     ...        ...    ...           ...\n12809       0          0         0       0          0      0             1\n12810       0          0         0       0          0      0             1\n12811       0          0         1       0          0      0             0\n12812       1          0         0       0          0      0             0\n12813       0          0         1       0          0      0             0\n\n[12814 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pastry</th>\n      <th>Z_Scratch</th>\n      <th>K_Scatch</th>\n      <th>Stains</th>\n      <th>Dirtiness</th>\n      <th>Bumps</th>\n      <th>Other_Faults</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12809</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12810</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12811</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12812</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12813</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>12814 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.zeros_like(submission.values)\n",
    "mask[np.arange(len(submission)), submission.values.argmax(1)] = 1\n",
    "\n",
    "test_sudo = pd.DataFrame(mask, columns=submission.columns).astype(int)\n",
    "test_sudo"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T06:56:45.710124Z",
     "start_time": "2024-03-31T06:56:45.698269500Z"
    }
   },
   "id": "11506f0e1e2402f6"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "new_train = pd.concat((X, test), axis=0)\n",
    "new_y = pd.concat((Y, test_sudo), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T06:56:52.138368700Z",
     "start_time": "2024-03-31T06:56:52.091284700Z"
    }
   },
   "id": "1232f1ee7b9d637c"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "(None, None)"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.reset_index(drop=True, inplace=True), new_y.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T06:56:54.081387Z",
     "start_time": "2024-03-31T06:56:54.071560Z"
    }
   },
   "id": "923f79cd55eced32"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "cv = MultilabelStratifiedKFold(n_splits=7, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T06:57:36.872569200Z",
     "start_time": "2024-03-31T06:57:36.856585900Z"
    }
   },
   "id": "9e7fa64e59c3268b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## adjested parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b075b8f6287d662c"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "estimators = dict(lgb=LGBMClassifier(num_iterations=1000,\n",
    "                                     max_depth=3,\n",
    "                                     learning_rate=0.0098988815333333,\n",
    "                                     feature_fraction=0.8578138132619784,\n",
    "                                     colsample_bytree=0.8768880865721203,\n",
    "                                     reg_lambda=0.7173767456929144,\n",
    "                                     device=\"gpu\",\n",
    "                                     verbose=-1),\n",
    "                  xgb=XGBClassifier(n_estimators=1000,\n",
    "                                    max_depth=6,\n",
    "                                    subsample=0.5342564004636723,\n",
    "                                    learning_rate=0.0064835939090773,\n",
    "                                    colsample_bytree=0.8195724454605662,\n",
    "                                    reg_lambda=0.09829546268908843,\n",
    "                                    device='cuda:0',\n",
    "                                    verbosity=0),\n",
    "                  cgb=CatBoostClassifier(iterations=110,\n",
    "                                         depth=6,\n",
    "                                         learning_rate=0.06201739,\n",
    "                                         task_type=\"GPU\",\n",
    "                                         cat_features=['col_7', 'col_9', 'col_10',\n",
    "                                                       'TypeOfSteel_A300',\n",
    "                                                       'TypeOfSteel_A400'],\n",
    "                                         silent=True)\n",
    "                  )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T06:58:13.515341200Z",
     "start_time": "2024-03-31T06:58:13.496688700Z"
    }
   },
   "id": "6bdf44c9b192199"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator: lgb\n",
      "repeat: 0\n",
      "fold: 0\n",
      "0.9235298340826964\n",
      "fold: 1\n",
      "0.920031843730221\n",
      "fold: 2\n",
      "0.925597484617836\n",
      "fold: 3\n",
      "0.9254829579036551\n",
      "fold: 4\n",
      "0.919936498938264\n",
      "fold: 5\n",
      "0.9173495225279107\n",
      "fold: 6\n",
      "0.9177276349419298\n",
      "repeat: 1\n",
      "fold: 0\n",
      "0.920152108402571\n",
      "fold: 1\n",
      "0.914422992867854\n",
      "fold: 2\n",
      "0.9223185143707201\n",
      "fold: 3\n",
      "0.9210876881754031\n",
      "fold: 4\n",
      "0.9234152922210682\n",
      "fold: 5\n",
      "0.9212804576067073\n",
      "fold: 6\n",
      "0.9278080851442703\n",
      "repeat: 2\n",
      "fold: 0\n",
      "0.9199293834871664\n",
      "fold: 1\n",
      "0.9191341820742318\n",
      "fold: 2\n",
      "0.9193754152224337\n",
      "fold: 3\n",
      "0.9175908421465644\n",
      "fold: 4\n",
      "0.926162562365645\n",
      "fold: 5\n",
      "0.9225567305225415\n",
      "fold: 6\n",
      "0.9239758035880096\n",
      "repeat: 3\n",
      "fold: 0\n",
      "0.9195858608549977\n",
      "fold: 1\n",
      "0.9162450151379825\n",
      "fold: 2\n",
      "0.9256171048837388\n",
      "fold: 3\n",
      "0.9283986278802904\n",
      "fold: 4\n",
      "0.9210490869989457\n",
      "fold: 5\n",
      "0.9178742574107288\n",
      "fold: 6\n",
      "0.9230452214652564\n",
      "repeat: 4\n",
      "fold: 0\n",
      "0.9189878545360827\n",
      "fold: 1\n",
      "0.9260340115851077\n",
      "fold: 2\n",
      "0.9214153499648114\n",
      "fold: 3\n",
      "0.919320059251012\n",
      "fold: 4\n",
      "0.9197256080084049\n",
      "fold: 5\n",
      "0.9188078459221057\n",
      "fold: 6\n",
      "0.9211438858918052\n",
      "estimator: xgb\n",
      "repeat: 0\n",
      "fold: 0\n",
      "0.9232725293603208\n",
      "fold: 1\n",
      "0.9294944391640483\n",
      "fold: 2\n",
      "0.9229406216303152\n",
      "fold: 3\n",
      "0.92483201576485\n",
      "fold: 4\n",
      "0.921900651686958\n",
      "fold: 5\n",
      "0.9197762409527855\n",
      "fold: 6\n",
      "0.9244877043523683\n",
      "repeat: 1\n",
      "fold: 0\n",
      "0.9229689878692074\n",
      "fold: 1\n",
      "0.9220752780978215\n",
      "fold: 2\n",
      "0.9224909334373493\n",
      "fold: 3\n",
      "0.9273850092571819\n",
      "fold: 4\n",
      "0.9252068530798685\n",
      "fold: 5\n",
      "0.922115055908999\n",
      "fold: 6\n",
      "0.9254330363639518\n",
      "repeat: 2\n",
      "fold: 0\n",
      "0.9226573867974613\n",
      "fold: 1\n",
      "0.9248460838714389\n",
      "fold: 2\n",
      "0.9236159863826033\n",
      "fold: 3\n",
      "0.9275983279706227\n",
      "fold: 4\n",
      "0.9209459084977174\n",
      "fold: 5\n",
      "0.9269556224982799\n",
      "fold: 6\n",
      "0.9231502720505954\n",
      "repeat: 3\n",
      "fold: 0\n",
      "0.9294453809027778\n",
      "fold: 1\n",
      "0.9182346525480497\n",
      "fold: 2\n",
      "0.9247395205100631\n",
      "fold: 3\n",
      "0.9216691212442932\n",
      "fold: 4\n",
      "0.9271442341443236\n",
      "fold: 5\n",
      "0.9235674507432827\n",
      "fold: 6\n",
      "0.9239835204491397\n",
      "repeat: 4\n",
      "fold: 0\n",
      "0.9238854154459529\n",
      "fold: 1\n",
      "0.9247623846697052\n",
      "fold: 2\n",
      "0.926546125300359\n",
      "fold: 3\n",
      "0.9218101655878278\n",
      "fold: 4\n",
      "0.9229291851166153\n",
      "fold: 5\n",
      "0.9241619434661413\n",
      "fold: 6\n",
      "0.9243746838210907\n",
      "estimator: cgb\n",
      "repeat: 0\n",
      "fold: 0\n",
      "0.9222849968726944\n",
      "fold: 1\n",
      "0.924677066563223\n",
      "fold: 2\n",
      "0.9171849627104077\n",
      "fold: 3\n",
      "0.9206000423388737\n",
      "fold: 4\n",
      "0.9193173376703918\n",
      "fold: 5\n",
      "0.9132418881212346\n",
      "fold: 6\n",
      "0.9297330525381179\n",
      "repeat: 1\n",
      "fold: 0\n",
      "0.9202131206855404\n",
      "fold: 1\n",
      "0.9198092762775929\n",
      "fold: 2\n",
      "0.9260803609731187\n",
      "fold: 3\n",
      "0.922070576225819\n",
      "fold: 4\n",
      "0.9241449582987789\n",
      "fold: 5\n",
      "0.9197718876539404\n",
      "fold: 6\n",
      "0.9181856125311999\n",
      "repeat: 2\n",
      "fold: 0\n",
      "0.9173446470830948\n",
      "fold: 1\n",
      "0.9278460891428798\n",
      "fold: 2\n",
      "0.921534488169003\n",
      "fold: 3\n",
      "0.9172618292998207\n",
      "fold: 4\n",
      "0.9230688128869494\n",
      "fold: 5\n",
      "0.9250855050910028\n",
      "fold: 6\n",
      "0.9188361137732092\n",
      "repeat: 3\n",
      "fold: 0\n",
      "0.9214772608245687\n",
      "fold: 1\n",
      "0.9236947742537568\n",
      "fold: 2\n",
      "0.9211913988878646\n",
      "fold: 3\n",
      "0.9236603835120638\n",
      "fold: 4\n",
      "0.9183048615030499\n",
      "fold: 5\n",
      "0.9200367555594224\n",
      "fold: 6\n",
      "0.9253483686865441\n",
      "repeat: 4\n",
      "fold: 0\n",
      "0.9151798634327093\n",
      "fold: 1\n",
      "0.9199777753119134\n",
      "fold: 2\n",
      "0.9262668521775944\n",
      "fold: 3\n",
      "0.9204745718808683\n",
      "fold: 4\n",
      "0.9283001509540391\n",
      "fold: 5\n",
      "0.9194749281627335\n",
      "fold: 6\n",
      "0.9224872894197109\n"
     ]
    }
   ],
   "source": [
    "preds_sudo = run(estimators, new_train, new_y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:32:48.223973Z",
     "start_time": "2024-03-31T06:58:19.001304600Z"
    }
   },
   "id": "bf7d78c879f54e01"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "         Pastry  Z_Scratch  K_Scatch    Stains  Dirtiness     Bumps  \\\nid                                                                    \n19219  0.600816   0.002274  0.002021  0.000160   0.007662  0.097604   \n19220  0.186851   0.009450  0.007282  0.000260   0.105812  0.148495   \n19221  0.001967   0.018239  0.019993  0.000506   0.005504  0.231412   \n19222  0.064271   0.001191  0.000393  0.001418   0.005827  0.402230   \n19223  0.002356   0.001193  0.000817  0.001439   0.002905  0.729605   \n...         ...        ...       ...       ...        ...       ...   \n32028  0.030502   0.059271  0.001424  0.000174   0.014847  0.121276   \n32029  0.079953   0.002290  0.012762  0.003498   0.077682  0.127815   \n32030  0.000470   0.000617  0.949288  0.000181   0.000325  0.001405   \n32031  0.629566   0.005676  0.010990  0.000187   0.022477  0.143209   \n32032  0.000958   0.005375  0.942396  0.000203   0.000437  0.004516   \n\n       Other_Faults  \nid                   \n19219      0.467252  \n19220      0.416563  \n19221      0.615824  \n19222      0.455761  \n19223      0.302489  \n...             ...  \n32028      0.573928  \n32029      0.621720  \n32030      0.048698  \n32031      0.357949  \n32032      0.050639  \n\n[12814 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pastry</th>\n      <th>Z_Scratch</th>\n      <th>K_Scatch</th>\n      <th>Stains</th>\n      <th>Dirtiness</th>\n      <th>Bumps</th>\n      <th>Other_Faults</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19219</th>\n      <td>0.600816</td>\n      <td>0.002274</td>\n      <td>0.002021</td>\n      <td>0.000160</td>\n      <td>0.007662</td>\n      <td>0.097604</td>\n      <td>0.467252</td>\n    </tr>\n    <tr>\n      <th>19220</th>\n      <td>0.186851</td>\n      <td>0.009450</td>\n      <td>0.007282</td>\n      <td>0.000260</td>\n      <td>0.105812</td>\n      <td>0.148495</td>\n      <td>0.416563</td>\n    </tr>\n    <tr>\n      <th>19221</th>\n      <td>0.001967</td>\n      <td>0.018239</td>\n      <td>0.019993</td>\n      <td>0.000506</td>\n      <td>0.005504</td>\n      <td>0.231412</td>\n      <td>0.615824</td>\n    </tr>\n    <tr>\n      <th>19222</th>\n      <td>0.064271</td>\n      <td>0.001191</td>\n      <td>0.000393</td>\n      <td>0.001418</td>\n      <td>0.005827</td>\n      <td>0.402230</td>\n      <td>0.455761</td>\n    </tr>\n    <tr>\n      <th>19223</th>\n      <td>0.002356</td>\n      <td>0.001193</td>\n      <td>0.000817</td>\n      <td>0.001439</td>\n      <td>0.002905</td>\n      <td>0.729605</td>\n      <td>0.302489</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32028</th>\n      <td>0.030502</td>\n      <td>0.059271</td>\n      <td>0.001424</td>\n      <td>0.000174</td>\n      <td>0.014847</td>\n      <td>0.121276</td>\n      <td>0.573928</td>\n    </tr>\n    <tr>\n      <th>32029</th>\n      <td>0.079953</td>\n      <td>0.002290</td>\n      <td>0.012762</td>\n      <td>0.003498</td>\n      <td>0.077682</td>\n      <td>0.127815</td>\n      <td>0.621720</td>\n    </tr>\n    <tr>\n      <th>32030</th>\n      <td>0.000470</td>\n      <td>0.000617</td>\n      <td>0.949288</td>\n      <td>0.000181</td>\n      <td>0.000325</td>\n      <td>0.001405</td>\n      <td>0.048698</td>\n    </tr>\n    <tr>\n      <th>32031</th>\n      <td>0.629566</td>\n      <td>0.005676</td>\n      <td>0.010990</td>\n      <td>0.000187</td>\n      <td>0.022477</td>\n      <td>0.143209</td>\n      <td>0.357949</td>\n    </tr>\n    <tr>\n      <th>32032</th>\n      <td>0.000958</td>\n      <td>0.005375</td>\n      <td>0.942396</td>\n      <td>0.000203</td>\n      <td>0.000437</td>\n      <td>0.004516</td>\n      <td>0.050639</td>\n    </tr>\n  </tbody>\n</table>\n<p>12814 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_sudo = (0.1 * np.mean(np.asarray(preds_sudo['lgb']), axis=0) +\n",
    "                   0.6 * np.mean(np.asarray(preds_sudo['xgb']), axis=0) +\n",
    "                   0.3 * np.mean(np.asarray(preds_sudo['cgb']), axis=0))\n",
    "submission_sudo = pd.DataFrame(submission_sudo, columns=sub.columns).set_index(sub.index)\n",
    "submission_sudo.to_csv('submission_sudo.csv')\n",
    "submission_sudo"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:33:43.775334500Z",
     "start_time": "2024-03-31T07:33:43.291066Z"
    }
   },
   "id": "98333263f4316ae6"
  }
 ]
}
